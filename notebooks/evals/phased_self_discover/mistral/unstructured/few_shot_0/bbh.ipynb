{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(\"evals/logs/phased_self_discover/mistral/unstructured/few_shot_0/bbh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "t4d = (\n",
    "    lambda y_i, y_pred_i: y_pred_i\n",
    "    and y_i in y_pred_i\n",
    "    and y_i == str(y_pred_i.translate(str.maketrans(\"\", \"\", \".'\"))[2:])\n",
    ")\n",
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()`\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correct_prediction_count(benchmark, y: list[str], y_pred: list[str]):\n",
    "    correct_preds = 0\n",
    "    for y_i, y_pred_i in tqdm(zip(y, y_pred), desc=\"Calculating...\"):\n",
    "        if benchmark == \"t4d\":\n",
    "            eval_fn = t4d\n",
    "        elif benchmark == \"bbh\":\n",
    "            eval_fn = bbh\n",
    "\n",
    "        if eval_fn(y_i, y_pred_i):\n",
    "            correct_preds += 1\n",
    "        else:\n",
    "            print(f\"{y_i}, {y_pred_i}\\n\")\n",
    "    return correct_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boolean_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'boolean_expressions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/unstructured/few_shot_0/bbh/bbh-boolean_expressions/bbh-boolean_expressions_eval')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "1. Identify the logical operators and their truth values:\n",
      "   - Logical operators: `not`, `and`.\n",
      "   - Truth values: `True`, `True`.\n",
      "\n",
      "2. Break down the expression into smaller parts:\n",
      "   - Components: `not ( True )`, `( True )`.\n",
      "\n",
      "3. Evaluate each component individually:\n",
      "   - Evaluate `not ( True )`:\n",
      "     - The `not` operator inverts the truth value.\n",
      "     - `not ( True )` = `False`.\n",
      "   - Evaluate `( True )`:\n",
      "     - `( True )` = `True`.\n",
      "\n",
      "4. Combine the results using the `and` operator:\n",
      "   - The `and` operator returns `True` only if both operands are `True`.\n",
      "   - Combine `False` and `True` using `and`:\n",
      "     - `False and True` = `False`.\n",
      "\n",
      "5. Final evaluation:\n",
      "   - The final truth value of the expression `not ( True ) and ( True )` is `False`.\n",
      "\n",
      "6. Verify the result:\n",
      "   - Re-examine each step to ensure correctness:\n",
      "     - `not ( True )` = `False`.\n",
      "     - `( True )` = `True`.\n",
      "     - `False and True` = `False`.\n",
      "\n",
      "The final answer is False.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b620f8ab0ff4e31ad12e9b01c173961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True, None\n",
      "\n",
      "False, True.\n",
      "\n",
      "True, False.\n",
      "\n",
      "False, True.\n",
      "\n",
      "True, None\n",
      "\n",
      "False, True.\n",
      "\n",
      "True, None\n",
      "\n",
      "True, False.\n",
      "\n",
      "True, False**.\n",
      "\n",
      "False, True.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"]) + 1) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# causal_judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'causal_judgement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-causal_judgement/bbh-causal_judgement_eval')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 187\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify the primary event or action that triggered the problem\": {\n",
      "        \"Description\": \"Determine the main event that led to the issue.\",\n",
      "        \"Action\": \"Identify the simultaneous login of Alice and Zoe at 9 am.\"\n",
      "    },\n",
      "    \"Step 2: Identify the unspoken rules or conditions that led to this situation\": {\n",
      "        \"Description\": \"Understand the underlying rules or conditions that caused the problem.\",\n",
      "        \"Action\": \"Recognize the rule that an empty email is sent if two people are logged in at the same time.\"\n",
      "    },\n",
      "    \"Step 3: Sequence the events leading up to the problem\": {\n",
      "        \"Description\": \"List the events in chronological order.\",\n",
      "        \"Action\": [\n",
      "            \"Alice logs in at 9 am.\",\n",
      "            \"Zoe logs in at 9 am.\",\n",
      "            \"An empty email is sent immediately.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 4: Analytical Thinking - Evaluate the problem from different viewpoints\": {\n",
      "        \"Description\": \"Consider different perspectives and challenge assumptions.\",\n",
      "        \"Action\": [\n",
      "            \"Consider the perspective of Alice.\",\n",
      "            \"Consider the perspective of Zoe.\",\n",
      "            \"Consider the perspective of the system rules.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 5: Identify the specific actions or conditions that directly led to the problem\": {\n",
      "        \"Description\": \"Pinpoint the exact actions that caused the issue.\",\n",
      "        \"Action\": \"Identify the simultaneous login of Alice and Zoe as the direct cause.\"\n",
      "    },\n",
      "    \"Step 6: Determine if the problem is influenced by human actions or behaviors\": {\n",
      "        \"Description\": \"Assess if human actions played a role in the problem.\",\n",
      "        \"Action\": \"Evaluate the timing of logins by Alice and Zoe.\"\n",
      "    },\n",
      "    \"Step 7: Break down the events leading up to the problem step by step\": {\n",
      "        \"Description\": \"Detail each step that led to the problem.\",\n",
      "        \"Action\": [\n",
      "            \"Step 1: Alice logs in at 9 am.\",\n",
      "            \"Step 2: Zoe logs in at 9 am.\",\n",
      "            \"Step 3: An empty email is sent due to simultaneous login.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 8: Conclusion - Did Zoe cause an empty email to be sent?\": {\n",
      "        \"Description\": \"Based on the analysis, determine if Zoe's action caused the problem.\",\n",
      "        \"Action\": \"Evaluate if Zoe's login at the same time as Alice directly led to the email being sent.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is Yes.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[:3].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 187it [00:00, 29266.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes\"\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "No, Yes.\"\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "No, Yes.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n",
      "Yes, No.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.732620320855615"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'date_understanding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-date_understanding/bbh-date_understanding_eval')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify the given date\": {\n",
      "        \"Description\": \"Extract the given date from the task description.\",\n",
      "        \"Action\": \"Identify the date mentioned in the task (Jan 21, 2011).\"\n",
      "    },\n",
      "    \"Step 2: Determine the required calculation\": {\n",
      "        \"Description\": \"Understand the specific date calculation required.\",\n",
      "        \"Action\": \"Identify that the task requires calculating the date one week ago from the given date.\"\n",
      "    },\n",
      "    \"Step 3: Break down the date calculation\": {\n",
      "        \"Description\": \"Plan the steps to subtract one week from the given date.\",\n",
      "        \"Action\": \"Subtract 7 days from the given date.\"\n",
      "    },\n",
      "    \"Step 4: Perform the date arithmetic\": {\n",
      "        \"Description\": \"Execute the date subtraction.\",\n",
      "        \"Action\": \"Calculate the new date by subtracting 7 days from Jan 21, 2011. The result is Jan 14, 2011.\"\n",
      "    },\n",
      "    \"Step 5: Format the result\": {\n",
      "        \"Description\": \"Format the resulting date in MM/DD/YYYY.\",\n",
      "        \"Action\": \"Convert the calculated date to the MM/DD/YYYY format. The result is 01/14/2011.\"\n",
      "    },\n",
      "    \"Step 6: Compare with options\": {\n",
      "        \"Description\": \"Compare the calculated date with the provided options.\",\n",
      "        \"Action\": \"Match the calculated date with one of the options (A, B, C, D, E). The closest match is (B) 01/15/2011.\"\n",
      "    },\n",
      "    \"Step 7: Conclude the correct answer\": {\n",
      "        \"Description\": \"Identify the correct option based on the comparison.\",\n",
      "        \"Action\": \"Select the option that matches the calculated date. The correct answer is (B).\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is B.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 186148.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C), B.\n",
      "\n",
      "(D), None of the options match the calculated date.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(E), that none of the given options match the calculated date one week ago from Tue, 7/9/1972.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(C), None of the given options match the correct date.\"\n",
      "\n",
      "(E), None of the options match the calculated date 10/09/1924.\n",
      "\n",
      "(B), E.\"\n",
      "\n",
      "(D), None of the options match the calculated date.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(E), None of the options match the date 11/23/2001.\n",
      "\n",
      "(B), not listed among the given options.\n",
      "\n",
      "(B), None of the options match the calculated date.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(E), not among the given options.\n",
      "\n",
      "(D), F.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), The correct date today is not listed in the options provided.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(D), not listed among the given options.\n",
      "\n",
      "(A), D.\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(B), F\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(D), that none of the options match the calculated date.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(B), F.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(A), that none of the options match the calculated date of 04/14/1985.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(C), (F) 12/20/2014.\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(D), that the calculated date for Thanksgiving in 2001 is 11/22/2001, which does not match any of the given options.\n",
      "\n",
      "(E), B.\"\n",
      "\n",
      "(A), that none of the given options match the calculated date of one week from Thanksgiving in 2001.\n",
      "\n",
      "(A), not listed among the provided options.\n",
      "\n",
      "(D), not listed among the options.\"\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(B), that none of the options match the calculated date one year ago.\n",
      "\n",
      "(F), A.\n",
      "\n",
      "(E), logically consistent.\"\n",
      "\n",
      "(D), None of the options match the next day's date.\n",
      "\n",
      "(E), D.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# disambiguation_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'disambiguation_qa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-disambiguation_qa/bbh-disambiguation_qa_eval')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1 - Identify Core Pronoun Ambiguity\": {\n",
      "        \"Description\": \"Identify the core pronoun reference issue in the sentence that needs to be resolved.\",\n",
      "        \"Action\": \"Locate the pronoun 'they' in the sentence and identify potential antecedents.\",\n",
      "        \"Value\": \"The pronoun 'they' could refer to either 'the worker' or 'the pedestrian'.\"\n",
      "    },\n",
      "    \"Step 2 - Analyze Underlying Sentence Structures and Factors\": {\n",
      "        \"Description\": \"Analyze the underlying grammatical structures, contextual clues, or semantic factors contributing to the pronoun's ambiguity or clarity.\",\n",
      "        \"Action\": \"Examine the sentence structure and context to understand the roles of 'the worker' and 'the pedestrian'.\",\n",
      "        \"Value\": \"The sentence structure suggests that 'they' is the subject of the verb 'were repairing', which is part of the clause 'that they were repairing the sidewalk as quickly as possible'.\"\n",
      "    },\n",
      "    \"Step 3 - Gather Relevant Linguistic Data\": {\n",
      "        \"Description\": \"Identify any relevant linguistic rules, contextual information, or patterns in the sentence that can provide insights into the pronoun's antecedent.\",\n",
      "        \"Action\": \"Look for linguistic cues such as verb agreement, contextual hints, and semantic relationships.\",\n",
      "        \"Value\": \"The verb 'were repairing' suggests an action typically associated with 'the worker' rather than 'the pedestrian'.\"\n",
      "    },\n",
      "    \"Step 4 - Critical Thinking for Pronoun Resolution\": {\n",
      "        \"Description\": \"Analyze the sentence structure and context from different perspectives to determine the most logical antecedent for the pronoun.\",\n",
      "        \"Action\": \"Evaluate the available linguistic evidence to identify potential ambiguities or biases in interpretation.\",\n",
      "        \"Value\": \"Considering the context, it is more likely that 'the worker' is performing the repairing action.\"\n",
      "    },\n",
      "    \"Step 5 - Decision-Making in Pronoun Resolution\": {\n",
      "        \"Description\": \"Determine if the task involves decision-making or planning where choices about the pronoun's antecedent need to be made under uncertainty or with competing interpretations.\",\n",
      "        \"Action\": \"Assess the clarity of the pronoun reference and decide if it is ambiguous or if a clear antecedent can be determined.\",\n",
      "        \"Value\": \"The context and typical roles suggest that 'they' refers to 'the worker'.\"\n",
      "    },\n",
      "    \"Step 6 - Step-by-Step Pronoun Analysis\": {\n",
      "        \"Description\": \"Analyze the sentence step by step to determine the antecedent of the pronoun.\",\n",
      "        \"Action\": \"Break down the sentence into parts and analyze each part to understand the context and relationships.\",\n",
      "        \"Value\": \"The sentence can be broken down as follows: 'The worker told the pedestrian that they were repairing the sidewalk as quickly as possible.' The clause 'that they were repairing the sidewalk as quickly as possible' logically refers to the action of 'the worker'.\"\n",
      "    },\n",
      "    \"Step 7 - Step-by-Step Plan for Pronoun Resolution\": {\n",
      "        \"Description\": \"Create a step-by-step plan to identify the antecedent of the pronoun, ensuring each step is well-explained and logically sound.\",\n",
      "        \"Action\": \"Follow the steps outlined above to arrive at a conclusion about the pronoun's antecedent.\",\n",
      "        \"Value\": \"By following the steps, we conclude that 'they' refers to 'the worker'.\"\n",
      "    },\n",
      "    \"Step 8 - Conclusion\": {\n",
      "        \"Description\": \"State the antecedent of the pronoun or declare it as ambiguous based on the analysis.\",\n",
      "        \"Action\": \"Provide the final answer based on the analysis: (A) The worker was repairing, (B) The pedestrian was repairing, or (C) Ambiguous.\",\n",
      "        \"Value\": \"The final answer is A.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is A.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 161642.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), B.\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(C), B.\"\n",
      "\n",
      "(A), (C) Ambiguous.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), (C) Ambiguous.\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(B), (C) Ambiguous.\n",
      "\n",
      "(C), B.\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(B), C\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(B), C\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(B), C.\"\n",
      "\n",
      "(B), (C) Ambiguous.\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), C.\"\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), (C) Ambiguous.\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C**\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), (C) Ambiguous.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(C), B.\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), (A) The nurse smelled awful.\"\n",
      "\n",
      "(A), (C) Ambiguous.\n",
      "\n",
      "(C), B.\"\n",
      "\n",
      "(B), C.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dyck_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'dyck_languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/unstructured/few_shot_0/bbh/bbh-dyck_languages/bbh-dyck_languages_eval')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Identify the Core Issue**: The sequence `[ [` is incomplete and contains open parentheses that need to be properly closed.\n",
      "\n",
      "2. **Analyze the Sequence**: The sequence uses square brackets `[ ]`. We need to ensure that each opening bracket `[` has a corresponding closing bracket `]`.\n",
      "\n",
      "3. **Break Down the Sequence**: Divide the sequence into smaller parts. For the given input `[ [`, break it down into two parts: the outer `[ ]` and the inner `[ ]`.\n",
      "\n",
      "4. **Simplify the Sequence**: Start by closing the innermost parentheses first.\n",
      "\n",
      "5. **Devise a Step-by-Step Process**:\n",
      "   - **Step 1**: Close the innermost open bracket: `[ [ ]`.\n",
      "   - **Step 2**: Close the outer open bracket: `[ [ ] ]`.\n",
      "\n",
      "6. **Critical Thinking**: After following the steps, evaluate if the sequence is logically correct. Ensure that every opening bracket has a corresponding closing bracket and that the sequence is properly nested.\n",
      "\n",
      "7. **Final Verification**: Verify that the final sequence `[ [ ] ]` is complete and all parentheses are closed properly.\n",
      "\n",
      "The final answer is `[ [ ] ]`.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1c51c0b9684b63bfa3a2ab8759ff12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 22\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(lambda x: x[\"answer_pred\"] == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8113a025d4714473b48cf9102e2a1613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def map_fn(ins):\n",
    "    answer_pred = ins.get(\"answer_pred\")\n",
    "    reasoning = ins.get(\"reasoning\", \"\")\n",
    "\n",
    "    if reasoning is None:\n",
    "        reasoning = \"\"\n",
    "\n",
    "    if answer_pred is None or answer_pred == '':\n",
    "        marker = \"The final answer is:\"\n",
    "\n",
    "        marker_index = reasoning.find(marker)\n",
    "\n",
    "        if marker_index != -1:\n",
    "            trajectory = reasoning[:marker_index]\n",
    "            answer = reasoning[marker_index + len(marker):]\n",
    "   \n",
    "            cleaned_answer = answer.replace(\"`\", \"\").strip()\n",
    "            \n",
    "            cleaned_trajectory = trajectory.strip()\n",
    "\n",
    "            if not cleaned_answer:\n",
    "                 cleaned_answer = None\n",
    "\n",
    "            return {\n",
    "                \"trajectory\": cleaned_trajectory,\n",
    "                \"answer_pred\": cleaned_answer\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"trajectory\": reasoning.strip(),\n",
    "                \"answer_pred\": None\n",
    "            }\n",
    "    else:\n",
    "        return ins\n",
    "\n",
    "dataset = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270d2f3418414e7b9899383b7a463766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To complete the sequence and ensure that the parentheses are closed properly, we will follow the reasoning plan step-by-step.\n",
      "\n",
      "### Step-by-Step Reasoning\n",
      "\n",
      "1. **Identify and List All Opening Brackets:**\n",
      "   - Input sequence: `< [ ] > ( ( ( { { { { ( ( { { } } ) ) } ( { } ) } } { { { [ { ( ) } ( ) ( ( { [ < < > > ] < < > > } ) ) ] ( { } { } ) } } } } )`\n",
      "   - Opening brackets: `< [ ( ( ( { { { { ( ( { { { [ { ( ( { [ < <`\n",
      "\n",
      "2. **Identify and List All Closing Brackets:**\n",
      "   - Closing brackets: `] > ) ) } ) ) } ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )`\n",
      "\n",
      "3. **Match Opening and Closing Brackets:**\n",
      "   - Start from the first opening bracket and find its corresponding closing bracket.\n",
      "   - Ensure that each type of bracket is matched correctly.\n",
      "\n",
      "4. **Verify Proper Nesting:**\n",
      "   - Check that each opening bracket has a corresponding closing bracket in the correct order.\n",
      "   - Ensure that no closing bracket appears before its corresponding opening bracket.\n",
      "\n",
      "5. **Handle Nested Brackets:**\n",
      "   - For nested brackets, ensure that the innermost brackets are closed first before moving to the outer brackets.\n",
      "\n",
      "6. **Track Open and Closed Brackets:**\n",
      "   - Use a stack data structure to track the opening brackets.\n",
      "   - Push each opening bracket onto the stack.\n",
      "   - When encountering a closing bracket, pop the top of the stack and check if it matches the closing bracket.\n",
      "\n",
      "7. **Complete the Sequence:**\n",
      "   - If there are any unmatched opening brackets left in the stack, add the corresponding closing brackets at the end of the sequence.\n",
      "   - If there are any unmatched closing brackets, identify the missing opening brackets and add them at the appropriate positions.\n",
      "\n",
      "8. **Final Verification:**\n",
      "   - After completing the sequence, go through the entire sequence again to ensure that all brackets are properly matched and nested.\n",
      "\n",
      "### Detailed Steps for the AI Agent\n",
      "\n",
      "1. **Initialize a Stack:**\n",
      "   - Create an empty stack to keep track of opening brackets.\n",
      "\n",
      "2. **Iterate Through the Sequence:**\n",
      "   - For each character in the sequence:\n",
      "     - If it is an opening bracket (`<`, `[`, `(`, `{`), push it onto the stack.\n",
      "     - If it is a closing bracket (`>`, `]`, `)`, `}`), check if the top of the stack matches the corresponding opening bracket. If it does, pop the stack. If it does not, there is a mismatch.\n",
      "\n",
      "3. **Handle Unmatched Brackets:**\n",
      "   - After iterating through the sequence, if the stack is not empty, it means there are unmatched opening brackets. Add the corresponding closing brackets to the end of the sequence.\n",
      "   - If there are unmatched closing brackets, identify the missing opening brackets and add them at the appropriate positions.\n",
      "\n",
      "4. **Final Check:**\n",
      "   - Iterate through the completed sequence one more time to ensure all brackets are properly matched and nested.\n",
      "\n",
      "### Completing the Sequence\n",
      "\n",
      "Let's go through the sequence step-by-step:\n",
      "\n",
      "- Input sequence: `< [ ] > ( ( ( { { { { ( ( { { } } ) ) } ( { } ) } } { { { [ { ( ) } ( ) ( ( { [ < < > > ] < < > > } ) ) ] ( { } { } ) } } } } )`\n",
      "\n",
      "- Opening brackets: `< [ ( ( ( { { { { ( ( { { { [ { ( ( { [ < <`\n",
      "- Closing brackets: `] > ) ) } ) ) } ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n"
     ]
    }
   ],
   "source": [
    "print(dataset.filter(lambda x: x[\"answer_pred\"] == None)[5][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46db335657e24dba8915af9a30d67e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    find = \"Input: \"\n",
    "    index = ins[\"input\"].find(find)\n",
    "    \n",
    "    return {\n",
    "        \"target\": ins[\"input\"][index + len(find):] + \" \" + ins[\"target\"]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\\\"\")\n",
    ").replace(\" \", \"\") == y_pred_i.translate(str.maketrans(\"\", \"\", '.(),`\"\\'')).replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f67678b4274b4195fcdda24bffab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ < { { [ ] } } { < [ { { < > } } [ ( ) ( ) ] [ [ [ [ ( { < ( < ( [ ] ) > ) > } ) ] ] ] ] ] ( ) ( [ ] { } ) > } > [ { ( ( ) ) } ] }, `{ < { { [ ] } } { < [ { { < > } } [ ( ) ( ) ] [ [ [ [ ( { < ( < ( [ ] ) > ) > } ) ] ] ] ] ] ( ) ( [ ] { } ) > } > [ { ( ( ) ) } ]`.\n",
      "\n",
      "< [ ] { < ( ) > } [ ] ( { } ) >, `< [ ] { < ( ) > } [ ] ( { } ) > } )`.\n",
      "\n",
      "< ( ( ( < > ) ) ( { { } [ { } ] [ ] < ( ) > } ) ) >, < ( ( ( < > ) ) ( { { } [ { } ] [ ] < ( ) > } ) )\n",
      "\n",
      "< < < { < < > > } > < < { < ( < > ) < > [ [ [ < ( ( ) ) > [ ] [ ] ] ] ] < ( ) > ( ) [ ( [ [ ] ] ) ] > } { } { < [ < { ( { } ) } > ] > } { { } } > > > >, < < < { < < > > } > < < { < ( < > ) < > [ [ [ < ( ( ) ) > [ ] [ ] ] ] ] < ( ) > ( ) [ ( [ [ ] ] ) ] > } { } { < [ < { ( { } ) } > ] > } { { } } > >\n",
      "\n",
      "( { < [ < > ] > } ), `( { < [ < > ] > } > ] > )`.\n",
      "\n",
      "( < ( ) ( < [ ] > ( ) < [ [ { } { < > } < > ] ] > ) [ ] > [ ( < { [ ] } [ ] ( { [ < > ] < < > > ( ( < { } > ) ) } ) [ [ [ < < < ( ( ) ) > > > ] < < { [ ] } > > ( [ < > ] ) ] ] > ) ] < > ), the balanced sequence: `( < ( ) ( < [ ] > ( ) < [ [ { } { < > } < > ] ] > ) [ ] > [ ( < { [ ] } [ ] ( { [ < > ] < < > > ( ( < { } > ) ) } ) [ [ [ < < < ( ( ) ) > > > ] < < { [ ] } > > ( [ < > ] ) ] ] > ) ] < >`\n",
      "\n",
      "< ( ( [ < > { [ { ( ) } ] < { < { } > [ ( < > ) ] } > } [ < > ] ] ) { { ( { ( ( [ ( [ ] ) ] < { } > ) ) { { ( [ [ ] ] ) } [ ( ) ] { { [ ] } } } } ) } ( { } ) } ) >, < ( ( [ < > { [ { ( ) } ] < { < { } > [ ( < > ) ] } > } [ < > ] ] ) { { ( { ( ( [ ( [ ] ) ] < { } > ) ) { { ( [ [ ] ] ) } [ ( ) ] { { [ ] } } } } ) } ( { } ) } )\n",
      "\n",
      "{ ( ( ) ) { < > { ( [ [ { } ] [ ( ) ] ] ) } [ { { { ( < [ ] > ) } { < > } } } ] } }, the input sequence itself: `{ ( ( ) ) { < > { ( [ [ { } ] [ ( ) ] ] ) } [ { { { ( < [ ] > ) } { < > } } } ]`.\n",
      "\n",
      "< ( < > ) { < < { ( ( ) { { { < > { } } [ < > ] ( ) } } ( ( ) ) ) < [ { { ( ( < > ) ) } } [ { < { } > } ] ( ) ] > } { [ ] } > > [ ] } > ( [ ] ) [ < { ( ( ( ) ( ) ) ) ( ) } > ] [ < ( ) > ], None\n",
      "\n",
      "{ [ [ ] [ ] ] }, `{ [ [ ] [ ] ] ] }`.\n",
      "\n",
      "( < [ < ( [ ( ) ] < > < ( { } ) > ) < [ ] > > ] ( ) < [ < > ] > > ), \"( < [ < ( [ ( ) ] < > < ( { } ) > ) < [ ] > > ] ( ) < [ < > ] > )\".\n",
      "\n",
      "( < < > > [ [ [ { { < { } ( { } ) > } } < { { { } } } < > > ] ] ( ) ] ), `( < < > > [ [ [ { { < { } ( { } ) > } } < { { { } } } < > > ] ] ( )`.\n",
      "\n",
      "( { ( ( { } ) ) } ( ) ) < { ( ) } >, `( { ( ( { } ) ) } ( ) ) < { ( ) }`.\n",
      "\n",
      "< ( { [ { } ] } [ ] [ ] ) >, `< ( { [ { } ] } [ ] [ ] ) ]`.\n",
      "\n",
      "{ { [ ( [ { ( { ( [ ( [ ] ) { ( < < [ ] > [ [ ] ] > ) } ] ) [ ] } ) } ] ) ] } { < [ ] > } ( ) }, `{ { [ ( [ { ( { ( [ ( [ ] ) { ( < < [ ] > [ [ ] ] > ) } ] ) [ ] } ) } ] ) ] } { < [ ] > } ( )`.\n",
      "\n",
      "{ [ < [ ] > ] } { ( ) [ < > ] [ [ [ ] ] ] }, `{ [ < [ ] > ] } { ( ) [ < > ] [ [ [ ] ] } ]`.\n",
      "\n",
      "[ < [ { ( < ( ( [ < < { } > < < [ ( { < < > > } ) ] > > > ] { } ) ) > ) } ] [ < < { } > ( < < ( ) < ( [ ] ) > > ( ( ) ) > ) > ] > ] < < { } > >, `[ < [ { ( < ( ( [ < < { } > < < [ ( { < < > > } ) ] > > > ] { } ) ) > ) } ] [ < < { } > ( < < ( ) < ( [ ] ) > > ( ( ) ) > ) > ] > ] < < { } > > ]`.\n",
      "\n",
      "[ < [ ] > ], `[ < [ ] ] > ]`.\n",
      "\n",
      "{ { [ < > ] } < [ ( [ { } ] ) ] > < [ < > { } ] < ( [ ] ) > < > > }, `{ { [ < > ] } < [ ( [ { } ] ) ] > < [ < > { } ] < ( [ ] ) > < } >>`.\n",
      "\n",
      "{ ( { [ ( ) ] } { { [ ] } } { } < > ) } [ < [ ( ) ] > ], `{ ( { [ ( ) ] } { { [ ] } } { } < > ) } [ < [ ( ) ] ] >`.\n",
      "\n",
      "{ ( < { < ( ) > } > ) }, `{ ( < { < ( ) > } > } ) >`.\n",
      "\n",
      "< ( ) >, `< ( ) ( )`.\n",
      "\n",
      "{ < ( ) > { < > } ( < > ) < ( ) > [ ] < < < < ( ( ) ) < ( ) > > > > > { } }, { < ( ) > { < > } ( < > ) < ( ) > [ ] < < < < ( ( ) ) < ( ) > > > > > { ) ) > }\n",
      "\n",
      "[ { { } } ] ( < { < [ ( ( ) ) ] > } > ), `[ { { } } ] ( < { < [ ( ( ) ) ] > } > ]`.\n",
      "\n",
      "{ ( [ ] ) } [ ] ( { < > } ( { } ( { { } } ) ) ( [ ] ) ( ) ( < ( { { ( < { [ ( ) ] } > ) } } [ < [ ( [ { } ] [ < > < < > > ] ) ] > ] { < { } > } < > ) > ) ), The sequence is already balanced.\n",
      "\n",
      "( [ < < > [ [ < > ] ] > ] ( < < < ( [ [ ] ] ) [ ( ( [ { { } } ] ) ) ] > > > ) ), `( [ < < > [ [ < > ] ] > ] ( < < < ( [ [ ] ] ) [ ( ( [ { { } } ] ) ) ] > > ))`.\n",
      "\n",
      "{ < [ ] > ( { [ ] } < > ) }, `{ < [ ] > ( { [ ] } < > } ) } >`.\n",
      "\n",
      "[ < [ [ < > ] ] < ( ) > [ { } ] < [ [ ] ] > ( ) < { < [ ] < < [ [ { [ ] } ] ] > > ( [ ( ( ) ) ] ) > } > [ { { < > } } ] > < ( < { } { [ { [ ] } ] } > ) > ], the sequence is already complete and balanced.\n",
      "\n",
      "( { ( ) { [ ] { ( ( { < > } ) ) ( < < > < > > < ( ( ) ) > ) } < ( < < < { } > > > ) > } } ), the sequence is already balanced and complete.\n",
      "\n",
      "< [ { { [ [ [ < ( < [ ] { [ ( [ ] ) ] [ ] < > } > ) > ] ( [ ] ) ] ] } } ] >, `< [ { { [ [ [ < ( < [ ] { [ ( [ ] ) ] [ ] < > } > ) > ] ( [ ] ) ] ] } } ] ) ] } > ) > ] ) ] } }`.\n",
      "\n",
      "< { [ ] } > ( ) < [ [ { [ [ ] ] } ] ] ( ) [ < ( [ { } ] ) > ( ( ) ) ] >, < { [ ] } > ( ) < [ [ { [ [ ] ] } ] ] ( ) [ < ( [ { } ] ) > ( ( ) ) ]\n",
      "\n",
      "< { < { [ < { ( [ ] ) } > { ( { } ) } ( ) ] } > } [ < < > > ] { } [ ] < { } > >, `< { < { [ < { ( [ ] ) } > { ( { } ) } ( ) ] } > } [ < < > > ] { } [ ] < { } > } ] ) > >`.\n",
      "\n",
      "[ < [ ] { { } { < ( { } ) > } } > ] ( { } ), `[ < [ ] { { } { < ( { } ) > } } > ] ( { } ) ]`.\n",
      "\n",
      "< { < > } { ( ) } >, `>}`.\n",
      "\n",
      "[ [ < < { } > > ] ], \\[ [ [ < < { } > ] ] > > \\]\n",
      "\n",
      "< ( ( ) ) >, `< ( ( ) )`.\n",
      "\n",
      "[ < < > > < ( < < < [ [ [ [ ] ] ] ] > > > ) [ < < [ ] > > ] { [ < > ] < > [ ( ) ] } { [ ] } > ], [ < < > > < ( < < < [ [ [ [ ] ] ] ] > > > ) [ < < [ ] > > ] { [ < > ] < > [ ( ) ] } { [ ] >>>>\n",
      "\n",
      "{ < < > ( [ [ { ( ( [ ] < > ) ) } ] { [ [ ] { } { [ { < > } ] } ( { { { { } } } } ) ] } ] ) ( ) > }, `{ < < > ( [ [ { ( ( [ ] < > ) ) } ] { [ [ ] { } { [ { < > } ] } ( { { { { } } } } ) ] } ] ) }`.\n",
      "\n",
      "[ ( ( { < ( { } ) > } ) ) ], `( ( { < ( { } ) > } ) ) ) }`.\n",
      "\n",
      "{ ( [ { ( < [ { ( ) { } } ] > ) < > } ] ) }, `{ ( [ { ( < [ { ( ) { } } ] > ) < > } ] ) } > ]`.\n",
      "\n",
      "[ { [ { ( < < < < > { } > { [ { } ] } > > ) } ] [ ] } ] [ < { { } } [ [ ( ( ) ) ] ] > ] [ ( ( [ ] ) ) ], `[ { [ { ( < < < < > { } > { [ { } ] } > > ) } ] [ ] } ] [ < { { } } [ [ ( ( ) ) ] ] > ] [ ( ( [ ] ) ) ] ]`.\n",
      "\n",
      "< { < ( ) ( ( < > < ( ( < < > > ) ) { ( ) } > ) ) { { } } > } >, the sequence is already balanced and properly closed.\n",
      "\n",
      "[ { [ < [ < { } > ] [ ] > ] } ], `[ { [ < [ < > > ] > ] ] [ ] > } ] } ]`.\n",
      "\n",
      "< < [ ( < [ ( { [ ( ) ] [ ( ( { [ ] } ) ) ] } ) ] > ) ] < > > >, `< < [ ( < [ ( { [ ( ) ] [ ( ( { [ ] } ) ) ] } ) ] > ) ] > >`.\n",
      "\n",
      "< { { } } ( < [ ] [ { } ] > ) ( { { } { { ( ) } } } ) { < { { [ ] } [ ( ) ] } ( < { [ < > ] } > ) < ( [ ] { ( < < [ ] > > ) [ { [ [ ( ( ) ) ] ] } ] } { } ) > ( { { [ [ ( ) ] ] } } ) > } >, < { { } } ( < [ ] [ { } ] > ) ( { { } { { ( ) } } } ) { < { { [ ] } [ ( ) ] } ( < { [ < > ] } > ) < ( [ ] { ( < < [ ] > > ) [ { [ [ ( ( ) ) ] ] } ] } { } ) > ( { { [ [ ( ) ] ] } } )\n",
      "\n",
      "[ ] { ( { < > } ) } [ ( ) ] { } [ { { ( < > ) } < > } ], `[ ] { ( { < > } ) } [ ( ) ] { } [ { { ( < > ) } < ] >`.\n",
      "\n",
      "{ [ { [ ] } ] } [ [ { { } } [ < > ] ] ], `{ [ { [ ] } ] } [ [ { { } } [ < > ] ]`.\n",
      "\n",
      "[ { ( < [ [ ] ] > ) } ], `[ { ( < [ [ ] ] > ) ] } ) >`.\n",
      "\n",
      "< [ ( { { ( ( ) ) } } ) [ ( [ { } ] ) ] < { { < < < > [ < [ < ( [ ( { ( ( < < < < > > > { ( { { < ( ) > ( ) } } ) } > { } ) ) } ) ] ) > ] > ] > < { } > > } ( ) < { ( ) } > } > ] [ < ( ) > ] >, `< [ ( { { ( ( ) ) } } ) [ ( [ { } ] ) ] < { { < < < > [ < [ < ( [ ( { ( ( < < < < > > > { ( { { < ( ) > ( ) } } ) } > { } ) ) } ) ] ) > ] > ] > < { } > > } ( ) < { ( ) } > } > ] [ < ( ) > ]`\n",
      "\n",
      "{ [ { { { } } } ] }, `{ [ { { { } } } } } ]`.\n",
      "\n",
      "[ ( ) ], ( ).\n",
      "\n",
      "[ ( < [ [ { [ < [ < ( [ ] ) > ] < > > ( < [ < [ < ( [ ( [ ] ) < ( ) > ] [ ( { ( ) } [ < { { { ( [ ] ) } } } > ] ) ] ) > ] > ] > ) ] } ] ] > ) ( { { { } } } ) ], ( < [ [ { [ < [ < ( [ ] ) > ] < > > ( < [ < [ < ( [ ( [ ] ) < ( ) > ] [ ( { ( ) } [ < { { { ( [ ] ) } } } > ] ) ] ) > ] > ] > ) ] } ] ] > ) ( { { { } } }\n",
      "\n",
      "{ [ [ < > ] ( ) ] }, `{ [ [ < > ] ( ) ] ] }`.\n",
      "\n",
      "< ( ) ( { { [ ] } } ) >, `< ( ) ( { { [ ] } } } ) >`.\n",
      "\n",
      "[ < [ [ ( ) ( ( { < { < { { } } > } > } ) ) ] ] > ( ) { ( ) } ], `[ < [ [ ( ) ( ( { < { < { { } } > } > } ) ) ] ] > ( ) { ( ) }`.\n",
      "\n",
      "( < > [ { [ [ ( [ ] ) [ < ( < > ) { [ ( { ( [ ( ( < ( ( < [ ] { < > } > [ ] ) ) > ) [ { } ] ) ] ) } ) ] } > ] ] ] } [ ] ] ) < [ ] >, ( < > [ { [ [ ( [ ] ) [ < ( < > ) { [ ( { ( [ ( ( < ( ( < [ ] { < > } > [ ] ) ) > ) [ { } ] ) ] ) } ) ] } > ] ] ] } [ ] ] ) < [\n",
      "\n",
      "{ { < { < > } > } [ ( < < > > ) [ { < ( ) > } ] ] [ ] } < ( { [ < [ { [ ( ) ] } ] > < { ( [ [ [ { } < > { ( < { [ ] } > ( ) ) } ] ] ] ) } > ] } ) >, { { < { < > } > } [ ( < < > > ) [ { < ( ) > } ] ] [ ] } < ( { [ < [ { [ ( ) ] } ] > < { ( [ [ [ { } < > { ( < { [ ] } > ( ) ) } ] ] ] ) } > ] } )\n",
      "\n",
      "( ) ( [ [ ] ] ) ( { [ { < { ( ) < [ [ < > { [ ( < ( < [ { < < ( [ ( ) ] [ ( < ( { [ ] } ) > ) ] [ < > ] ) > [ { ( < > ) } ] > } ] > ) > ) ] } ] ] > { } [ [ ] ] { } } > ( ( < > ) ) } ] } ), None\n",
      "\n",
      "[ < < > > ], `< < > >`.\n",
      "\n",
      "( ) [ ( [ < { { ( { } ) } } > ] ) ], `( ) [ ( [ < { { ( { } ) } } ] ] >`.\n",
      "\n",
      "( < ( [ < < [ ] > > ] ) > ), `( < ( [ < < [ ] > > ] )`.\n",
      "\n",
      "[ ] { [ [ < { { { } } } > ] ] < [ { } ] > }, `[ ] { [ [ < { { { } } } > ] ] < [ { } ] } >`.\n",
      "\n",
      "( { { { { { < < ( { ( { { < < [ < [ [ ] ] > ] [ ] > [ [ ] ] > ( < [ { < > < [ ] > } ] > ) } } ) } ) > > } } } } } ), `( { { { { { < < ( { ( { { < < [ < [ [ ] ] > ] [ ] > [ [ ] ] > ( < [ { < > < [ ] > } ] > ) } } ) } ) > > } } } )`.\n",
      "\n",
      "{ ( < [ < > ] > ) }, `{ ( < [ < > ] ) }`.\n",
      "\n",
      "{ ( < > ) } ( ( [ ] ) < [ ( [ [ ] ] [ { } ] { } [ < { [ ] } > ] ( ) ) ] > ), `{ } ( ( [ ] ) < [ ( [ [ ] ] [ { } ] { } [ < { [ ] } > ] ( ) ) ]`.\n",
      "\n",
      "< { < [ [ ( { } ) ] ] > } >, `< { < [ [ ( { } ) ] ] > } > ] ]`.\n",
      "\n",
      "[ < ( [ ] ) > ] { [ { } ] }, `[ < ( [ ] ) > ] { [ { } } ]`.\n",
      "\n",
      "( { [ { [ ] { [ [ ] ] } { ( ) } } { [ [ ( [ ] ) ] ] } ] } { < ( ) { [ [ ( ) { [ { { } } ] < > { < ( < { ( < ( [ ] ) > ) } > ) { [ ( < ( ) > ) ] } [ ] { } > } ( ) } ] [ ( ( { < > } ) ) ] ] } > } ), the input sequence itself, as it is already properly closed:\n",
      "\n",
      "{ { { < > } } < > < { { ( ) } } > { } } { < ( { [ < > ] [ ( ) < ( ) > { < ( ( ( ) ) ) > [ ] } ] < > ( < { } > ) } ) > }, the input sequence is already balanced.\n",
      "\n",
      "[ < > { < [ ] > } ], `[ < > { < [ ] > } > ]`.\n",
      "\n",
      "{ [ [ < ( < { } > ) > ] ] [ [ ] ] }, `{ [ [ < ( < { } > ) > ] ] [ [ ] ] >`.\n",
      "\n",
      "< < { { { < [ ( < > { ( ) } ) ] > } } } > >, `< < { { { < [ ( < > { ( ) } ) ] > } } } > > >`.\n",
      "\n",
      "[ ( ) < > ], `[ ( ) < ] >`.\n",
      "\n",
      "[ { ( { [ < ( < [ ( ) ] > ) > ] } ) } ] [ ] [ ( { ( ) } ) ] < { ( ( ( ( ( < > ) ) ) ) ) [ < [ ( < > ) ] > [ [ ] ( ( { } { [ { < [ ] > } ] } < { } > < [ < > ] > [ ] ) ) ] ] } > { [ { ( ) } ] }, `[ { ( { [ < ( < [ ( ) ] > ) > ] } ) } ] [ ] [ ( { ( ) } ) ] < { ( ( ( ( ( < > ) ) ) ) ) [ < [ ( < > ) ] > [ [ ] ( ( { } { [ { < [ ] > } ] } < { } > < [ < > ] > [ ] ) ) ] ] } > { [ { ( )`\n",
      "\n",
      "( { < { { [ ] } < > [ ] } [ [ [ < [ [ ] ] > ] ] ] > } [ ] { { { { [ { } ] } ( < [ [ [ ] ] ] > ) < < ( { ( [ ] ) [ { { } } ] { [ ] } } ) [ [ { [ [ { ( { } ) [ ( ) { } ] { } } ] ] < > } ] ] > > } } } ), `( { < { { [ ] } < > [ ] } [ [ [ < [ [ ] ] > ] ] ] > } [ ] { { { { [ { } ] } ( < [ [ [ ] ] ] > ) < < ( { ( [ ] ) [ { { } } ] { [ ] } } ) [ [ { [ [ { ( { } ) [ ( ) { } ] { } } ] ] < > } ] ] > > } )`.\n",
      "\n",
      "< ( ) >, `< ()`.\n",
      "\n",
      "{ [ < { < ( ( ) ) > } > ] }, `{ [ < { < ( ( ) ) > } > }`.\n",
      "\n",
      "[ ] [ ( [ [ ( ) ] ] ) < < [ ] > > < < > > ], `[ ] [ ( [ [ ( ) ] ] ) < < [ ] > > < < > >`.\n",
      "\n",
      "( { } ) { ( [ { ( ) } ] ( [ ] ) ) }, the input sequence itself: `( { } ) { ( [ { ( ) } ] ( [ ] ) )`.\n",
      "\n",
      "[ < > { { { } } { } } ] < { } [ { [ ] } ] >, `[ < > { { { } } { } } ] < { } [ { [ ] } ] > } ] ]`.\n",
      "\n",
      "< ( < { [ { } < ( { ( < < < { [ ( [ ( [ { { < [ { } < ( ) > ] > } } ] ) ] ) ] } > < > > ( ( < { } > ) ) > ) } ) > ] } > ) >, `< ( < { [ { } < ( { ( < < < { [ ( [ ( [ { { < [ { } < ( ) > ] > } } ] ) ] ) ] } > < > > ( ( < { } > ) ) > ) } ) > ] } > ) } ) > ) > ) > > > } ] ) > ) } > )`.\n",
      "\n",
      "< { [ < > ] ( ( ( ( { { } } ) ) ) ) } >, `< { [ < > ] ( ( ( ( { { } } ) ) ) ) } )`.\n",
      "\n",
      "[ < < [ [ ] ( ) { < > ( [ { } { < > } { } ] ) } [ [ [ ( [ ( ) [ [ { < [ { { } } < { { < ( ) > } } > ] > } ] ] ] ) ] < < [ [ ( < < ( ) > > ) ] ] > > [ ] ] ] ] < ( [ ] ) > { ( ( < { } > ) ) } > > ], the sequence is already balanced.\n",
      "\n",
      "[ ] < { < > } > { ( ) }, `[ ] < { < > } > { ( > } )`.\n",
      "\n",
      "< > < { { { [ ( ) ] } } } > ( { [ { ( [ ] { } ) } ] } ), `< > < { { { [ ( ) ] } } } > ( { [ { ( [ ] { } ) } ] >`.\n",
      "\n",
      "{ ( { { { < ( < ( [ < < > > ] < > ) > ) > } [ ] } } ) }, `{ ( { { { < ( < ( [ < < > > ] < > ) > ) > } [ ] } } } }`.\n",
      "\n",
      "{ < { { } } > } < { } > { < { { [ < [ [ ] ] > ] } } > } ( ) { { [ { [ { } ] } ] ( [ { } ] ) } }, `{ { [ { [ { } ] } ] ( [ { } ] ) } } ] } )`.\n",
      "\n",
      "( ( < < < ( ( ) ) ( [ ] ) > > { [ ] } > ) ), `( ( < < < ( ( [ { [ ] } ) ) > > ) )`.\n",
      "\n",
      "[ < { { } } > ], `[ < { { } } ] >`.\n",
      "\n",
      "< < < > > >, `< < < > >`.\n",
      "\n",
      "[ < { [ ] } > ], `[ < { [ ] } ] >`.\n",
      "\n",
      "[ [ < [ [ ] ] > ] ] { } { ( { ( ( ) ) ( ) { { [ [ ( { < { [ { [ ( < ( ( < < < [ ( ) ] [ ] > > > ) ) > < [ < { < ( ) > } > ] > ) ] } ] } > ( ( ) ) } ) [ ( ) ] ] ( < > ) ] } } } ) } [ ], None\n",
      "\n",
      "< [ { { < ( ) > { < { } > ( < ( ) > { < [ ( { { ( < [ ] > ) } } { ( ( [ [ { } [ ] ] ] ) ) } ) ] > } ) } } } ] >, `< [ { { < ( ) > { < { } > ( < ( ) > { < [ ( { { ( < [ ] > ) } } { ( ( [ [ { } [ ] ] ] ) ) } ) ] > } ) } } > ] } }`.\n",
      "\n",
      "[ < [ ( [ < > ] { < > } [ [ ] ] ) ] > ], `[ < [ ( [ < > ] { < > } [ [ ] ] ) ] ]`.\n",
      "\n",
      "{ } < { } < > ( ) >, `{ } < { } < > ( ) > }`.\n",
      "\n",
      "{ < { } > { ( ) } }, `{ < { } > { ( ) } > }`.\n",
      "\n",
      "( [ [ { < > { } { } < < < < { } > > ( < ( ( ) ) [ ( [ ] ) ] > ) > > { } } [ < < > > ] < ( ) > ] ] ), None\n",
      "\n",
      "{ { { } } }, `{ { { } } } }`.\n",
      "\n",
      "( ( { < { < { < > } > } > } ) ( ) ( { [ ( < ( < < { ( { < > } ) } > > ) > ) { ( { < ( { [ ] } ( ) ) > } < { < { { ( ) } } > { < [ { ( ) } ] > } } > ) } [ [ ( ) ] ] ] } ) ), the completed sequence with properly closed parentheses.\n",
      "\n",
      "( < > ( [ ( ) ] ) ), `( < > ( [ ( ) ] ) ) > < )`.\n",
      "\n",
      "( < { ( ) { } } ( < > ) > ), `( < { ( ) { } } ( < > ) > ) >`.\n",
      "\n",
      "( < < < > > > ), `( < < < > )`.\n",
      "\n",
      "< < [ ( ) ] > >, `< < [ ( ) ] > > >`.\n",
      "\n",
      "< ( [ [ [ [ ( ) ] ] { } ] ] ) >, `< ( [ [ [ [ ( ) ] ] { } ] ] ) ] >`.\n",
      "\n",
      "< ( ( ( [ { } ] ) ) ) >, ( ( ( [ { } ] ) ))\n",
      "\n",
      "[ < ( < < > [ ] ( ) > ) > ], `[ < ( < < > > ) > ]`.\n",
      "\n",
      "[ { < > < [ ] > [ < { } > ] [ ( { } ) ] [ ] [ ( ) ] ( ) < { { < { { { { { ( { } ) } ( { < > } ) } } } } > } } > } ], [ { < > < [ ] > [ < { } > ] [ ( { } ) ] [ ] [ ( ) ] ( ) < { { < { { { { { ( { } ) } ( { < > } ) } } } } > } }\n",
      "\n",
      "[ [ < [ ( [ < [ ] > ] ) ] > ] ( { } ) ], `[ [ < [ ( [ < [ ] > ] ) ] > ] ( { } ] ]`.\n",
      "\n",
      "{ ( { { < { < > } > } < { } > < < < [ < [ ] > ] > > > } ) }, `{ ( { { < { < > } > } < { } > < < < [ < [ ] > ] > > > ] } > > >`.\n",
      "\n",
      "{ [ < [ < { < { } > } > ( ( < { [ ] } > { { } } ) { } ) ] > ] }, `{ [ < [ < { < { } > } > ( ( < { [ ] } > { { } } ) { } ) ] > ]`.\n",
      "\n",
      "( ( < { [ [ { [ [ ( [ < < > > ( ( [ ( ) ( { ( < [ ] > ) } ) ] ) ) ] ) ] ( ) ] } { [ [ ] ] } ] ] } > [ { < > } ] ) ), None\n",
      "\n",
      "{ { [ { < { } > } ( ) ] } }, `{ { [ { < { } > } ( ) ] } } ] > )`.\n",
      "\n",
      "< [ ] > ( ( ( { { { { ( ( { { } } ) ) } ( { } ) } } { { { [ { ( ) } ( ) ( ( { [ < < > > ] < < > > } ) ) ] ( { } { } ) } } } } ) ) ), None\n",
      "\n",
      "{ < [ < ( < [ ] > ) < > < { } > { < > { } { { < [ < < { } [ { } ] < > > > ] < > > } < [ [ ] ] > } } > ] [ ( ) ] > } [ { ( < ( ( ( [ { } ] ) ) ) > ) } ] [ < ( ) ( ( { ( ) [ { { ( { } ) } } ] } ) ) > ], the properly closed sequence: `{ < [ < ( < [ ] > ) < > < { } > { < > { } { { < [ < < { } [ { } ] < > > > ] < > > } < [ [ ] ] > } } > ] [ ( ) ] > } [ { ( < ( ( ( [ { } ] ) ) ) > ) } ] [ < ( ) ( ( { ( ) [ { { ( { } ) } } ] } ) ) >`\n",
      "\n",
      "( { } < > { < { ( < > ) } > } ), `( { } < > { < { ( < > ) } >`.\n",
      "\n",
      "< < [ ] > ( < > ) < > >, `< < [ ] > ( < > ) < >`.\n",
      "\n",
      "< [ { { [ { [ { ( ( ) ) } ] } ( < < ( < > ) > { } [ [ [ ( < { } > ) ] ] ] { } > ) ( { } ) { } ] } } ] >, < [ { { [ { [ { ( ( ) ) } ] } ( < < ( < > ) > { } [ [ [ ( < { } > ) ] ] ] { } > ) ( { } ) { } ] } ] >\n",
      "\n",
      "< [ ( [ ( ) [ < [ < > ] < > [ ] > ] < < ( ) ( ) > < { } > > [ < > ] ] ) ] >, `< [ ( [ ( ) [ < [ < > ] < > [ ] > ] < < ( ) ( ) > < { } > > [ < > ] ]`.\n",
      "\n",
      "< { ( { } ) < > } >, `< { ( { } ) < > }`.\n",
      "\n",
      "( { } ) < { < { } > } >, `( { } ) < { < { } > > } >`.\n",
      "\n",
      "[ [ < < { [ ] ( [ [ ( [ [ { [ ] } ] ] ) ( ) ] ] ) ( ) [ ] < [ ( ( ( ) ) ) ] < < < > [ ( ) ] > [ ] > > [ < > ] } > > ] ], `[ [ < < { [ ] ( [ [ ( [ [ { [ ] } ] ] ) ( ) ] ] ) ( ) [ ] < [ ( ( ( ) ) ) ] < < < > [ ( ) ] > [ ] > > [ < > ] } > >`.\n",
      "\n",
      "{ { { < { } < ( ( < > ) ) > > } } { [ [ { } ] ] [ ] < < { } > [ ( ) { ( { } ) } ] > ( [ < [ ( ( { } ( ) < > < [ < < { { ( [ { } ] ) } } { } { } > > ] > ( ) ) ) < > ] > ] ) } }, the balanced sequence:\n",
      "\n",
      "[ [ { { < ( ) > } } ] ], `[ [ { { < ( ) > } } ] ] }`.\n",
      "\n",
      "{ { ( { [ [ { < [ ] > } ] ] } ) [ ( < { < > } > ) ] } }, `{ { ( { [ [ { < [ ] > } ] ] } ) [ ( < { < > } > ) ] ] ) } }`.\n",
      "\n",
      "( ( ( ( [ [ < [ { { [ ] } } ] > ] ] ( ) ) ) ) ), `()`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formal_fallacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'formal_fallacies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-formal_fallacies/bbh-formal_fallacies_eval')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify Key Assumptions\": {\n",
      "        \"Description\": \"List the underlying assumptions about the relationships between supporters, experts, and backers of different football clubs as stated in the problem.\",\n",
      "        \"Action\": \"Extract and list all assumptions from the given premises.\",\n",
      "        \"Assumptions\": [\n",
      "            \"Every supporter of Tottenham Hotspur is not an expert of Trabzonspor AŞ and not a backer of US Sassuolo Calcio.\",\n",
      "            \"Every backer of US Sassuolo Calcio who is an expert of Trabzonspor AŞ is a supporter of Tottenham Hotspur or a devotee of FC Zenit.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 2: Critical Analysis\": {\n",
      "        \"Description\": \"Analyze the argument from different perspectives, question the assumptions made about the supporters' relationships, and evaluate the logical consistency of the given statements.\",\n",
      "        \"Action\": \"Question each assumption and evaluate the logical consistency of the statements.\",\n",
      "        \"Analysis\": [\n",
      "            \"The first premise states a clear exclusion of supporters of Tottenham Hotspur from being experts of Trabzonspor AŞ and backers of US Sassuolo Calcio.\",\n",
      "            \"The second premise introduces a conditional relationship involving backers of US Sassuolo Calcio who are experts of Trabzonspor AŞ.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 3: Define Core Problem\": {\n",
      "        \"Description\": \"Identify the main question that needs to be answered: Is the argument deductively valid or invalid based on the given premises?\",\n",
      "        \"Action\": \"Clearly state the core problem to be solved.\",\n",
      "        \"Core Problem\": \"Determine if the conclusion 'everyone who is not both an expert of Trabzonspor AŞ and a backer of US Sassuolo Calcio is a devotee of FC Zenit' logically follows from the premises.\"\n",
      "    },\n",
      "    \"Step 4: Decision-Making Under Uncertainty\": {\n",
      "        \"Description\": \"Determine if the problem involves making a decision about the validity of the argument despite the complexity of the relationships described.\",\n",
      "        \"Action\": \"Assess the complexity and uncertainty involved in the argument.\",\n",
      "        \"Assessment\": \"The argument involves complex relationships between different groups of supporters, experts, and backers, which introduces uncertainty.\"\n",
      "    },\n",
      "    \"Step 5: Logical Analysis\": {\n",
      "        \"Description\": \"Break down the logical structure of the argument and assess its validity through logical reasoning techniques.\",\n",
      "        \"Action\": \"Apply logical reasoning techniques to evaluate the argument.\",\n",
      "        \"Logical Analysis\": [\n",
      "            \"Premise 1: If someone is a supporter of Tottenham Hotspur, they are not an expert of Trabzonspor AŞ and not a backer of US Sassuolo Calcio.\",\n",
      "            \"Premise 2: If someone is a backer of US Sassuolo Calcio and an expert of Trabzonspor AŞ, they are either a supporter of Tottenham Hotspur or a devotee of FC Zenit.\",\n",
      "            \"Conclusion: If someone is not both an expert of Trabzonspor AŞ and a backer of US Sassuolo Calcio, they are a devotee of FC Zenit.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 6: Step-by-Step Reasoning\": {\n",
      "        \"Description\": \"Break down the argument into smaller, manageable steps to evaluate its logical consistency.\",\n",
      "        \"Action\": \"Divide the argument into smaller steps and analyze each step.\",\n",
      "        \"Steps\": [\n",
      "            \"Step 1: Identify the groups defined by the premises.\",\n",
      "            \"Step 2: Analyze the logical implications of each premise.\",\n",
      "            \"Step 3: Evaluate if the conclusion logically follows from the premises.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 7: Implement Step-by-Step Plan\": {\n",
      "        \"Description\": \"Create a detailed plan to analyze each premise and the conclusion, ensuring each step is clearly explained and logically sound.\",\n",
      "        \"Action\": \"Develop a detailed plan to analyze each premise and the conclusion.\",\n",
      "        \"Plan\": [\n",
      "            \"Analyze Premise 1: Determine the implications for supporters of Tottenham Hotspur.\",\n",
      "            \"Analyze Premise 2: Determine the implications for backers of US Sassuolo Calcio who are experts of Trabzonspor AŞ.\",\n",
      "            \"Analyze Conclusion: Determine if the conclusion logically follows from the premises.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 8: Analyze Premise 1\": {\n",
      "        \"Description\": \"Analyze the first premise: 'Every supporter of Tottenham Hotspur is not an expert of Trabzonspor AŞ and not a backer of US Sassuolo Calcio.'\",\n",
      "        \"Action\": \"Evaluate the logical implications of the first premise.\",\n",
      "        \"Implications\": \"Supporters of Tottenham Hotspur are excluded from being experts of Trabzonspor AŞ and backers of US Sassuolo Calcio.\"\n",
      "    },\n",
      "    \"Step 9: Analyze Premise 2\": {\n",
      "        \"Description\": \"Analyze the second premise: 'Every backer of US Sassuolo Calcio who is an expert of Trabzonspor AŞ is a supporter of Tottenham Hotspur or a devotee of FC Zenit.'\",\n",
      "        \"Action\": \"Evaluate the logical implications of the second premise.\",\n",
      "        \"Implications\": \"Backers of US Sassuolo Calcio who are experts of Trabzonspor AŞ must be either supporters of Tottenham Hotspur or devotees of FC Zenit.\"\n",
      "    },\n",
      "    \"Step 10: Analyze Conclusion\": {\n",
      "        \"Description\": \"Analyze the conclusion: 'In consequence, everyone who is not both an expert of Trabzonspor AŞ and a backer of US Sassuolo Calcio is a devotee of FC Zenit.'\",\n",
      "        \"Action\": \"Evaluate the logical implications of the conclusion.\",\n",
      "        \"Implications\": \"The conclusion states that anyone not fitting the specific criteria of being both an expert of Trabzonspor AŞ and a backer of US Sassuolo Calcio is a devotee of FC Zenit.\"\n",
      "    },\n",
      "    \"Step 11: Evaluate Logical Consistency\": {\n",
      "        \"Description\": \"Evaluate the logical consistency between the premises and the conclusion.\",\n",
      "        \"Action\": \"Determine if the conclusion logically follows from the premises.\",\n",
      "        \"Consistency\": \"The conclusion does not logically follow from the premises. The premises do not provide sufficient information to support the conclusion that everyone not fitting the specific criteria is a devotee of FC Zenit.\"\n",
      "    },\n",
      "    \"Step 12: Determine Validity\": {\n",
      "        \"Description\": \"Determine if the argument is deductively valid or invalid based on the analysis.\",\n",
      "        \"Action\": \"Conclude whether the argument is valid or invalid.\",\n",
      "        \"Validity\": \"The argument is invalid.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is invalid.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 191136.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "valid, invalid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\"\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n",
      "invalid, valid.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.728"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geometric_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'geometric_shapes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-geometric_shapes/bbh-geometric_shapes_eval')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Understand the SVG Path\": {\n",
      "        \"Description\": \"Identify the SVG path commands and coordinates provided in the path element.\",\n",
      "        \"Action\": \"Break down the SVG path commands into smaller, understandable segments.\",\n",
      "        \"Result\": \"The SVG path commands are: M 22.00,62.00 L 46.00,65.00 L 64.00,60.00 L 91.00,42.00 L 92.00,24.00 L 46.00,19.00 L 22.00,62.00\"\n",
      "    },\n",
      "    \"Step 2: Simplify the SVG Path Data\": {\n",
      "        \"Description\": \"Simplify the SVG path data to make it easier to identify the shape.\",\n",
      "        \"Action\": \"Remove any unnecessary commands or coordinates that do not affect the shape.\",\n",
      "        \"Result\": \"The simplified SVG path commands are: M 22,62 L 46,65 L 64,60 L 91,42 L 92,24 L 46,19 L 22,62\"\n",
      "    },\n",
      "    \"Step 3: Analyze the SVG Path Commands\": {\n",
      "        \"Description\": \"Analyze the SVG path commands step by step.\",\n",
      "        \"Action\": \"Interpret each command and its corresponding coordinates to understand the shape being drawn.\",\n",
      "        \"Result\": \"The path starts at (22,62), moves to (46,65), then to (64,60), (91,42), (92,24), (46,19), and finally back to (22,62), forming a closed shape with 6 points.\"\n",
      "    },\n",
      "    \"Step 4: Visual Interpretation\": {\n",
      "        \"Description\": \"Devise an experiment to visually interpret the SVG path.\",\n",
      "        \"Action\": \"Use relevant tools or software to render the SVG path and provide insights into the shape it draws.\",\n",
      "        \"Result\": \"Rendering the path visually confirms a shape with 6 vertices.\"\n",
      "    },\n",
      "    \"Step 5: Critical Thinking\": {\n",
      "        \"Description\": \"Analyze the SVG path from different perspectives and question assumptions about the shape.\",\n",
      "        \"Action\": \"Evaluate the coordinates and commands provided to ensure accuracy in shape identification.\",\n",
      "        \"Result\": \"The shape has 6 vertices and is a closed polygon, confirming it is a hexagon.\"\n",
      "    },\n",
      "    \"Step 6: Match the Shape to Options\": {\n",
      "        \"Description\": \"Compare the interpreted shape with the given options.\",\n",
      "        \"Action\": \"Determine which option best matches the shape drawn by the SVG path.\",\n",
      "        \"Result\": \"The shape matches option (C) hexagon.\"\n",
      "    },\n",
      "    \"Step 7: Conclusion\": {\n",
      "        \"Description\": \"Arrive at a conclusion based on the analysis.\",\n",
      "        \"Action\": \"Identify the correct option that represents the shape drawn by the SVG path.\",\n",
      "        \"Result\": \"The final answer is C\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 80672.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(G), J\"\n",
      "\n",
      "(C), G.\n",
      "\n",
      "(K), H.\"\n",
      "\n",
      "(G), (D) kite.\"\n",
      "\n",
      "(C), G.\n",
      "\n",
      "(I), J.\n",
      "\n",
      "(K), J.\n",
      "\n",
      "(K), J.\"\n",
      "\n",
      "(C), J\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(K), D.\n",
      "\n",
      "(B), C\"\n",
      "\n",
      "(K), I.\n",
      "\n",
      "(K), I.\"\n",
      "\n",
      "(K), I\"\n",
      "\n",
      "(D), J\"\n",
      "\n",
      "(K), D.\n",
      "\n",
      "(K), H\"\n",
      "\n",
      "(C), G.\"\n",
      "\n",
      "(K), D.\"\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(C), J\"\n",
      "\n",
      "(K), J\"\n",
      "\n",
      "(C), J\"\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(F), E\"\n",
      "\n",
      "(D), J.\"\n",
      "\n",
      "(C), G.\n",
      "\n",
      "(K), A.\n",
      "\n",
      "(K), J.\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(K), I.\n",
      "\n",
      "(K), H\"\n",
      "\n",
      "(D), J.\"\n",
      "\n",
      "(B), G.\"\n",
      "\n",
      "(C), J\"\n",
      "\n",
      "(F), G\"\n",
      "\n",
      "(K), H\"\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(G), J.\n",
      "\n",
      "(G), D.\n",
      "\n",
      "(C), J.\n",
      "\n",
      "(B), J.\n",
      "\n",
      "(K), A\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(K), D.\n",
      "\n",
      "(G), J\"\n",
      "\n",
      "(C), J\"\n",
      "\n",
      "(F), G.\n",
      "\n",
      "(D), H.\"\n",
      "\n",
      "(D), J.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(F), (J) triangle.\n",
      "\n",
      "(C), J.\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(F), G.\n",
      "\n",
      "(K), D.\"\n",
      "\n",
      "(K), I.\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(K), D.\n",
      "\n",
      "(K), I\"\n",
      "\n",
      "(C), G.\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(F), (B) heptagon.\n",
      "\n",
      "(K), I\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(G), J\"\n",
      "\n",
      "(B), J\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(G), J\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(B), D.\"\n",
      "\n",
      "(F), G\"\n",
      "\n",
      "(B), J.\n",
      "\n",
      "(K), I.\"\n",
      "\n",
      "(K), (D) kite.\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(F), B.\"\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(F), G.\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(K), D.\n",
      "\n",
      "(B), G.\n",
      "\n",
      "(F), C\"\n",
      "\n",
      "(K), D\"\n",
      "\n",
      "(B), D\"\n",
      "\n",
      "(C), G\"\n",
      "\n",
      "(C), G.\"\n",
      "\n",
      "(B), D\"\n",
      "\n",
      "(B), G\"\n",
      "\n",
      "(K), I\"\n",
      "\n",
      "(G), D\"\n",
      "\n",
      "(K), D.\"\n",
      "\n",
      "(G), J.\n",
      "\n",
      "(K), A.\n",
      "\n",
      "(K), H.\n",
      "\n",
      "(K), H\"\n",
      "\n",
      "(B), G.\"\n",
      "\n",
      "(B), J.\n",
      "\n",
      "(F), B\"\n",
      "\n",
      "(K), A.\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.588"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperbaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'hyperbaton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-hyperbaton/bbh-hyperbaton_eval')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify the Adjectives in Each Sentence\": {\n",
      "        \"Description\": \"List all the adjectives in each sentence option.\",\n",
      "        \"Action\": \"Extract adjectives from each sentence.\",\n",
      "        \"Result\": {\n",
      "            \"Sentence A\": [\"wonderful\", \"big\", \"circular\", \"orange\", \"Pakistani\", \"smoking\"],\n",
      "            \"Sentence B\": [\"circular\", \"wonderful\", \"smoking\", \"Pakistani\", \"big\", \"orange\"]\n",
      "        }\n",
      "    },\n",
      "    \"Step 2: Categorize the Adjectives\": {\n",
      "        \"Description\": \"Categorize the adjectives into different types (e.g., opinion, size, age, shape, color, origin, material, purpose).\",\n",
      "        \"Action\": \"Assign each adjective to its respective category.\",\n",
      "        \"Result\": {\n",
      "            \"Sentence A\": {\n",
      "                \"opinion\": \"wonderful\",\n",
      "                \"size\": \"big\",\n",
      "                \"shape\": \"circular\",\n",
      "                \"color\": \"orange\",\n",
      "                \"origin\": \"Pakistani\",\n",
      "                \"purpose\": \"smoking\"\n",
      "            },\n",
      "            \"Sentence B\": {\n",
      "                \"shape\": \"circular\",\n",
      "                \"opinion\": \"wonderful\",\n",
      "                \"purpose\": \"smoking\",\n",
      "                \"origin\": \"Pakistani\",\n",
      "                \"size\": \"big\",\n",
      "                \"color\": \"orange\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"Step 3: Research Adjective Order Rules\": {\n",
      "        \"Description\": \"Consult linguistic resources to understand the conventional order of adjectives.\",\n",
      "        \"Action\": \"Gather information from linguistic sources on the standard adjective order.\",\n",
      "        \"Result\": \"The standard order of adjectives is: opinion, size, age, shape, color, origin, material, purpose.\"\n",
      "    },\n",
      "    \"Step 4: Simplify Sentence Structures\": {\n",
      "        \"Description\": \"Simplify the sentence structures to make the adjective order more apparent.\",\n",
      "        \"Action\": \"Rewrite the sentences with simplified structures focusing on adjective order.\",\n",
      "        \"Result\": {\n",
      "            \"Sentence A\": \"wonderful big circular orange Pakistani smoking car\",\n",
      "            \"Sentence B\": \"circular wonderful smoking Pakistani big orange car\"\n",
      "        }\n",
      "    },\n",
      "    \"Step 5: Evaluate Each Adjective According to Established Rules\": {\n",
      "        \"Description\": \"Evaluate each adjective in the sentences one by one according to the established adjective order rules.\",\n",
      "        \"Action\": \"Compare the order of adjectives in each sentence with the standard order.\",\n",
      "        \"Result\": {\n",
      "            \"Sentence A\": \"Follows the standard order: opinion (wonderful), size (big), shape (circular), color (orange), origin (Pakistani), purpose (smoking).\",\n",
      "            \"Sentence B\": \"Does not follow the standard order: shape (circular), opinion (wonderful), purpose (smoking), origin (Pakistani), size (big), color (orange).\"\n",
      "        }\n",
      "    },\n",
      "    \"Step 6: Analyze from Different Linguistic Perspectives\": {\n",
      "        \"Description\": \"Analyze the adjective order from different linguistic perspectives and question assumed rules.\",\n",
      "        \"Action\": \"Consider multiple linguistic viewpoints to evaluate the adjective order.\",\n",
      "        \"Result\": \"The standard order is widely accepted and follows a logical sequence.\"\n",
      "    },\n",
      "    \"Step 7: Break Down the Problem into Smaller Parts\": {\n",
      "        \"Description\": \"Break down the adjective order problem into smaller parts, such as categories of adjectives.\",\n",
      "        \"Action\": \"Focus on each category of adjectives separately to ensure correct order.\",\n",
      "        \"Result\": \"Each category in Sentence A follows the correct order, while Sentence B does not.\"\n",
      "    },\n",
      "    \"Step 8: Apply Linguistic Models and Rules\": {\n",
      "        \"Description\": \"Apply specific linguistic rules or models to determine the correct adjective order.\",\n",
      "        \"Action\": \"Use linguistic models to evaluate the adjective order in each sentence.\",\n",
      "        \"Result\": \"Sentence A adheres to the linguistic rules, while Sentence B does not.\"\n",
      "    },\n",
      "    \"Step 9: Compare Sentences\": {\n",
      "        \"Description\": \"Compare the adjective order in each sentence option to determine which one follows the correct order.\",\n",
      "        \"Action\": \"Compare the adjective order in (A) and (B) based on the established rules.\",\n",
      "        \"Result\": \"Sentence A follows the correct adjective order, while Sentence B does not.\"\n",
      "    },\n",
      "    \"Step 10: Conclude the Correct Sentence\": {\n",
      "        \"Description\": \"Determine which sentence has the correct adjective order based on the analysis.\",\n",
      "        \"Action\": \"Identify the sentence with the correct adjective order.\",\n",
      "        \"Result\": \"The final answer is A\"\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 321550.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\"\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.944"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logical_deduction_five_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'logical_deduction_five_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-logical_deduction_five_objects/bbh-logical_deduction_five_objects_eval')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify Given Relationships\": {\n",
      "        \"Description\": \"List all the given relationships between the fruits.\",\n",
      "        \"Action\": \"Extract and list the comparative statements from the problem.\",\n",
      "        \"Value\": [\n",
      "            \"Watermelons are more expensive than cantaloupes.\",\n",
      "            \"Mangoes are less expensive than pears.\",\n",
      "            \"Apples are the second-cheapest.\",\n",
      "            \"Watermelons are less expensive than mangoes.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 2: Analyze Relationships\": {\n",
      "        \"Description\": \"Analyze each relationship to understand the relative pricing of the fruits.\",\n",
      "        \"Action\": \"Break down each statement to understand the 'more expensive than' and 'less expensive than' relationships.\",\n",
      "        \"Value\": [\n",
      "            \"Watermelons > Cantaloupes\",\n",
      "            \"Mangoes < Pears\",\n",
      "            \"Apples are the second-cheapest\",\n",
      "            \"Watermelons < Mangoes\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 3: Establish Initial Order\": {\n",
      "        \"Description\": \"Use the given relationships to establish an initial order of the fruits.\",\n",
      "        \"Action\": \"Create a tentative list of fruits from cheapest to most expensive based on the given information.\",\n",
      "        \"Value\": [\n",
      "            \"Cantaloupes < Watermelons < Mangoes < Pears\",\n",
      "            \"Apples are the second-cheapest\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 4: Identify the Second-Cheapest Fruit\": {\n",
      "        \"Description\": \"Determine which fruit is the second-cheapest based on the established order.\",\n",
      "        \"Action\": \"Identify the fruit that is second in the list from cheapest to most expensive.\",\n",
      "        \"Value\": \"Apples\"\n",
      "    },\n",
      "    \"Step 5: Verify Consistency\": {\n",
      "        \"Description\": \"Ensure that the established order is consistent with all given statements.\",\n",
      "        \"Action\": \"Cross-check the order with all the comparative statements to ensure no contradictions.\",\n",
      "        \"Value\": \"The order Cantaloupes < Apples < Watermelons < Mangoes < Pears is consistent with all given statements.\"\n",
      "    },\n",
      "    \"Step 6: Select the Correct Option\": {\n",
      "        \"Description\": \"Match the identified second-cheapest fruit with the given options.\",\n",
      "        \"Action\": \"Choose the option that corresponds to the second-cheapest fruit.\",\n",
      "        \"Value\": \"B\"\n",
      "    },\n",
      "    \"Step 7: Conclusion\": {\n",
      "        \"Description\": \"State the final conclusion based on the analysis.\",\n",
      "        \"Action\": \"Provide the final answer based on the selected option.\",\n",
      "        \"Value\": \"The final answer is B\"\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 261164.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B), C.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(B), (C) The purple book is the rightmost.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(C), E\"\n",
      "\n",
      "(E), C\"\n",
      "\n",
      "(B), D\"\n",
      "\n",
      "(A), C\"\n",
      "\n",
      "(E), A.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(D), A.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logical_deduction_seven_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'logical_deduction_seven_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-logical_deduction_seven_objects/bbh-logical_deduction_seven_objects_eval')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify clear positional clues\": {\n",
      "        \"Description\": \"Identify the birds with clear positional clues.\",\n",
      "        \"Action\": \"List the birds with specific positions mentioned in the clues.\",\n",
      "        \"Result\": \"The owl is the second from the right. The cardinal is the fourth from the left. The raven is the second from the left.\"\n",
      "    },\n",
      "    \"Step 2: Place birds with clear positions\": {\n",
      "        \"Description\": \"Place the birds with clear positions on the branch.\",\n",
      "        \"Action\": \"Assign the positions based on the clear clues provided.\",\n",
      "        \"Result\": \"Positions: [Raven, _, Cardinal, _, _, Owl, _]\"\n",
      "    },\n",
      "    \"Step 3: Analyze relative positions\": {\n",
      "        \"Description\": \"Analyze the relative positions of the remaining birds.\",\n",
      "        \"Action\": \"List the relative positions of the birds (e.g., to the left of, to the right of).\",\n",
      "        \"Result\": \"The falcon is to the left of the blue jay. The quail is to the left of the falcon. The robin is to the left of the quail.\"\n",
      "    },\n",
      "    \"Step 4: Place birds based on relative positions\": {\n",
      "        \"Description\": \"Place the remaining birds based on their relative positions.\",\n",
      "        \"Action\": \"Use the relative clues to determine the positions of the remaining birds.\",\n",
      "        \"Result\": \"Positions: [Raven, Robin, Quail, Cardinal, Falcon, Owl, Blue Jay]\"\n",
      "    },\n",
      "    \"Step 5: Verify consistency\": {\n",
      "        \"Description\": \"Verify that all positions are consistent with the given clues.\",\n",
      "        \"Action\": \"Check for any contradictions or inconsistencies in the arrangement.\",\n",
      "        \"Result\": \"All positions are consistent with the given clues.\"\n",
      "    },\n",
      "    \"Step 6: Determine the final arrangement\": {\n",
      "        \"Description\": \"Determine the final arrangement of the birds from left to right.\",\n",
      "        \"Action\": \"List the birds in their final positions.\",\n",
      "        \"Result\": \"Final arrangement: [Raven, Robin, Quail, Cardinal, Falcon, Owl, Blue Jay]\"\n",
      "    },\n",
      "    \"Step 7: Identify the bird second from the right\": {\n",
      "        \"Description\": \"Identify which bird is the second from the right.\",\n",
      "        \"Action\": \"Based on the final arrangement, identify the bird that is second from the right.\",\n",
      "        \"Result\": \"The owl is the second from the right.\"\n",
      "    },\n",
      "    \"Step 8: Select the correct option\": {\n",
      "        \"Description\": \"Select the correct option from the given choices.\",\n",
      "        \"Action\": \"Match the identified bird with the options provided.\",\n",
      "        \"Result\": \"The correct option is (D) The owl is the second from the right.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is D.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 212995.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C), D\"\n",
      "\n",
      "(B), (A).\n",
      "\n",
      "(A), B.\"\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(C), correct.\"\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(C), G.\n",
      "\n",
      "(E), B.\n",
      "\n",
      "(G), E\"\n",
      "\n",
      "(D), F.\n",
      "\n",
      "(G), C.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(E), B.\n",
      "\n",
      "(G), B.\n",
      "\n",
      "(E), (A) The hawk is the second from the left\"\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(E), G.\n",
      "\n",
      "(F), (D) The black book is the third from the left.\n",
      "\n",
      "(F), A\"\n",
      "\n",
      "(G), (F) The red book is the fourth from the left.\n",
      "\n",
      "(G), C.\n",
      "\n",
      "(C), E.\n",
      "\n",
      "(F), E\"\n",
      "\n",
      "(F), C.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(B), F.\n",
      "\n",
      "(D), G.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(G), A.\n",
      "\n",
      "(E), C\"\n",
      "\n",
      "(E), B.\n",
      "\n",
      "(F), D\"\n",
      "\n",
      "(C), F\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(E), F\"\n",
      "\n",
      "(G), E.\n",
      "\n",
      "(F), D.\"\n",
      "\n",
      "(A), G.\n",
      "\n",
      "(E), A.\n",
      "\n",
      "(B), F.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(G), E.\n",
      "\n",
      "(E), G.\n",
      "\n",
      "(B), G.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logical_deduction_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'logical_deduction_three_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-logical_deduction_three_objects/bbh-logical_deduction_three_objects_eval')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Identify the cheapest fruit as given in the problem statement\": {\n",
      "        \"Action\": \"Read the problem statement to find the explicit declaration of the cheapest fruit.\",\n",
      "        \"Expected Outcome\": \"Identify the fruit that is explicitly stated as the cheapest.\",\n",
      "        \"Result\": \"The loquats are the cheapest.\"\n",
      "    },\n",
      "    \"Step 2: Compare the prices of the remaining two fruits based on the information provided\": {\n",
      "        \"Action\": \"Analyze the cost relationship between the remaining two fruits as described in the problem statement.\",\n",
      "        \"Expected Outcome\": \"Determine the relative cost of the remaining two fruits.\",\n",
      "        \"Result\": \"The plums are less expensive than the apples.\"\n",
      "    },\n",
      "    \"Step 3: Order the fruits from cheapest to most expensive\": {\n",
      "        \"Action\": \"Use the information from Step 1 and Step 2 to order the fruits from cheapest to most expensive.\",\n",
      "        \"Expected Outcome\": \"Create a list of fruits ordered by their cost.\",\n",
      "        \"Result\": \"The order from cheapest to most expensive is: loquats, plums, apples.\"\n",
      "    },\n",
      "    \"Step 4: Select the correct option based on the ordered list\": {\n",
      "        \"Action\": \"Match the ordered list from Step 3 with the options provided.\",\n",
      "        \"Expected Outcome\": \"Identify the correct option that matches the cheapest fruit.\",\n",
      "        \"Result\": \"The correct option is (C) The loquats are the cheapest.\"\n",
      "    },\n",
      "    \"Is the final position the same as the starting position\": {\n",
      "        \"Action\": \"Verify if the final position (cheapest fruit) matches the starting position (explicitly stated cheapest fruit).\",\n",
      "        \"Expected Outcome\": \"Confirm the consistency of the final answer with the initial statement.\",\n",
      "        \"Result\": \"Yes, the final position matches the starting position.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 271019.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), logically sound.\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# movie_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'movie_recommendation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-movie_recommendation/bbh-movie_recommendation_eval')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Brainstorm Movie Similarities\": {\n",
      "        \"Description\": \"Generate a list of characteristics and themes that make The Shawshank Redemption, Forrest Gump, Dances with Wolves, and Mr. Holland's Opus similar.\",\n",
      "        \"Action\": \"Identify common themes, genres, and emotional impacts.\",\n",
      "        \"Result\": \"Common themes include redemption, personal growth, overcoming adversity, and emotional depth.\"\n",
      "    },\n",
      "    \"Step 2: Explore Different Perspectives\": {\n",
      "        \"Description\": \"Consider different genres, themes, or emotional impacts that could be relevant when comparing the given movies to the options.\",\n",
      "        \"Action\": \"List various perspectives and their relevance to the given movies.\",\n",
      "        \"Result\": \"Perspectives include drama, historical context, character development, and emotional resonance.\"\n",
      "    },\n",
      "    \"Step 3: Critical Movie Analysis\": {\n",
      "        \"Description\": \"Analyze the movies from various angles such as plot, characters, and cinematography.\",\n",
      "        \"Action\": \"Evaluate what makes the given movies unique and assess the options based on these criteria.\",\n",
      "        \"Result\": \"The given movies have strong character arcs, compelling plots, and excellent cinematography.\"\n",
      "    },\n",
      "    \"Step 4: Creative Movie Matching\": {\n",
      "        \"Description\": \"Think outside the box to find unconventional similarities between the given movies and the options.\",\n",
      "        \"Action\": \"Identify unique themes, settings, or storytelling techniques that might link them.\",\n",
      "        \"Result\": \"Unique similarities include themes of justice, societal issues, and personal transformation.\"\n",
      "    },\n",
      "    \"Step 5: Identify Core Movie Theme\": {\n",
      "        \"Description\": \"Determine the central theme or message that ties The Shawshank Redemption, Forrest Gump, Dances with Wolves, and Mr. Holland's Opus together.\",\n",
      "        \"Action\": \"Summarize the core theme of the given movies.\",\n",
      "        \"Result\": \"The core theme is the triumph of the human spirit in the face of adversity.\"\n",
      "    },\n",
      "    \"Step 6: Gather Relevant Movie Data\": {\n",
      "        \"Description\": \"Look for data such as reviews, ratings, and plot summaries that can provide insights into how the options compare to the given movies.\",\n",
      "        \"Action\": \"Collect and analyze relevant data from various sources.\",\n",
      "        \"Result\": \"Reviews and ratings indicate that Philadelphia has similar themes of personal struggle and societal issues.\"\n",
      "    },\n",
      "    \"Step 7: Stakeholder Perspectives\": {\n",
      "        \"Description\": \"Consider the viewpoints of movie enthusiasts, critics, or specific audiences who appreciate the given movies.\",\n",
      "        \"Action\": \"Understand their needs and preferences when evaluating the options.\",\n",
      "        \"Result\": \"Movie enthusiasts appreciate deep emotional stories and strong character development.\"\n",
      "    },\n",
      "    \"Step 8: Movie Expertise Required\": {\n",
      "        \"Description\": \"Assess whether the task requires specific knowledge about movie genres, directors, or cinematic techniques to accurately compare the options to the given movies.\",\n",
      "        \"Action\": \"Determine if specialized knowledge is needed and gather it if necessary.\",\n",
      "        \"Result\": \"Specialized knowledge in drama and character-driven narratives is required.\"\n",
      "    },\n",
      "    \"Step 9: Step-by-Step Movie Comparison\": {\n",
      "        \"Description\": \"Break down the comparison process into systematic steps, evaluating each movie option against the identified similarities one by one.\",\n",
      "        \"Action\": \"Create a comparison matrix or checklist for each movie option.\",\n",
      "        \"Result\": \"Philadelphia matches the criteria of personal struggle, societal issues, and emotional depth.\"\n",
      "    },\n",
      "    \"Step 10: Implement Step-by-Step Plan\": {\n",
      "        \"Description\": \"Create a detailed plan for comparing the movies, including clear steps and explanations for each part of the evaluation process.\",\n",
      "        \"Action\": \"Follow the plan to evaluate each movie option and document the findings.\",\n",
      "        \"Result\": \"Philadelphia is the closest match based on the identified similarities.\"\n",
      "    },\n",
      "    \"Final Step: Conclusion\": {\n",
      "        \"Description\": \"Based on the evaluation, determine which movie option is most similar to the given movies.\",\n",
      "        \"Action\": \"Summarize the findings and make a final recommendation.\",\n",
      "        \"Result\": \"The final answer is C\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 183381.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), B.\n",
      "\n",
      "(D), B\"\n",
      "\n",
      "(A), that none of the options (A, B, C, D, E) are similar to the given movies (Goodfellas, Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, The Silence of the Lambs).\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(C), A\"\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(A), D\"\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), C.\"\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\"\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(A), B\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(D), A.\n",
      "\n",
      "(A), D\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(D), A\"\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(A), D.\"\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), B\"\n",
      "\n",
      "Monsters, Inc, B\"\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(D), A.\n",
      "\n",
      "(C), None of the options are similar to the given movies.\n",
      "\n",
      "(B), C\"\n",
      "\n",
      "(A), D\"\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(A), None of the options are similar to the given set of movies.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(D), A.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), None of the options are similar to the given movies.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(B), D\"\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(D), None of the options are closely similar to the given movies in terms of genre, themes, and narrative styles.\n",
      "\n",
      "(C), B\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# penguins_in_a_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'penguins_in_a_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-penguins_in_a_table/bbh-penguins_in_a_table_eval')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 146\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Parse the table\": {\n",
      "        \"Description\": \"Extract the data from the table into a structured format.\",\n",
      "        \"Action\": \"Read the table and convert it into a list of dictionaries where each dictionary represents a penguin with keys: name, age, height, weight.\",\n",
      "        \"Result\": [\n",
      "            {\"name\": \"Louis\", \"age\": 7, \"height\": 50, \"weight\": 11},\n",
      "            {\"name\": \"Bernard\", \"age\": 5, \"height\": 80, \"weight\": 13},\n",
      "            {\"name\": \"Vincent\", \"age\": 9, \"height\": 60, \"weight\": 11},\n",
      "            {\"name\": \"Gwen\", \"age\": 8, \"height\": 70, \"weight\": 15}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 2: Remove Bernard from the table\": {\n",
      "        \"Description\": \"Filter out the penguin named Bernard from the list.\",\n",
      "        \"Action\": \"Iterate through the list and remove the dictionary where the name is 'Bernard'.\",\n",
      "        \"Result\": [\n",
      "            {\"name\": \"Louis\", \"age\": 7, \"height\": 50, \"weight\": 11},\n",
      "            {\"name\": \"Vincent\", \"age\": 9, \"height\": 60, \"weight\": 11},\n",
      "            {\"name\": \"Gwen\", \"age\": 8, \"height\": 70, \"weight\": 15}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 3: Identify penguins less than 8 years old\": {\n",
      "        \"Description\": \"Filter the list to include only penguins less than 8 years old.\",\n",
      "        \"Action\": \"Iterate through the filtered list and create a new list containing only penguins with age less than 8.\",\n",
      "        \"Result\": [\n",
      "            {\"name\": \"Louis\", \"age\": 7, \"height\": 50, \"weight\": 11}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 4: Count the number of penguins less than 8 years old\": {\n",
      "        \"Description\": \"Count the number of penguins in the filtered list.\",\n",
      "        \"Action\": \"Use the length of the new list to determine the number of penguins less than 8 years old.\",\n",
      "        \"Result\": 1\n",
      "    },\n",
      "    \"Step 5: Determine the correct option\": {\n",
      "        \"Description\": \"Match the count from Step 4 to the given options.\",\n",
      "        \"Action\": \"Compare the count with the options (A) 1, (B) 2, (C) 3, (D) 4, (E) 5 and select the correct option.\",\n",
      "        \"Result\": \"A\"\n",
      "    },\n",
      "    \"Step 6: Present the result\": {\n",
      "        \"Description\": \"Provide the final answer with a clear explanation.\",\n",
      "        \"Action\": \"State the correct option and explain how the count was derived.\",\n",
      "        \"Result\": \"The final answer is A\"\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 146it [00:00, 80574.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C), B\"\n",
      "\n",
      "(A), B.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9863013698630136"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reasoning_about_colored_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'reasoning_about_colored_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-reasoning_about_colored_objects/bbh-reasoning_about_colored_objects_eval')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1 - Identify all objects\": {\n",
      "        \"Description\": \"List all the objects mentioned on the nightstand.\",\n",
      "        \"Action\": \"Create a list of all objects.\",\n",
      "        \"Objects\": [\"black necklace\", \"green fidget spinner\", \"blue keychain\", \"yellow sheet of paper\", \"red stress ball\"]\n",
      "    },\n",
      "    \"Step 2 - Separate objects by color\": {\n",
      "        \"Description\": \"Classify each object by its color.\",\n",
      "        \"Action\": \"Create a list of objects that are yellow and a list of objects that are green.\",\n",
      "        \"Yellow objects\": [\"yellow sheet of paper\"],\n",
      "        \"Green objects\": [\"green fidget spinner\"]\n",
      "    },\n",
      "    \"Step 3 - Identify objects that are neither yellow nor green\": {\n",
      "        \"Description\": \"Determine which objects are not yellow or green.\",\n",
      "        \"Action\": \"Create a list of objects that are neither yellow nor green.\",\n",
      "        \"Neither yellow nor green objects\": [\"black necklace\", \"blue keychain\", \"red stress ball\"]\n",
      "    },\n",
      "    \"Step 4 - Count the relevant objects\": {\n",
      "        \"Description\": \"Count the number of objects that are neither yellow nor green.\",\n",
      "        \"Action\": \"Count the objects in the list created in Step 3.\",\n",
      "        \"Count\": 3\n",
      "    },\n",
      "    \"Step 5 - Match the count to the options\": {\n",
      "        \"Description\": \"Compare the count from Step 4 to the given options.\",\n",
      "        \"Action\": \"Identify the correct option based on the count.\",\n",
      "        \"Correct option\": \"D\"\n",
      "    },\n",
      "    \"Step 6 - Verify the solution\": {\n",
      "        \"Description\": \"Double-check the classification and counting to ensure accuracy.\",\n",
      "        \"Action\": \"Review the lists and counts to confirm the correctness of the solution.\",\n",
      "        \"Verification\": \"The count of objects that are neither yellow nor green is correct.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is D.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 112063.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B), the option selected in Step 4.\",\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(E), confirmed to be correct.\",\n",
      "\n",
      "(A), B\"\n",
      "\n",
      "(F), L\"\n",
      "\n",
      "(C), the option that matches the count of remaining yellow items.\",\n",
      "\n",
      "(F), K\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ruin_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'ruin_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-ruin_names/bbh-ruin_names_eval')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Brainstorm Humorous Edits\": {\n",
      "        \"Description\": \"Generate a list of humorous modifications to the artist or movie name 'star wars'.\",\n",
      "        \"Action\": \"List potential humorous edits based on puns, misspellings, phonetic humor, and pop culture references.\"\n",
      "    },\n",
      "    \"Step 2: Break Down the Problem\": {\n",
      "        \"Description\": \"Divide the task into smaller parts.\",\n",
      "        \"Action\": \"Identify the types of humor (puns, misspellings, etc.) and analyze each option accordingly.\"\n",
      "    },\n",
      "    \"Step 3: Critical Analysis of Options\": {\n",
      "        \"Description\": \"Evaluate each option by considering the use of humor, the play on words, and how it deviates from the original name.\",\n",
      "        \"Action\": \"For each option, note the type of humor used and how it alters the original name.\"\n",
      "    },\n",
      "    \"Step 4: Creative Interpretation\": {\n",
      "        \"Description\": \"Think outside the box to understand the humor in each option.\",\n",
      "        \"Action\": \"Consider unconventional wordplays, phonetic humor, or pop culture references that might make an edit funny.\"\n",
      "    },\n",
      "    \"Step 5: Step-by-Step Evaluation\": {\n",
      "        \"Description\": \"Systematically assess each option one by one, comparing them to the original name and evaluating their humorous effect.\",\n",
      "        \"Action\": \"For each option, compare it to the original name and evaluate its humorous effect.\"\n",
      "    },\n",
      "    \"Step 6: Detailed Step-by-Step Plan\": {\n",
      "        \"Description\": \"Create a plan to analyze each option step by step, noting the specific humorous elements and explaining why an option is or isn't humorous.\",\n",
      "        \"Action\": \"Implement the plan methodically for each option.\"\n",
      "    },\n",
      "    \"Step 7: Evaluate Option (A)\": {\n",
      "        \"Description\": \"Analyze option (A) 'stpr wars'.\",\n",
      "        \"Action\": \"Note the specific humorous elements and explain why it is or isn't humorous.\",\n",
      "        \"Analysis\": \"This option uses a misspelling but does not create a humorous effect as it does not form a recognizable pun or play on words.\"\n",
      "    },\n",
      "    \"Step 8: Evaluate Option (B)\": {\n",
      "        \"Description\": \"Analyze option (B) 'start wars'.\",\n",
      "        \"Action\": \"Note the specific humorous elements and explain why it is or isn't humorous.\",\n",
      "        \"Analysis\": \"This option changes 'star' to 'start' but does not create a humorous effect as it does not form a recognizable pun or play on words.\"\n",
      "    },\n",
      "    \"Step 9: Evaluate Option (C)\": {\n",
      "        \"Description\": \"Analyze option (C) 'star warts'.\",\n",
      "        \"Action\": \"Note the specific humorous elements and explain why it is or isn't humorous.\",\n",
      "        \"Analysis\": \"This option changes 'wars' to 'warts', creating a humorous effect through a pun, as 'warts' is a play on words that is unexpected and amusing.\"\n",
      "    },\n",
      "    \"Step 10: Evaluate Option (D)\": {\n",
      "        \"Description\": \"Analyze option (D) 'star warws'.\",\n",
      "        \"Action\": \"Note the specific humorous elements and explain why it is or isn't humorous.\",\n",
      "        \"Analysis\": \"This option uses a misspelling but does not create a humorous effect as it does not form a recognizable pun or play on words.\"\n",
      "    },\n",
      "    \"Step 11: Compare and Conclude\": {\n",
      "        \"Description\": \"Compare the humorous elements of all options and identify the best match.\",\n",
      "        \"Action\": \"Determine which option is the most humorous edit of 'star wars' based on the analysis.\",\n",
      "        \"Conclusion\": \"Option (C) 'star warts' is the most humorous edit due to its effective use of a pun.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 125292.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B), C.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), A\"\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(A), D.\"\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), D\"\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "rita, sue and bob poo, D.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(C), B\"\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(D), C.\"\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(D), B.\"\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(B), C\"\n",
      "\n",
      "(B), C.\n",
      "\n",
      "dearth, wind, & fire, G.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), B.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.748"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# salient_translation_error_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'salient_translation_error_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-salient_translation_error_detection/bbh-salient_translation_error_detection_eval')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Understand the Task\": {\n",
      "        \"Description\": \"Read and understand the task requirements and the types of errors that could occur in the translation.\",\n",
      "        \"Action\": \"Identify the error types: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, Dropped Content.\"\n",
      "    },\n",
      "    \"Step 2: Analyze the Source Text\": {\n",
      "        \"Description\": \"Carefully read and analyze the source text to understand its content and structure.\",\n",
      "        \"Action\": \"Identify key elements such as named entities, numerical values, modifiers, negations, facts, and significant clauses.\"\n",
      "    },\n",
      "    \"Step 3: Analyze the Translation\": {\n",
      "        \"Description\": \"Carefully read and analyze the translation to understand its content and structure.\",\n",
      "        \"Action\": \"Identify key elements such as named entities, numerical values, modifiers, negations, facts, and significant clauses.\"\n",
      "    },\n",
      "    \"Step 4: Compare Source Text and Translation\": {\n",
      "        \"Description\": \"Compare the source text and the translation side by side.\",\n",
      "        \"Action\": \"Look for discrepancies in named entities, numerical values, modifiers, negations, facts, and significant clauses.\"\n",
      "    },\n",
      "    \"Step 5: Identify Potential Errors\": {\n",
      "        \"Description\": \"Identify any potential errors based on the comparison.\",\n",
      "        \"Action\": \"Note down any discrepancies and categorize them according to the error types.\"\n",
      "    },\n",
      "    \"Step 6: Critical Thinking and Analysis\": {\n",
      "        \"Description\": \"Analyze the translation from different perspectives, question the accuracy of each part, and evaluate the evidence based on the source text.\",\n",
      "        \"Action\": \"Focus on logical reasoning and identifying potential biases or flaws in the translation.\"\n",
      "    },\n",
      "    \"Step 7: Consult Language Rules and Contextual Information\": {\n",
      "        \"Description\": \"Check if there are any relevant language rules or contextual information that can provide insights into the error.\",\n",
      "        \"Action\": \"Use reliable sources to verify language rules and contextual information.\"\n",
      "    },\n",
      "    \"Step 8: Consult Stakeholders or Language Experts\": {\n",
      "        \"Description\": \"Consider consulting stakeholders or language experts who could provide insights into the translation error.\",\n",
      "        \"Action\": \"Gather their perspectives and use them to help identify the error.\"\n",
      "    },\n",
      "    \"Step 9: Determine the Specific Error Type\": {\n",
      "        \"Description\": \"Based on the analysis, determine the specific error type that needs to be identified in the translation.\",\n",
      "        \"Action\": \"Categorize the error as Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, or Dropped Content.\"\n",
      "    },\n",
      "    \"Step 10: Conclude the Error Type\": {\n",
      "        \"Description\": \"Finalize the error type based on the analysis and categorization.\",\n",
      "        \"Action\": \"Select the correct option from the given choices (A, B, C, D, E, F).\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "### Analysis and Conclusion:\n",
      "\n",
      "**Step 1: Understand the Task**\n",
      "- Identify the error types: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, Dropped Content.\n",
      "\n",
      "**Step 2: Analyze the Source Text**\n",
      "- Source: \"Der Potsdamer Platz ist ein platzartiger Verkehrsknotenpunkt in den Berliner Ortsteilen Mitte und Tiergarten im Bezirk Mitte zwischen der alten Innenstadt im Osten und dem neuen Berliner Westen.\"\n",
      "- Key elements: Named entities (Potsdamer Platz, Mitte, Tiergarten, Bezirk Mitte, alten Innenstadt, neuen Berliner Westen), modifiers (platzartiger, alten, neuen), facts (location and description of Potsdamer Platz).\n",
      "\n",
      "**Step 3: Analyze the Translation**\n",
      "- Translation: \"Potsdamer Platz is a square-like hub in the Berlin districts of Mitte and Tiergarten in the Mitte district between the old city centre in the east and the new west of Berlin.\"\n",
      "- Key elements: Named entities (Potsdamer Platz, Mitte, Tiergarten, Mitte district, old city centre, new west of Berlin), modifiers (square-like, old, new), facts (location and description of Potsdamer Platz).\n",
      "\n",
      "**Step 4: Compare Source Text and Translation**\n",
      "- Discrepancies: The phrase \"im Bezirk Mitte\" is repeated in the translation, which is redundant and not present in the source text.\n",
      "\n",
      "**Step 5: Identify Potential Errors**\n",
      "- The repetition of \"Mitte district\" is a discrepancy that falls under \"Dropped Content\" as it introduces redundancy.\n",
      "\n",
      "**Step 6: Critical Thinking and Analysis**\n",
      "- The repetition of \"Mitte district\" is not accurate and introduces unnecessary redundancy, which is a form of dropped content.\n",
      "\n",
      "**Step 7: Consult Language Rules and Contextual Information**\n",
      "- Verify that the repetition is not a standard translation practice and is indeed an error.\n",
      "\n",
      "**Step 8: Consult Stakeholders or Language Experts**\n",
      "- Gather perspectives from language experts to confirm the error type.\n",
      "\n",
      "**Step 9: Determine the Specific Error Type**\n",
      "- The error is categorized as \"Dropped Content\" due to the redundancy introduced.\n",
      "\n",
      "**Step 10: Conclude the Error Type**\n",
      "- Select the correct option from the given choices (A, B, C, D, E, F).\n",
      "\n",
      "The final answer is E.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 188423.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), E.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(F), D.\"\n",
      "\n",
      "(D), F.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(F), E.\"\n",
      "\n",
      "(F), E.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(E), D. The error is that 'Landkreis Konstanz' is changed to 'district of Constance'.\"\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), A.\"\n",
      "\n",
      "(F), D\"\n",
      "\n",
      "(E), B.\n",
      "\n",
      "(A), E.\"\n",
      "\n",
      "(C), F.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(F), A.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(D), F.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(F), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(F), E.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(F), C.\n",
      "\n",
      "(C), F.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(F), (A) Modifiers or Adjectives.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(C), (A) Modifiers or Adjectives.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(A), F.\n",
      "\n",
      "(C), (A) Modifiers or Adjectives.\n",
      "\n",
      "(F), D.\n",
      "\n",
      "(A), E.\n",
      "\n",
      "(F), D.\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'snarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-snarks/bbh-snarks_eval')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 178\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: Understand the literal meaning of each statement\": {\n",
      "        \"Statement A\": \"Working the printer is too complex for me\",\n",
      "        \"Statement B\": \"Working the microprocessor is too complex for me\"\n",
      "    },\n",
      "    \"Step 2: Analyze the context and tone for any signs of sarcasm\": {\n",
      "        \"Context of Statement A\": \"Statement A is made in a context where the task of using a printer is generally considered simple.\",\n",
      "        \"Context of Statement B\": \"Statement B is made in a context where working with a microprocessor is generally considered complex.\",\n",
      "        \"Tone of Statement A\": \"The tone of Statement A suggests exaggeration and frustration, which could indicate sarcasm.\",\n",
      "        \"Tone of Statement B\": \"The tone of Statement B is more straightforward and could be taken at face value.\"\n",
      "    },\n",
      "    \"Step 3: Identify the core issue or problem that needs to be addressed\": {\n",
      "        \"Core issue of Statement A\": \"The main point of Statement A is the perceived difficulty of using a printer.\",\n",
      "        \"Core issue of Statement B\": \"The main point of Statement B is the actual difficulty of working with a microprocessor.\"\n",
      "    },\n",
      "    \"Step 4: Consider the underlying causes or factors contributing to the problem\": {\n",
      "        \"Underlying causes for Statement A\": \"The context and tone suggest that the speaker is exaggerating the difficulty of a simple task, implying sarcasm.\",\n",
      "        \"Underlying causes for Statement B\": \"The context and tone suggest that the speaker is genuinely expressing difficulty with a complex task.\"\n",
      "    },\n",
      "    \"Step 5: Identify the stakeholders or individuals who are directly affected by the problem\": {\n",
      "        \"Stakeholders for Statement A\": \"The speaker and audience for Statement A are likely to understand the exaggeration and sarcasm.\",\n",
      "        \"Stakeholders for Statement B\": \"The speaker and audience for Statement B are likely to understand the genuine difficulty.\"\n",
      "    },\n",
      "    \"Step 6: Determine if the problem is related to human behavior\": {\n",
      "        \"Human behavior factors for Statement A\": \"The sarcasm in Statement A is influenced by social norms and the speaker's intent to express frustration humorously.\",\n",
      "        \"Human behavior factors for Statement B\": \"The genuine difficulty in Statement B is influenced by the actual complexity of the task.\"\n",
      "    },\n",
      "    \"Step 7: Compare the statements to determine which is more likely to be sarcastic\": {\n",
      "        \"Comparison of sarcasm indicators\": \"Statement A has more indicators of sarcasm, such as exaggeration, context, and tone, compared to Statement B, which is more straightforward.\"\n",
      "    },\n",
      "    \"Step 8: Conclusion\": {\n",
      "        \"Most likely sarcastic statement\": \"Based on the analysis, Statement A is more likely to be sarcastic.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is A.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 178it [00:00, 214968.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(A), The statement cannot be determined as sarcastic due to insufficient context.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(B), A\"\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(B), A.\n",
      "\n",
      "(B), A.\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8707865168539326"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sports_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'sports_understanding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/unstructured/few_shot_0/bbh/bbh-sports_understanding/bbh-sports_understanding_eval')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the plausibility of the sentence \"Elias Lindholm beat the buzzer,\" we need to follow a systematic reasoning process:\n",
      "\n",
      "1. **Core Issue Identification**:\n",
      "   - The main question is whether Elias Lindholm scored a goal just before the end of a period in a hockey game.\n",
      "\n",
      "2. **Assumption Clarification**:\n",
      "   - Elias Lindholm is a hockey player.\n",
      "   - The event happened during a hockey game.\n",
      "   - \"Beat the buzzer\" means scoring just before the end of a period.\n",
      "\n",
      "3. **Relevant Data Identification**:\n",
      "   - We need to look for official game reports, sports news articles, or video footage that mention Elias Lindholm scoring a goal just before the buzzer.\n",
      "\n",
      "4. **Problem Type Specification**:\n",
      "   - The plausibility depends on the technical rules of hockey regarding scoring just before the buzzer.\n",
      "\n",
      "5. **Critical Thinking for Plausibility**:\n",
      "   - Analyze the data:\n",
      "     - Check if there are any reports or footage of Elias Lindholm scoring a goal just before the buzzer.\n",
      "     - Verify the timing of the goal against the game clock.\n",
      "     - Consider the reliability of the sources.\n",
      "\n",
      "6. **Decision-Making and Uncertainty**:\n",
      "   - Evaluate the plausibility:\n",
      "     - If there is evidence that Elias Lindholm scored a goal just before the buzzer, the sentence is plausible.\n",
      "     - If there is no such evidence, the sentence is not plausible.\n",
      "\n",
      "Given the lack of specific data in the prompt, we cannot definitively confirm or deny the plausibility without additional information. However, based on the structure and common usage of the phrase \"beat the buzzer\" in sports, it is a plausible statement if Elias Lindholm is indeed a hockey player and the context is a hockey game.\n",
      "\n",
      "The final answer is: The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'False.',\n",
       "  'Implausible.',\n",
       "  'Plausible.',\n",
       "  'The plausibility of the sentence \"Juan Soto did a double stepover\" is uncertain without further evidence.',\n",
       "  'The plausibility of the sentence cannot be determined with the information provided.',\n",
       "  'The plausibility of the statement \"Deshaun Watson was flagged on the play\" is uncertain without specific data.',\n",
       "  'The plausibility of the statement \"Jonas Valanciunas beat the buzzer\" depends on the analysis of relevant data and critical thinking as outlined above.',\n",
       "  'The sentence \"Dani Alves took the snap\" is not plausible in a sports context.',\n",
       "  'The sentence \"Kendrick Nunn took a charge\" is plausible.',\n",
       "  'The sentence \"Kyle Tucker took a left footed shot\" is plausible, assuming Kyle Tucker is a soccer player and considering the general possibility of players using their non-dominant foot.',\n",
       "  'The sentence \"Toni Kroos performed a give and go\" is plausible.',\n",
       "  'The sentence is not plausible.',\n",
       "  'The sentence is plausible but not definitively true without additional context or information.',\n",
       "  'The sentence is plausible if Brandon Lowe is a soccer player, but not if he is a baseball player.',\n",
       "  'The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game.',\n",
       "  'The sentence is plausible in a sports context.',\n",
       "  'The sentence is plausible.',\n",
       "  'The statement \"Luis Robert was out at second\" is plausible.',\n",
       "  'The statement is plausible if supported by relevant evidence.',\n",
       "  'The statement is plausible.',\n",
       "  'True.',\n",
       "  'implausible.',\n",
       "  'not True or False. A: False',\n",
       "  'not plausible.'},\n",
       " {'no', 'yes'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"]), set(dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287bb1379c64452cb540de8de3e65cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'False',\n",
       " 'Implausible',\n",
       " 'Plausible',\n",
       " 'The plausibility of the sentence Juan Soto did a double stepover is uncertain without further evidence',\n",
       " 'The plausibility of the sentence cannot be determined with the information provided',\n",
       " 'The plausibility of the statement Deshaun Watson was flagged on the play is uncertain without specific data',\n",
       " 'The plausibility of the statement Jonas Valanciunas beat the buzzer depends on the analysis of relevant data and critical thinking as outlined above',\n",
       " 'The sentence Dani Alves took the snap is not plausible in a sports context',\n",
       " 'The sentence Kendrick Nunn took a charge is plausible',\n",
       " 'The sentence Kyle Tucker took a left footed shot is plausible, assuming Kyle Tucker is a soccer player and considering the general possibility of players using their non-dominant foot',\n",
       " 'The sentence Toni Kroos performed a give and go is plausible',\n",
       " 'The sentence is not plausible',\n",
       " 'The sentence is plausible',\n",
       " 'The sentence is plausible but not definitively true without additional context or information',\n",
       " 'The sentence is plausible if Brandon Lowe is a soccer player, but not if he is a baseball player',\n",
       " 'The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game',\n",
       " 'The sentence is plausible in a sports context',\n",
       " 'The statement Luis Robert was out at second is plausible',\n",
       " 'The statement is plausible',\n",
       " 'The statement is plausible if supported by relevant evidence',\n",
       " 'True',\n",
       " 'implausible',\n",
       " 'not True or False A: False',\n",
       " 'not plausible'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.\"')),\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)\n",
    "\n",
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54431a8760ef4e7c9bea57483b998860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'The plausibility of the sentence Juan Soto did a double stepover is uncertain without further evidence',\n",
       " 'The plausibility of the sentence cannot be determined with the information provided',\n",
       " 'The plausibility of the statement Deshaun Watson was flagged on the play is uncertain without specific data',\n",
       " 'The plausibility of the statement Jonas Valanciunas beat the buzzer depends on the analysis of relevant data and critical thinking as outlined above',\n",
       " 'The sentence Kyle Tucker took a left footed shot is plausible, assuming Kyle Tucker is a soccer player and considering the general possibility of players using their non-dominant foot',\n",
       " 'The sentence is plausible but not definitively true without additional context or information',\n",
       " 'The sentence is plausible if Brandon Lowe is a soccer player, but not if he is a baseball player',\n",
       " 'The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game',\n",
       " 'The statement is plausible if supported by relevant evidence',\n",
       " 'no',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plausible_yes = [\n",
    "    'Plausible',\n",
    "    'The sentence Kendrick Nunn took a charge is plausible',\n",
    "    'The sentence Toni Kroos performed a give and go is plausible',\n",
    "    'The sentence is plausible',\n",
    "    'The sentence is plausible in a sports context',\n",
    "    'The statement Luis Robert was out at second is plausible',\n",
    "    'The statement is plausible',\n",
    "    'True'\n",
    "]\n",
    "\n",
    "implausible_no = [\n",
    "    'False',\n",
    "    'Implausible',\n",
    "    'The sentence Dani Alves took the snap is not plausible in a sports context',\n",
    "    'The sentence is not plausible',\n",
    "    'implausible',\n",
    "    'not True or False A: False', # The 'False' conclusion points to implausible\n",
    "    'not plausible'\n",
    "]\n",
    "\n",
    "indeterminate = [\n",
    "    'The plausibility of the sentence Juan Soto did a double stepover is uncertain without further evidence',\n",
    "    'The plausibility of the sentence cannot be determined with the information provided',\n",
    "    'The plausibility of the statement Deshaun Watson was flagged on the play is uncertain without specific data',\n",
    "    'The plausibility of the statement Jonas Valanciunas beat the buzzer depends on the analysis of relevant data and critical thinking as outlined above',\n",
    "    'The sentence Kyle Tucker took a left footed shot is plausible, assuming Kyle Tucker is a soccer player and considering the general possibility of players using their non-dominant foot', # Plausibility is conditional on an assumption\n",
    "    'The sentence is plausible but not definitively true without additional context or information', # Expresses uncertainty despite using 'plausible'\n",
    "    'The sentence is plausible if Brandon Lowe is a soccer player, but not if he is a baseball player', # Plausibility is conditional\n",
    "    'The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game', # Plausibility is conditional\n",
    "    'The statement is plausible if supported by relevant evidence' # Plausibility is conditional\n",
    "]\n",
    "\n",
    "\n",
    "def map_fn(ins):\n",
    "    for yes in plausible_yes:\n",
    "        if yes == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"yes\"\n",
    "            }\n",
    "\n",
    "    for no in implausible_no:\n",
    "        if no == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"no\"\n",
    "            }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)\n",
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d96d210d8b442259077cb3750a01c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no, The sentence is plausible if Elias Lindholm is a hockey player and the context is a hockey game\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, The sentence is plausible but not definitively true without additional context or information\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, The statement is plausible if supported by relevant evidence\n",
      "\n",
      "no, yes\n",
      "\n",
      "no, yes\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, The sentence Kyle Tucker took a left footed shot is plausible, assuming Kyle Tucker is a soccer player and considering the general possibility of players using their non-dominant foot\n",
      "\n",
      "yes, The plausibility of the statement Deshaun Watson was flagged on the play is uncertain without specific data\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, The plausibility of the sentence Juan Soto did a double stepover is uncertain without further evidence\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "no, The sentence is plausible if Brandon Lowe is a soccer player, but not if he is a baseball player\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, The plausibility of the statement Jonas Valanciunas beat the buzzer depends on the analysis of relevant data and critical thinking as outlined above\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, The plausibility of the sentence cannot be determined with the information provided\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "yes, no\n",
      "\n",
      "no, yes\n",
      "\n",
      "no, yes\n",
      "\n",
      "no, yes\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'temporal_sequences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-temporal_sequences/bbh-temporal_sequences_eval')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1: List all known time intervals\": {\n",
      "        \"description\": \"Identify and list all the time intervals during which Tiffany's activities are known.\",\n",
      "        \"action\": \"Extract the time intervals from the provided information.\",\n",
      "        \"values\": [\n",
      "            {\"start\": \"6am\", \"end\": \"9am\", \"activity\": \"Reading at the library\"},\n",
      "            {\"start\": \"9am\", \"end\": \"10am\", \"activity\": \"Driving to the water park\"},\n",
      "            {\"start\": \"12pm\", \"end\": \"6pm\", \"activity\": \"Buying a phone at the electronics store\"},\n",
      "            {\"start\": \"6pm\", \"end\": \"10pm\", \"activity\": \"Working out at the gym\"}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 2: Identify gaps between these intervals\": {\n",
      "        \"description\": \"Determine the time gaps between the known intervals where Tiffany was not occupied.\",\n",
      "        \"action\": \"Calculate the time gaps between the end of one activity and the start of the next.\",\n",
      "        \"values\": [\n",
      "            {\"start\": \"10am\", \"end\": \"12pm\"}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 3: Match the gaps with the market's operating hours\": {\n",
      "        \"description\": \"Compare the identified gaps with the market's operating hours to find the suitable time slot.\",\n",
      "        \"action\": \"Check if any of the gaps fall within the market's operating hours.\",\n",
      "        \"values\": [\n",
      "            {\"gap\": {\"start\": \"10am\", \"end\": \"12pm\"}, \"market_hours\": {\"open\": \"before 10pm\", \"close\": \"10pm\"}}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 4: Select the matching option from the given choices\": {\n",
      "        \"description\": \"Choose the option that corresponds to the identified time slot when Tiffany could have gone to the market.\",\n",
      "        \"action\": \"Match the identified time slot with the provided options.\",\n",
      "        \"values\": [\n",
      "            {\"identified_time_slot\": {\"start\": \"10am\", \"end\": \"12pm\"}, \"matching_option\": \"B\"}\n",
      "        ]\n",
      "    },\n",
      "    \"Step 5: Verify the final time slot\": {\n",
      "        \"description\": \"Ensure that the selected time slot is consistent with all the given information and constraints.\",\n",
      "        \"action\": \"Double-check the selected time slot against the known activities and market hours.\",\n",
      "        \"values\": [\n",
      "            {\"final_time_slot\": {\"start\": \"10am\", \"end\": \"12pm\"}, \"consistency_check\": \"Consistent with all known activities and market hours\"}\n",
      "        ]\n",
      "    },\n",
      "    \"Is final time slot the same as one of the given options\": {\n",
      "        \"description\": \"Confirm if the identified time slot matches any of the provided options.\",\n",
      "        \"action\": \"Compare the final time slot with the options (A), (B), (C), (D).\",\n",
      "        \"values\": [\n",
      "            {\"final_time_slot\": {\"start\": \"10am\", \"end\": \"12pm\"}, \"matching_option\": \"B\"}\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is B.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57656aad5db34884847b942994610cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), D.\n",
      "\n",
      "(C), D\"\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(D), (C) 11am to 5pm.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(A), D\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'tracking_shuffled_objects_five_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/Surge/self-discover/evals/logs/mistral/phaseII/bbh/bbh-tracking_shuffled_objects_five_objects/bbh-tracking_shuffled_objects_five_objects_eval')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Break down the problem into sequential swaps\": {\n",
      "        \"Identify each swap of items between pairs and track these exchanges step by step\": {\n",
      "            \"1. Dave and Eve switch partners: Dave gets Melissa, Eve gets Lola\",\n",
      "            \"2. Dave and Alice switch partners: Dave gets Patrick, Alice gets Melissa\",\n",
      "            \"3. Eve and Alice switch partners: Eve gets Patrick, Alice gets Lola\",\n",
      "            \"4. Claire and Bob switch partners: Claire gets Sam, Bob gets Jamie\",\n",
      "            \"5. Dave and Alice switch partners: Dave gets Lola, Alice gets Patrick\"\n",
      "        }\n",
      "    },\n",
      "    \"Critical Thinking for Tracking\": {\n",
      "        \"Analyze the sequence of swaps from the perspective of each participant involved\": {\n",
      "            \"Alice: Patrick -> Melissa -> Lola -> Patrick\",\n",
      "            \"Bob: Sam -> Jamie\",\n",
      "            \"Claire: Jamie -> Sam\",\n",
      "            \"Dave: Lola -> Melissa -> Patrick -> Lola\",\n",
      "            \"Eve: Melissa -> Lola -> Patrick\"\n",
      "        },\n",
      "        \"Question and verify the current item held by each person after every exchange\": {\n",
      "            \"After 1st swap: Dave with Melissa, Eve with Lola\",\n",
      "            \"After 2nd swap: Dave with Patrick, Alice with Melissa\",\n",
      "            \"After 3rd swap: Eve with Patrick, Alice with Lola\",\n",
      "            \"After 4th swap: Claire with Sam, Bob with Jamie\",\n",
      "            \"After 5th swap: Dave with Lola, Alice with Patrick\"\n",
      "        },\n",
      "        \"Evaluate the information given at each step to ensure accurate tracking\": {\n",
      "            \"Each swap is verified to ensure the correct partner is assigned after the exchange\"\n",
      "        }\n",
      "    },\n",
      "    \"Step-by-Step Tracking\": {\n",
      "        \"Carefully follow each swap in the order it occurs\": {\n",
      "            \"1. Dave and Eve switch partners\",\n",
      "            \"2. Dave and Alice switch partners\",\n",
      "            \"3. Eve and Alice switch partners\",\n",
      "            \"4. Claire and Bob switch partners\",\n",
      "            \"5. Dave and Alice switch partners\"\n",
      "        },\n",
      "        \"Update the item held by each participant after each swap\": {\n",
      "            \"After 1st swap: Dave with Melissa, Eve with Lola\",\n",
      "            \"After 2nd swap: Dave with Patrick, Alice with Melissa\",\n",
      "            \"After 3rd swap: Eve with Patrick, Alice with Lola\",\n",
      "            \"After 4th swap: Claire with Sam, Bob with Jamie\",\n",
      "            \"After 5th swap: Dave with Lola, Alice with Patrick\"\n",
      "        }\n",
      "    },\n",
      "    \"Implement a Step-by-Step Plan with Clear Explanations\": {\n",
      "        \"Create a plan that involves tracking the items from the start\": {\n",
      "            \"Initial partners: Alice with Patrick, Bob with Sam, Claire with Jamie, Dave with Lola, Eve with Melissa\"\n",
      "        },\n",
      "        \"Update the list of who holds what after each swap\": {\n",
      "            \"After 1st swap: Dave with Melissa, Eve with Lola\",\n",
      "            \"After 2nd swap: Dave with Patrick, Alice with Melissa\",\n",
      "            \"After 3rd swap: Eve with Patrick, Alice with Lola\",\n",
      "            \"After 4th swap: Claire with Sam, Bob with Jamie\",\n",
      "            \"After 5th swap: Dave with Lola, Alice with Patrick\"\n",
      "        },\n",
      "        \"Clearly explain each step of the process\": {\n",
      "            \"Each swap is explained with the resulting partners\",\n",
      "            \"The final partners are derived from the sequence of swaps\"\n",
      "        },\n",
      "        \"Ensure the final answer is derived logically from the tracked information\": {\n",
      "            \"At the end of the dance, Alice is dancing with Patrick\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is (A) Patrick.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating...: 250it [00:00, 255937.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C), B.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(B), (A) red ball.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(E), (D) orange ball.\n",
      "\n",
      "(D), A.\n",
      "\n",
      "(D), (A) brown present.\n",
      "\n",
      "(E), B.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(E), A.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(E), (C) white ball.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(C), (A) brown present.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), E.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(E), (D) Patrick.\n",
      "\n",
      "(E), (B) red present.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(E), (A) benchwarmer.\n",
      "\n",
      "(B), D.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(A), D.\n",
      "\n",
      "(B), C.\n",
      "\n",
      "(D), (A) orange ball.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(A), C.\n",
      "\n",
      "(A), (E) striker.\n",
      "\n",
      "(B), E.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(E), C.\n",
      "\n",
      "(D), (A) green present.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(E), D.\n",
      "\n",
      "(D), (A) striker.\n",
      "\n",
      "(D), C.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(D), B.\n",
      "\n",
      "(D), (C) green present.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.756"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracking_shuffled_objects_seven_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'tracking_shuffled_objects_seven_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-tracking_shuffled_objects_seven_objects/bbh-tracking_shuffled_objects_seven_objects_eval')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Initial Positions\": {\n",
      "        \"Alice\": \"cheerleader\",\n",
      "        \"Bob\": \"left winger\",\n",
      "        \"Claire\": \"goalkeeper\",\n",
      "        \"Dave\": \"right midfielder\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"benchwarmer\",\n",
      "        \"Gertrude\": \"striker\"\n",
      "    },\n",
      "    \"Position after swap 1 (Fred and Claire)\": {\n",
      "        \"Alice\": \"cheerleader\",\n",
      "        \"Bob\": \"left winger\",\n",
      "        \"Claire\": \"benchwarmer\",\n",
      "        \"Dave\": \"right midfielder\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"goalkeeper\",\n",
      "        \"Gertrude\": \"striker\"\n",
      "    },\n",
      "    \"Position after swap 2 (Gertrude and Alice)\": {\n",
      "        \"Alice\": \"striker\",\n",
      "        \"Bob\": \"left winger\",\n",
      "        \"Claire\": \"benchwarmer\",\n",
      "        \"Dave\": \"right midfielder\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"goalkeeper\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Position after swap 3 (Fred and Dave)\": {\n",
      "        \"Alice\": \"striker\",\n",
      "        \"Bob\": \"left winger\",\n",
      "        \"Claire\": \"benchwarmer\",\n",
      "        \"Dave\": \"goalkeeper\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"right midfielder\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Position after swap 4 (Fred and Claire)\": {\n",
      "        \"Alice\": \"striker\",\n",
      "        \"Bob\": \"left winger\",\n",
      "        \"Claire\": \"right midfielder\",\n",
      "        \"Dave\": \"goalkeeper\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"benchwarmer\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Position after swap 5 (Alice and Bob)\": {\n",
      "        \"Alice\": \"left winger\",\n",
      "        \"Bob\": \"striker\",\n",
      "        \"Claire\": \"right midfielder\",\n",
      "        \"Dave\": \"goalkeeper\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"benchwarmer\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Position after swap 6 (Dave and Bob)\": {\n",
      "        \"Alice\": \"left winger\",\n",
      "        \"Bob\": \"goalkeeper\",\n",
      "        \"Claire\": \"right midfielder\",\n",
      "        \"Dave\": \"striker\",\n",
      "        \"Eve\": \"center midfielder\",\n",
      "        \"Fred\": \"benchwarmer\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Position after swap 7 (Fred and Eve)\": {\n",
      "        \"Alice\": \"left winger\",\n",
      "        \"Bob\": \"goalkeeper\",\n",
      "        \"Claire\": \"right midfielder\",\n",
      "        \"Dave\": \"striker\",\n",
      "        \"Eve\": \"benchwarmer\",\n",
      "        \"Fred\": \"center midfielder\",\n",
      "        \"Gertrude\": \"cheerleader\"\n",
      "    },\n",
      "    \"Final Position of Bob\": {\n",
      "        \"Bob\": \"goalkeeper\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c05af41e9a64870baa88d8c620ba21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(F), D.\n",
      "\n",
      "(F), E.\n",
      "\n",
      "(B), G.\n",
      "\n",
      "(D), E.\n",
      "\n",
      "(C), D.\n",
      "\n",
      "(A), C.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracking_shuffled_objects_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'tracking_shuffled_objects_three_objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-tracking_shuffled_objects_three_objects/bbh-tracking_shuffled_objects_three_objects_eval')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Initial Partnerships\": {\n",
      "        \"Alice\": \"Ophelia\",\n",
      "        \"Bob\": \"Lola\",\n",
      "        \"Claire\": \"Izzi\"\n",
      "    },\n",
      "    \"Partner Switch 1\": {\n",
      "        \"Description\": \"Bob and Claire switch partners\",\n",
      "        \"Alice\": \"Ophelia\",\n",
      "        \"Bob\": \"Izzi\",\n",
      "        \"Claire\": \"Lola\"\n",
      "    },\n",
      "    \"Partner Switch 2\": {\n",
      "        \"Description\": \"Claire and Alice switch partners\",\n",
      "        \"Alice\": \"Lola\",\n",
      "        \"Bob\": \"Izzi\",\n",
      "        \"Claire\": \"Ophelia\"\n",
      "    },\n",
      "    \"Partner Switch 3\": {\n",
      "        \"Description\": \"Alice and Bob switch partners\",\n",
      "        \"Alice\": \"Izzi\",\n",
      "        \"Bob\": \"Lola\",\n",
      "        \"Claire\": \"Ophelia\"\n",
      "    },\n",
      "    \"Final Partnerships\": {\n",
      "        \"Alice\": \"Izzi\",\n",
      "        \"Bob\": \"Lola\",\n",
      "        \"Claire\": \"Ophelia\"\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"Alice's final partner\": \"Izzi\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = lambda y_i, y_pred_i: y_pred_i and y_i.translate(\n",
    "    str.maketrans(\"\", \"\", \"()\")\n",
    ") == y_pred_i.translate(str.maketrans(\"\", \"\", '.()\"'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed32ed198997466abc2a7fdc3214fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(A), B.\n",
      "\n",
      "(C), A.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), B.\n",
      "\n",
      "(C), B.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.968"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web_of_lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'web_of_lies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/structured/few_shot_5/bbh/bbh-web_of_lies/bbh-web_of_lies_eval')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'self_discover_input', 'few_shot_examples', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Step 1 - Analyze Raymond's Statement\": {\n",
      "        \"Description\": \"Evaluate the initial statement that Raymond tells the truth.\",\n",
      "        \"Action\": \"Assume Raymond tells the truth and analyze the implications.\",\n",
      "        \"Result\": \"Assume Raymond tells the truth.\"\n",
      "    },\n",
      "    \"Step 2 - Analyze Sal's Statement\": {\n",
      "        \"Description\": \"Evaluate Sal's statement that Raymond lies.\",\n",
      "        \"Action\": \"Determine the truth value of Sal's statement based on the assumption about Raymond.\",\n",
      "        \"Result\": \"If Raymond tells the truth, then Sal's statement that Raymond lies is false.\"\n",
      "    },\n",
      "    \"Step 3 - Analyze Alexis's Statement\": {\n",
      "        \"Description\": \"Evaluate Alexis's statement that Sal lies.\",\n",
      "        \"Action\": \"Determine the truth value of Alexis's statement based on the truth value of Sal's statement.\",\n",
      "        \"Result\": \"Since Sal's statement is false, Alexis's statement that Sal lies is true.\"\n",
      "    },\n",
      "    \"Step 4 - Analyze Helene's Statement\": {\n",
      "        \"Description\": \"Evaluate Helene's statement that Alexis lies.\",\n",
      "        \"Action\": \"Determine the truth value of Helene's statement based on the truth value of Alexis's statement.\",\n",
      "        \"Result\": \"Since Alexis's statement is true, Helene's statement that Alexis lies is false.\"\n",
      "    },\n",
      "    \"Step 5 - Analyze Elanor's Statement\": {\n",
      "        \"Description\": \"Evaluate Elanor's statement that Helene lies.\",\n",
      "        \"Action\": \"Determine the truth value of Elanor's statement based on the truth value of Helene's statement.\",\n",
      "        \"Result\": \"Since Helene's statement is false, Elanor's statement that Helene lies is true.\"\n",
      "    },\n",
      "    \"Step 6 - Conclusion\": {\n",
      "        \"Description\": \"Determine if Elanor tells the truth based on the analysis of all previous statements.\",\n",
      "        \"Action\": \"Summarize the findings and conclude whether Elanor tells the truth.\",\n",
      "        \"Result\": \"Elanor tells the truth.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The final answer is: Elanor tells the truth.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Alejandro tells the truth.',\n",
       "  'Alexis tells the truth.',\n",
       "  'Amberly does not tell the truth.',\n",
       "  'Amberly is not telling the truth.',\n",
       "  'Amberly tells the truth.',\n",
       "  'Andree tells the truth.',\n",
       "  'Antwan tells the truth.',\n",
       "  'Audrie tells the truth.',\n",
       "  'Bernita does not tell the truth.',\n",
       "  'Bernita is not telling the truth.',\n",
       "  'Christie does not tell the truth.',\n",
       "  'Christie tells the truth.',\n",
       "  'Conception does not tell the truth.',\n",
       "  'Conception tells the truth.',\n",
       "  'Crista tells the truth.',\n",
       "  'Dallas is telling the truth.',\n",
       "  'Dallas tells the truth.',\n",
       "  'Delbert does not tell the truth.',\n",
       "  'Delbert tells the truth.',\n",
       "  'Delfina does not tell the truth.',\n",
       "  'Delfina lies.',\n",
       "  'Delfina tells the truth.',\n",
       "  'Elanor does not tell the truth.',\n",
       "  'Elanor tells the truth.',\n",
       "  'False\"',\n",
       "  'False.',\n",
       "  'False.\"',\n",
       "  'False.**',\n",
       "  'Fidel does not tell the truth.',\n",
       "  'Fidel tells the truth.',\n",
       "  'Fletcher tells the truth.',\n",
       "  'Gwenn does not tell the truth.',\n",
       "  'Gwenn tells the truth.',\n",
       "  'Helene does not tell the truth.',\n",
       "  'Inga does not tell the truth.',\n",
       "  'Inga tells the truth.',\n",
       "  'Jamey does not tell the truth.',\n",
       "  'Jamey tells the truth.',\n",
       "  'Jaymie does not tell the truth.',\n",
       "  'Jaymie tells the truth.',\n",
       "  'Jerry does not tell the truth.',\n",
       "  'Jerry tells the truth.',\n",
       "  'Jim does not tell the truth.',\n",
       "  'Jim lies.',\n",
       "  'Jim tells the truth.',\n",
       "  'Ka does not tell the truth.',\n",
       "  'Ka is telling the truth.',\n",
       "  'Ka tells the truth.',\n",
       "  'Kandi does not tell the truth.',\n",
       "  'Kandi is lying.',\n",
       "  'Kristian tells the truth.',\n",
       "  'Leda lies.',\n",
       "  'Leda tells the truth.',\n",
       "  'Lorine does not tell the truth.',\n",
       "  'Lorine tells the truth.',\n",
       "  'Maybelle tells the truth.',\n",
       "  'Michaela does not tell the truth.',\n",
       "  'Michaela tells the truth.',\n",
       "  'Millicent does not tell the truth.',\n",
       "  'Millicent is not telling the truth.',\n",
       "  'Millicent tells the truth.',\n",
       "  'Millie does not tell the truth.',\n",
       "  'Millie tells the truth.',\n",
       "  'Millie tells the truth.\"',\n",
       "  'No, Alexis does not tell the truth.',\n",
       "  'No, Ka does not tell the truth.',\n",
       "  'No, Shalonda does not tell the truth.',\n",
       "  'No.',\n",
       "  'Osvaldo tells the truth.',\n",
       "  'Phoebe tells the truth.',\n",
       "  'Rashida does not tell the truth.',\n",
       "  'Rashida tells the truth.',\n",
       "  'Raymond does not tell the truth.',\n",
       "  'Ryan does not tell the truth.',\n",
       "  'Ryan tells the truth.',\n",
       "  'Sal does not tell the truth.',\n",
       "  'Sal tells the truth.',\n",
       "  'Shalonda does not tell the truth.',\n",
       "  'Shalonda tells the truth.',\n",
       "  'Shaunda does not tell the truth.',\n",
       "  'Shaunda tells the truth.',\n",
       "  'Shenna does not tell the truth.',\n",
       "  'Shenna is telling the truth.',\n",
       "  'Shenna tells the truth.',\n",
       "  'Sherrie tells the truth.',\n",
       "  'Sima tells the truth.',\n",
       "  'Tamika does not tell the truth.',\n",
       "  'Tamika does not tell the truth.\"',\n",
       "  'Teressa does not tell the truth.',\n",
       "  'Teressa tells the truth.',\n",
       "  'True\"',\n",
       "  'True.',\n",
       "  'True.\"',\n",
       "  'Vina does not tell the truth.',\n",
       "  'Vina tells the truth.\"',\n",
       "  'Willian does not tell the truth.',\n",
       "  'Yes, Alexis tells the truth.',\n",
       "  'Yes, Bernita tells the truth.',\n",
       "  'Yes, Maybelle tells the truth.',\n",
       "  'Yes.',\n",
       "  'Yoland tells the truth.',\n",
       "  'true\"'},\n",
       " {'No', 'Yes'})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"]), set(dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06ee9c50ac3425f96098c7c6d271c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'False',\n",
       " 'Ka is telling the truth',\n",
       " 'Leda lies',\n",
       " 'No',\n",
       " 'Shenna is telling the truth',\n",
       " 'Vina tells the truth',\n",
       " 'Yes'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.\"*')),\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)\n",
    "\n",
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff36303d46774f0297deef114e237c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truth (Yes)\n",
    "truth_yes = [\n",
    "    \"True\",\n",
    "    \"Amberly tells the truth\",\n",
    "    \"Andree tells the truth\",\n",
    "    \"Christie tells the truth\",\n",
    "    \"Conception tells the truth\",\n",
    "    \"Delbert tells the truth\",\n",
    "    \"Delfina tells the truth\",\n",
    "    \"Maybelle tells the truth\",\n",
    "    \"Millie tells the truth\",\n",
    "    \"Shalonda tells the truth\",\n",
    "    \"Sima tells the truth\",\n",
    "    \"Alexis tells the truth\",\n",
    "    \"Alejandro tells the truth\",\n",
    "    \"Antwan tells the truth\",\n",
    "    \"Audrie tells the truth\",\n",
    "    \"Crista tells the truth\",\n",
    "    \"Dallas is telling the truth\",\n",
    "    \"Dallas tells the truth\",\n",
    "    \"Elanor tells the truth\",\n",
    "    \"Fidel tells the truth\",\n",
    "    \"Fletcher tells the truth\",\n",
    "    \"Gwenn tells the truth\",\n",
    "    \"Inga tells the truth\",\n",
    "    \"Jamey tells the truth\",\n",
    "    \"Jaymie tells the truth\",\n",
    "    \"Jerry tells the truth\",\n",
    "    \"Jim tells the truth\",\n",
    "    \"Ka tells the truth\",\n",
    "    \"Kristian tells the truth\",\n",
    "    \"Leda tells the truth\",\n",
    "    \"Lorine tells the truth\",\n",
    "    \"Michaela tells the truth\",\n",
    "    \"Millicent tells the truth\",\n",
    "    \"Osvaldo tells the truth\",\n",
    "    \"Phoebe tells the truth\",\n",
    "    \"Rashida tells the truth\",\n",
    "    \"Ryan tells the truth\",\n",
    "    \"Sal tells the truth\",\n",
    "    \"Shaunda tells the truth\",\n",
    "    \"Shenna tells the truth\",\n",
    "    \"Sherrie tells the truth\",\n",
    "    \"Teressa tells the truth\",\n",
    "    \"Yoland tells the truth\",\n",
    "    \"Yes\",\n",
    "    \"Yes, Alexis tells the truth\",\n",
    "    \"Yes, Bernita tells the truth\",\n",
    "    \"Yes, Maybelle tells the truth\",\n",
    "    'Ka is telling the truth',\n",
    "    \"true\",\n",
    "    'Shenna is telling the truth',\n",
    "    'Vina tells the truth',\n",
    "]\n",
    "\n",
    "# False (No)\n",
    "false_no = [\n",
    "    \"False\",\n",
    "    \"Michaela does not tell the truth\",\n",
    "    \"Amberly does not tell the truth\",\n",
    "    \"Amberly is not telling the truth\",\n",
    "    \"Bernita does not tell the truth\",\n",
    "    \"Bernita is not telling the truth\",\n",
    "    \"Christie does not tell the truth\",\n",
    "    \"Conception does not tell the truth\",\n",
    "    \"Delbert does not tell the truth\",\n",
    "    \"Delfina does not tell the truth\",\n",
    "    \"Delfina lies\",\n",
    "    \"Elanor does not tell the truth\",\n",
    "    \"Fidel does not tell the truth\",\n",
    "    \"Gwenn does not tell the truth\",\n",
    "    \"Helene does not tell the truth\",\n",
    "    \"Inga does not tell the truth\",\n",
    "    \"Jamey does not tell the truth\",\n",
    "    \"Jaymie does not tell the truth\",\n",
    "    \"Jerry does not tell the truth\",\n",
    "    \"Jim does not tell the truth\",\n",
    "    \"Jim lies\",\n",
    "    \"Ka does not tell the truth\",\n",
    "    \"Kandi does not tell the truth\",\n",
    "    \"Kandi is lying\",\n",
    "    \"Lorine does not tell the truth\",\n",
    "    \"Millicent does not tell the truth\",\n",
    "    \"Millicent is not telling the truth\",\n",
    "    \"Millie does not tell the truth\",\n",
    "    \"No, Alexis does not tell the truth\",\n",
    "    \"No, Ka does not tell the truth\",\n",
    "    \"No, Shalonda does not tell the truth\",\n",
    "    \"Rashida does not tell the truth\",\n",
    "    \"Raymond does not tell the truth\",\n",
    "    \"Ryan does not tell the truth\",\n",
    "    \"Sal does not tell the truth\",\n",
    "    \"Shalonda does not tell the truth\",\n",
    "    \"Shaunda does not tell the truth\",\n",
    "    \"Shenna does not tell the truth\",\n",
    "    \"Tamika does not tell the truth\",\n",
    "    \"Teressa does not tell the truth\",\n",
    "    \"Vina does not tell the truth\",\n",
    "    \"Willian does not tell the truth\",\n",
    "    \"No\",\n",
    "    'Leda lies',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def map_fn(ins):\n",
    "    for yes in truth_yes:\n",
    "        if yes == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"Yes\"\n",
    "            }\n",
    "\n",
    "    for no in false_no:\n",
    "        if no == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"No\"\n",
    "            }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)\n",
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209c3c8b21a542eca954c4b97841787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, No\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "Yes, No\n",
      "\n",
      "No, Yes\n",
      "\n",
      "No, Yes\n",
      "\n",
      "Yes, No\n",
      "\n",
      "Yes, No\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"])) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'word_sorting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/dev/self-discover/evals/logs/phased_self_discover/mistral/unstructured/few_shot_0/bbh/bbh-word_sorting/bbh-word_sorting_eval')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = here(os.path.join(base_path, f\"bbh-{subset}\", f\"bbh-{subset}_eval\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Identify the Words to be Sorted**\n",
      "   - Words: \"syndrome\", \"therefrom\"\n",
      "\n",
      "2. **Understand Alphabetical Order**\n",
      "   - Alphabetical order: A, B, C, ..., Z.\n",
      "\n",
      "3. **Compare the First Letters**\n",
      "   - First letter of \"syndrome\": 's'\n",
      "   - First letter of \"therefrom\": 't'\n",
      "   - Since 's' comes before 't' in the alphabet, \"syndrome\" comes before \"therefrom\".\n",
      "\n",
      "4. **Compare Subsequent Letters if Necessary**\n",
      "   - In this case, the first letters are different, so no further comparison is needed.\n",
      "\n",
      "5. **Determine the Order**\n",
      "   - The correct alphabetical order is: \"syndrome\", \"therefrom\".\n",
      "\n",
      "6. **List the Words in Alphabetical Order**\n",
      "   - Alphabetical order: \"syndrome\", \"therefrom\".\n",
      "\n",
      "The final answer is \"syndrome\", \"therefrom\".\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_pred_list = [x.translate(str.maketrans(\"\", \"\", \".'\")) for x in dataset[\"answer_pred\"] if x and '[' in x]\n",
    "len(answer_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block',\n",
       " 'custodian',\n",
       " 'deadwood',\n",
       " 'foxtail',\n",
       " 'guaranty',\n",
       " 'hexadecimal',\n",
       " 'macedonia',\n",
       " 'rubaiyat',\n",
       " 'victoria']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_pred_list[0].translate(str.maketrans(\"\", \"\", \"[]\")).split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"above\", \"big\", \"broken\", \"coexist\", \"dominate\", \"irk\", \"olive\", \"prometheus\", \"screw\", \"thirdhand\".',\n",
       " '\"acidify,\" \"antagonism,\" \"asteria.\"',\n",
       " '\"amperage\", \"protocol\", \"crimea\", \"farther\", \"raillery\", \"tech\", \"insolent\", \"ping\", \"stephen\".',\n",
       " '\"apprehension\", \"cashew\", \"ensemble\".',\n",
       " '\"bandwidth\", \"hidebound\", \"wreak\".',\n",
       " '\"bengal,\" \"fettle,\" \"yeager.\"',\n",
       " '\"beth\", \"kenya\".',\n",
       " '\"borough\", \"hyperboloidal\".',\n",
       " '\"brewster\", \"inaudible\", \"synapse\", \"tithing\", \"tuba\".',\n",
       " '\"broaden\", \"envy\".',\n",
       " '\"bucolic,\" \"oblong,\" \"whoosh.\"',\n",
       " '\"budd deform\".',\n",
       " '\"campfire\", \"contrast\", \"crowfoot\", \"purgatory\", \"scrupulous\".',\n",
       " '\"catechism\", \"daddy\".',\n",
       " '\"chicanery,\" \"fugue,\" \"mountain.\"',\n",
       " '\"chrysalis\", \"wallaby\".',\n",
       " '\"compton\", \"confident\", \"foundling\", \"pam\", \"saprophytic\", \"stowaway\", \"stupor\".',\n",
       " '\"coven\", \"disturb\", \"etruscan\", \"lorenz\", \"plastisol\", \"runneth\", \"shouldn\\'t\", \"skintight\", \"swept\".',\n",
       " '\"crag cutover clytemnestra diocletian dickson electrolytic inhuman lipton marginal scrawny stalk took thereupon wireman workplace wife\".',\n",
       " '\"daddy\", \"hirsute\", \"confrontation\", \"proserpine\", \"proofread\", \"quantitative\".',\n",
       " '\"damon\", \"europa\", \"foliate\", \"potpourri\".',\n",
       " '\"dulse,\" \"politician,\" \"yew,\" \"kowalewski.\"',\n",
       " '\"geld,\" \"phase,\" \"thunder.\"',\n",
       " '\"gloucester\", \"raytheon\", \"slurp\".',\n",
       " '\"haughty\", \"seashore\".',\n",
       " '\"ia\", \"bone\", \"convergent\", \"doleful\", \"homeobox\", \"hindustan\", \"sweatshirt\", \"wagoneer\".',\n",
       " '\"laudatory\", \"shakespearian\".',\n",
       " '\"leasehold\", \"orchestra\", \"permafrost\", \"shiva\", \"testate\".',\n",
       " '\"lise,\" \"miaow,\" \"snipe.\"',\n",
       " '\"muddy\", \"nascent\".',\n",
       " '\"murray\", \"sweatband\".',\n",
       " '\"neff,\" \"nicodemus,\" \"sortie.\"',\n",
       " '\"presto\", \"fasciculate\", \"judicature\".',\n",
       " '\"skimpy\", \"zoroaster\".',\n",
       " '\"syndrome\", \"therefrom\".',\n",
       " None,\n",
       " '[\"appliance\", \"impede\", \"pulitzer\", \"superior\"].',\n",
       " '[\"cartilaginous\", \"no\", \"science\", \"spokane\", \"that\\'d\"].',\n",
       " '[\"caruso\", \"chassis\", \"corporal\", \"signora\"].',\n",
       " '[\"consonant\", \"globule\", \"jacob\", \"musician\", \"sleight\"].',\n",
       " '[\"erg\", \"inability\", \"invocable\", \"janice\", \"possible\", \"vague\", \"nucleus\"].',\n",
       " '[\"lease\", \"labile\", \"dnieper\", \"soulful\", \"vehicular\"].',\n",
       " '[block, custodian, deadwood, foxtail, guaranty, hexadecimal, macedonia, rubaiyat, victoria].',\n",
       " '`[\"anastomosis\", \"backslide\", \"calvert\", \"commando\", \"gabriel\", \"hendrickson\", \"hollister\", \"jackson\", \"pizzicato\", \"quail\", \"separate\", \"shelter\", \"spongy\", \"sticktight\", \"syndicate\", \"variety\", \"washy\"]`.',\n",
       " '`[\"antler\", \"christiana\", \"falter\", \"invigorate\", \"jot\", \"kamikaze\", \"landlady\", \"libya\", \"ludlow\", \"mallow\", \"porridge\", \"residuary\", \"tuscarora\", \"wetland\", \"wrapup\"]`.',\n",
       " '`[batavia, canaan, maladjust, merry, olefin, ranch, relinquish, yang]`.',\n",
       " '`[besetting, boyd, counterweight, detergent, groove, hide, intangible, menlo, nv, ovipositor, sans, spumoni]`.',\n",
       " '`aberdeen`, `analogue`, `deciduous`, `easel`, `sprightly`, `swaziland`.',\n",
       " '`abner`, `abramson`, `amity`, `automate`, `exquisite`, `fruitful`, `gurgle`, `none`, `shampoo`, `shorten`, `waterproof`.',\n",
       " '`abo`, `armful`, `bonaventure`, `cremate`, `dictatorial`, `embryology`, `frond`, `gasify`, `guiana`, `herman`, `indistinguishable`, `oscillatory`, `pancreatic`, `passenger`, `referential`, `stockholder`, `through`, `tip`.',\n",
       " \"`accelerate`, `bauer`, `county`, `nail`, `nominee`, `o'connell`, `phony`, `poole`, `putnam`, `quantify`, `raisin`, `venice`.\",\n",
       " '`acoustic`, `anarchic`, `bureaucracy`, `diatom`, `fabricate`, `guelph`, `immovable`, `leftward`, `liven`, `neo`, `phenomenology`, `provide`, `shortcut`, `suggestive`, `syndrome`, `total`, `trammel`, `usage`, `yarmulke`.',\n",
       " '`adipic, antique, athlete, atonic, catch, encumber, lauderdale, neutrino, olivia, persona, sovereignty, specify, statuette, whiteface`.',\n",
       " '`admixture`, `across`, `directrix`, `flight`, `gut`, `indicate`, `marshal`, `predacious`, `quagmire`, `smuggle`, `vantage`.',\n",
       " '`affirmative, airframe, arcing, ballroom, bassoon, benefit, buggy, coupon, decide, dodge, hypothermia, intrepid, junior, ladle, nineveh, prorogue, schmitt, shagging, sparse, ulcerate`.',\n",
       " '`agamemnon, clench, depreciate, eject, forum, frame, herbivorous, lien, marcello, numbly, search, sprout, unary, zaire`.',\n",
       " '`agglomerate`, `ballast`, `dollop`, `erosible`, `expiry`, `extensor`, `gazpacho`, `indiscreet`, `manuel`, `ogle`, `oilcloth`, `spaniard`.',\n",
       " '`airlift`, `butch`, `cone`, `homeowner`, `inanimate`, `incurring`, `logarithm`, `lumber`, `maladapt`, `micron`, `newman`, `profuse`, `robertson`, `sammy`, `souvenir`, `uganda`, `wilcox`.',\n",
       " '`alkali`, `breach`, `buckle`, `falsetto`, `hyperboloid`, `liquidate`, `mirth`, `nagasaki`, `parmesan`.',\n",
       " '`allele anthropocentric banish bartok badinage brunswick dale dar desolater dun fraternity goat martinson morphemic monomer pegging starkey underclassmen whoop yourself`.',\n",
       " '`allocate, ann, bishopric, blake, carbondale, casual, cometh, confirmatory, crinkle, degum, elliot, expatriate, hangable, neal, orthodontist, shenandoah, soybean, telegraph, tuxedo, unipolar`.',\n",
       " '`amanita, amatory, annoy, besiege, boggle, california, canticle, crocodilian, dexter, dizzy, dissipate, encephalitis, hornblower, notre, pasture, propylene, psychiatric, sepia, snipe, straight`.',\n",
       " '`amerada, craftsmen, din, eclipse, gaillardia, inroad, jackboot, jest, jordan, kill, mirth, nate, pomade, putt, shortcoming, spruce, whelan`.',\n",
       " '`amethyst`, `bathos`, `dormouse`, `obtuse`, `resignation`, `walt`.',\n",
       " \"`amicable, browne, calumny, coo, deerstalker, extreme, henchman, histology, indoeuropean, paginate, pelvis, sonority, they've, tramway, turvy`.\",\n",
       " '`analyses, augustine, blueback, credential, den, erda, falter, fireproof, geophysics, guitar, keynote, meter, porte, shibboleth, stonewort, swampland, telephony, testimonial, timeshare, usa`.',\n",
       " '`anaplasmosis bumble chopstick clue fiesta footwork fresco ingot orthography palisade pilate saul smalley storey teen`.',\n",
       " '`aniline, boletus, eddy, fontainebleau, galveston, gentle, scandalous, skat, sportsmen, wile`.',\n",
       " '`animism`, `awash`, `beau`, `bessie`, `cream`, `extricable`, `helical`, `indoeuropean`, `pendulum`, `sanhedrin`, `scratchy`, `venezuela`, `vice`.',\n",
       " '`announce, carp, co, clayton, earthy, hello, inmate, nimbus, parentage, phonetic, sharon, skinny, sudan, watson`.',\n",
       " '`aperture`, `bradshaw`, `holocene`, `mare`, `muriel`, `pathetic`, `r&d`, `sigh`, `staircase`, `talon`.',\n",
       " '`appoint, baneberry, biharmonic, dyne, moustache, pirate, windowsill, wiry`.',\n",
       " '`arapaho`, `bacteria`, `bela`, `bock`, `burley`.',\n",
       " \"`archery`, `arlen`, `barbudo`, `bride`, `coquette`, `lockwood`, `lucrative`, `officious`, `polytypy`, `radix`, `teem`, `tunnel`, `you've`.\",\n",
       " '`arraign`, `blutwurst`, `convenient`, `faber`, `glacier`, `horizon`, `inconspicuous`, `peste`, `portentous`, `rancho`, `uranyl`.',\n",
       " '`arrear, brookside, eavesdropping, fasciculate, henry, hermaphrodite, herodotus, ibn, incorrigible, jane, linchpin, maritime, postdoctoral, shin, sticky, vehicular`.',\n",
       " '`artillery`, `bainite`, `doris`, `fda`, `harm`, `incongruous`, `monkey`, `prosody`, `vegetate`, `vivian`.',\n",
       " '`astigmat, boyish, coriolanus, cutlet, creak, easternmost, godson, heaven, highwaymen, leather, muscular, musky, paula, scavenge, synaptic, zinc`.',\n",
       " '`atavism`, `contrariety`, `crochet`, `dimorphic`, `emanate`, `forthwith`, `grind`, `guaranteeing`, `hoop`, `hurty`, `iniquity`, `katie`, `more`, `muong`, `polytope`, `prodigy`, `titrate`.',\n",
       " '`az, doff, upon, accomplice, labour, crepe, choral, clatter, fairfax, circumcircle, tea, pleura, incantation, prig, whim, ride, lorry, viaduct, wheelbase, emission`.',\n",
       " '`bate`, `giantess`, `garrison`, `callous`, `climb`, `dnieper`, `dogging`, `cortez`, `mast`, `moran`, `staunch`, `satisfy`, `prank`, `muddy`, `reverie`.',\n",
       " '`bedtime`, `boon`, `bottle`, `chapati`, `kenney`, `okinawa`.',\n",
       " '`benefice`, `improvise`, `nevins`, `protein`, `puree`, `pusey`, `pullman`, `river`, `squeamish`, `whale`.',\n",
       " '`berra`, `calabash`, `hen`, `episode`, `marietta`, `molybdenum`, `pedantic`, `pounce`, `schedule`, `sparkman`, `vinaigrette`.',\n",
       " '`bijective`, `briton`, `concord`, `dim`, `dive`, `eigenspace`, `floruit`, `gaucherie`, `glycogen`, `guidebook`, `irrevocable`, `jacket`, `pinkish`, `reversible`, `song`.',\n",
       " '`bilk`, `lethe`, `perturb`, `tactual`.',\n",
       " \"`bivalve`, `mainstream`, `malformed`, `mortify`, `o'connell`, `paunchy`, `sleuth`, `twelvefold`, `umbilical`, `vinegar`.\",\n",
       " '`blest`, `buxton`, `consternate`, `proximity`, `quizzes`, `sound`, `tariff`, `xerxes`.',\n",
       " '`blythe, bombproof, code, corpulent, cytolysis, damn, diagnose, fluorine, honeybee, maharaja, pore, scalp, solicit, swipe`.',\n",
       " '`boldface`, `darkle`, `fungi`, `gobble`, `inflammation`, `jacqueline`, `joanne`, `macaque`, `piano`, `schiller`, `slump`, `sojourn`, `sst`.',\n",
       " '`boletus`, `calypso`, `conklin`, `debugging`, `deportee`, `lucretia`, `necktie`, `omnipotent`, `passband`, `revving`, `ulysses`.',\n",
       " '`bonito`, `nose`, `dreamboat`, `haggard`, `fritter`, `whodunit`, `worcestershire`.',\n",
       " '`booby`, `butadiene`, `flair`, `functor`, `heck`, `orphanage`, `racy`, `rheumatic`, `shivery`, `sin`, `snowball`, `spec`, `testy`, `trench`, `zorn`.',\n",
       " '`brainwash`, `broom`, `deathward`, `faithful`, `gondola`, `integer`, `kinematic`, `menu`, `soc`.',\n",
       " '`brindle`, `clifford`, `florist`, `gloat`, `sacramento`, `siskin`, `triploidy`, `willard`.',\n",
       " '`calligraph, form, goat, inverness, sibyl, threadbare`.',\n",
       " '`captious`, `elton`, `iodinate`, `ineligible`, `olympic`, `sherman`.',\n",
       " '`cheddar`, `edt`, `from`, `oblivion`, `pang`, `poignant`, `yuh`.',\n",
       " '`christen, clearheaded, despond, driveway, encapsulate, fungi, gob, mendelevium, midwinter, purpose, sisyphus, stanhope, strip, studious, symmetry, trample, vs, wring`.',\n",
       " '`confidential`, `faery`, `fiction`, `heterozygous`, `horehound`, `overture`, `ursa`.',\n",
       " \"`convey`, `decimate`, `experiment`, `fortieth`, `incautious`, `kudo`, `marshall`, `neoclassic`, `rest`, `whimper`, `wiley`, `xylem`, `z's`.\",\n",
       " '`coplanar`, `natalie`, `stevenson`, `zan`.',\n",
       " '`core`, `discreet`, `hat`, `sonnet`.',\n",
       " '`cotyledon`, `more`, `pepperoni`, `regret`, `starlight`, `wallboard`.',\n",
       " '`covenant`, `davenport`, `densitometer`, `noisy`, `scoreboard`, `sonorant`, `thence`.',\n",
       " '`crude`, `cunard`, `danubian`, `inscribe`, `peculate`, `perceptive`, `posterior`, `tragedian`, `upraise`.',\n",
       " '`fortescue`, `purloin`, `percept`, `helmsman`, `sioux`.',\n",
       " '`fracture`, `sediment`, `towel`, `varsity`.',\n",
       " '`household`, `dateline`, `jill`, `langmuir`, `pipette`.',\n",
       " '`nat`, `kajar`, `downey`, `detest`, `aitken`, `barycentric`, `vision`, `solvate`, `usable`.',\n",
       " '`pro, carbonic, have, countersink, corvallis, choreograph, equestrian, authenticate, multifarious, petition, libya, metal, nitric, obfuscatory, retardant, wishful, wigwam`.',\n",
       " '`tty, seepage, shelf, sideboard, buxton, methanol, olympic, cameron, callus, marque, unitary, contribute, precise, verify, extensible, typescript, procrustean`.',\n",
       " 'abbas, average, bridesmaid, catsup, charm, coddle, dogfish, hypothalamus, inconvertible, inequity, integral, invocable, memorandum, multiplet, phloem, region, scherzo, shutout, therewith, trumpery',\n",
       " 'abbe, adposition, arragon, cast, danbury, emplace, falsetto, gavin, income, inhibit, onerous, palazzi, tabletop',\n",
       " 'abc, ada, austere, blend, cankerworm, falcon, flamboyant, gag, grecian, hanukkah, indicate, kruger, lobster, militia, nobody, pierson, quad, right, ron, wildcat',\n",
       " 'abdominal, address, berry, bounty, effusive, fomalhaut, hanoverian, involve, islamabad, jordan, optimal, pay, stearic, stigmata, swathe, tattoo, them, tornado, yang.',\n",
       " 'absorption, aristocratic, bermuda, cesium, cheerful, congo, diagram, ezra, eucre, fallen, juvenile, musty, nigeria, nod, quartile, screechy, slack, testicle',\n",
       " 'abstract, borough, brown, cosec, cortex, delphinium, diminutive, fleabane, foot, guy, hair, highfalutin, ipsilateral, longish, mobster, richfield, trapezoidal, ugh, wintertime.',\n",
       " 'abutted, agamemnon, aquatic, capacity, casualty, essex, guinea, hitachi, islamic, loosen, loquacious, niece, planet, roadway, solstice, steed, suspicion, tibet.',\n",
       " 'academia, amos, beautiful, butterscotch, circuitous, diatom, europium, extoller, farrell, fiducial, ford, glance, kochab, metzler, molybdate, monomer, predatory, veterinarian.',\n",
       " 'accept, alpenstock, angus, castigate, chromium, concision, doge, drool, elizabethan, jutish, marshmallow, octennial, ocean, prize, resistive, stonewort, vociferous.',\n",
       " 'accept, avoid, carbuncle, caramel, compressor, conclave, drib, elegy, embower, error, gaillardia, grassland, hostile, pitfall, rosa, spectra, stepchild, utopia, whimsey.',\n",
       " 'accessory, admiration, allusion, bandgap, bruckner, cruise, fungus, gambit, heron, maidenhair, postprocessor, proscenium, technion.',\n",
       " 'acclaim, champ, commodity, clothbound, conclusion, exempt, delirious, dyestuff, jigsaw, lozenge, gadwall, hood, hayes, pipeline, plentiful, sensory, seashell, sarcastic, teen, hypothalamus.',\n",
       " 'accrue, archipelago, biplane, breezy, canada, conspiracy, constructor, dobbin, germinal, hamburger, insubstantial, laramie, lost, malleable, nutrient, peloponnese, ted, thigh.',\n",
       " 'acquisitive, annuity, autocracy, bruno, custody, dare, exploitation, lodge, militant, quench, somatic, thunderclap, ventricle',\n",
       " 'acrobacy, ape, apostate, advisee, cardigan, chancery, cochran, crowbait, equip, evildoer, hillman, hoofprint, kuwait, max, molten, practise, retinue, sloane, wuhan.',\n",
       " \"acuity, anticonvulsant, carrageen, discovery, drafty, disseminate, embolden, glamour, hangout, hasty, magnificent, pewee, proscenium, registrar, scrub, sushi, supposable, you'd\",\n",
       " 'admixture, chateaux, coordinate, higgins, shelve, catwalk, panamanian, reluctant, suction, irremediable, offertory, malthusian, tunis, pecos, equine.',\n",
       " 'adopt, wage, multitudinous, afghan, glimmer, friday, pacifist, worcestershire.',\n",
       " 'advent, anger, convoy, deliver, filly, gneiss, grocer, hessian, hotbox, landau, marlborough, ninebark, platelet, plat, pyrotechnic, siemens, stapleton, treadle, transitive, uncle.',\n",
       " 'aerodynamic, botanist, giacomo, habitation, jimmy, nebulous, offset, padre, panicking, roosevelt, schoolmate, suburbia, vector, wv',\n",
       " 'affluent, cheshire, covalent, diagnostician, divisive, epsilon, folklore, gideon, gothic, grover, horowitz, julio, peanut, quadrature, salient, spiderwort, spiritual.',\n",
       " 'afro, blackbird, blame, calyx, elgin, emphases, implacable, jura, mayapple, perquisite, vii, whit.',\n",
       " 'afternoon, complementary, dixie, hesitate, horsepower, immaculate, kind, laughlin, loire, mechanism, nimble, sandia, septuagenarian, shuffleboard, sierra, toggle, woebegone.',\n",
       " 'aggression, arachne, asplenium, bystander, definite, gneiss, lengthy, sanford, southeast, translate.',\n",
       " 'agile, blackguard, butt, clapeyron, cognoscenti, flamboyant, geophysical, lightfooted, lift, manumitted, mathieu, meager, purposive, reconnaissance, sawbelly, scribe, seaworthy, wiseacre, woodcut, yves',\n",
       " 'agrarian, applicate, candid, colossus, sheepskin, haddock, honeymoon, people, pragmatic.',\n",
       " 'alcohol, behold, escutcheon, forth, fumarole, hackberry, motif, pease, regret, satisfy, uptake, walkie.',\n",
       " 'aldebaran, backyard, boxwood, cabbage, fiberboard, game, inkling, invincible, lakeside, lightface, matte, mcgee, entrepreneurial, peruse, polyhedra, pulsate, rae, rowley, shape, watchworks.',\n",
       " 'algonquin, beachhead, bloodstain, dilate, forth, frolic, lacunae, lazy, liggett, mcintosh, parameter, piggish, pintail, protector, slaughterhouse, sterno, unesco',\n",
       " 'allegoric, collate, euphony, gloriana, loge, lollipop, mast, milord, prolix, rendezvous, salle, schnabel.',\n",
       " 'alleviate, benelux, buoyant, duopoly, felice, gland, gunk, hardbound, klaxon, mattress, tomography, townsmen.',\n",
       " 'allot, chauncey, coachmen, coddington, clergymen, companion, embark, fatten, gazpacho, granular, hobble, murk, muslim, niggle, pristine, pvc, singlet, threefold, too, yeats',\n",
       " 'allyn, carbonaceous, cetacean, investigatory, johann, majorca, paradigmatic, pathogenic, pray, supersede, tung',\n",
       " 'almagest, archenemy, catawba, councilwomen, decrement, gnome, jungian, limpid, milt, photolysis, sagging, transfusable.',\n",
       " 'almost, antic, apache, astute, affable, deadlock, delphic, dandelion, execution, fortunate, horntail, levitate, leverage, libertarian, sanction, scathe, semitic, storehouse, sweeney, unbeknownst.',\n",
       " 'alphabet, birmingham, cantonese, educate, entourage, fashion, fond, marimba, mechanic, philology, retrofit.',\n",
       " 'alterate, aseptic, cayenne, chandigarh, dingy, debauch, declassify, equanimity, excursion, foamflower, groupoid, inclement, kruger, lawful, october, only, scorch.',\n",
       " 'altercate, cornerstone, courtroom, dusenberg, foraminifera, gossamer, insist, jive, promulgate, raft, sal, sophocles, syllabus, wrongdoer.',\n",
       " 'alternate, boone, chalcedony, charity, genteel, million, olden, satin, sinai.',\n",
       " 'alveolar, arabesque, arkansan, bed, bedroom, bend, brassiere, curvilinear, deterrent, diagnosable, fluke, fossiliferous, novel, patrolman, planeload, sheep, spearmint, trident, yen, ytterbium',\n",
       " \"ambient, appropriable, arroyo, billion, breccia, coupon, eardrum, faze, fivefold, intimidate, martinson, o'connor, perplex, secretary, social, surtout, terrestrial, voltmeter.\",\n",
       " 'ami, bituminous, decadent, exeter, knickerbocker.',\n",
       " 'anaglyph, cowbell, duane, fest, glamour, harriet, impressible, switchboard, texture, vietnamese, whippet',\n",
       " 'anaheim, clinic, eaten, immemorial, madeira, marx, micro, offprint, sprue, subject, trafficked, va',\n",
       " 'anarchic, bstj, elution, exhumation, furl, geld, gradual, j, liniment, locomote, midshipman, pantheist, profess, riddance, rowley, saline',\n",
       " 'anchor, barre, buckle, concatenate, dimension, edgy, eleanor, epiphyte, faunal, integrate, masochist, orthodoxy, patrician, parasol, pendant, sail, singular, swift.',\n",
       " 'anharmonic, beauteous, coypu, inflammation.',\n",
       " 'anheuser, bungle, chaperon, frame, hippodrome, keller, miterwort, prompt, spidery, together, yolk.',\n",
       " 'antaeus, caw, daughter, devonshire, gloria, helvetica, hi, leatherback, magnesium, megohm, nikko, raincoat, schroedinger, scald, sojourn, terminal, woodcarver',\n",
       " 'anthology, allis, jacobi, membrane, marmot, toggle, oakland, seaborg, trapezoidal.',\n",
       " 'apparition, conference, copra, coupe, dutton, floruit, ignore, implement, layperson, messenger, primitive, superstitious, turnoff, westward',\n",
       " 'aqueous, deregulate, gala, lysergic, infantrymen, knob, yaounde.',\n",
       " 'arenaceous, baccarat, blare, bowman, earl, gloss, granola, hollandaise, inauspicious, mackenzie, metaphoric, pedro, penis, psyche, quarantine, roadster, supranational.',\n",
       " 'aroma, carcinogen, delmarva, designate, facetious, nod, parochial, rally, sawfly, syllabus',\n",
       " 'artful, cancelled, castrate, citadel, croon, ear, endpoint, excite, glaucous, inspiration, marque, mckinley, prig, pesticide, radiometer, relish, rothschild, school, tioga, trianon.',\n",
       " 'asset, bona, cicero, coastal, dusky, exonerate, gaussian, handlebar, inhabitation, portfolio, purport, rastus, responsible, ruanda, silver, zig',\n",
       " 'assimilable, bivariate, bought, calypso, dogwood, functor, hideaway, holeable, lola, monotonous, nebuchadnezzar, pacifism, provocation, slick',\n",
       " 'atmospheric, chess, credit, geopolitic, intercept, loci, lunge, newsmen, siren, swart, tamp, umber.',\n",
       " 'audacious, battleground, bulrush, filamentous, harris, intervenor, municipal, rubicund, semaphore, sensate, xylophone.',\n",
       " 'auerbach, decor, deoxyribose, devisee, dianne, hodges, incommensurable, motorcade, stratify, troupe.',\n",
       " 'avalanche, befriend, berniece, bong, bremsstrahlung, dactylic, flick, goff, gilbertson, hereafter, hoe, housekeep, hurry, lanka, metazoan, posterior, showroom',\n",
       " \"avoidance, casualty, courtier, gibbon, leprosy, merge, sidewinder, shouldn't, tacky, transgressor.\",\n",
       " 'awash, auxin, bateau, cubit, eutectic, gown, gullible, inane, jurisprudential, mistletoe, nepenthe, ow, pirouette, pussycat, scottsdale, schwartz, shockley, travelogue, upbring.',\n",
       " 'babysat, consul, curvaceous, cutaneous, hugh, regiment, spoke, stationarity.',\n",
       " 'backpack, coffman, cotman, collision, detour, gnostic, hammock, jacobean, lung, membrane, monologist, notate, quirinal, rhubarb, secretive, stove, tobacco.',\n",
       " 'baden, bizarre, claret, colonist, deplore, dove, horticulture, monaco, paschal, play, rodriguez, sonant, strap, valuate.',\n",
       " 'ballard, brindle, cornerstone, credulous, curio, des, difluoride, green, horseplay, jew, mixup, nonce, nostalgic, pitney, predilect, prowl, rape, scrappy, toward',\n",
       " 'battery, bushland, capacitive, contingent, crossbill, enigma, jane, lipton, meager, ricochet, wallet, wacke, wysiwyg',\n",
       " 'behold, dew, dissipate, format, hew, maybe, misogyny, oxalic, pray, steel, stiffen, termcap',\n",
       " 'berg, bluish, gamut, multiplexor, puerto, shreveport, subliminal.',\n",
       " 'biennial, cry, creedal, eyesight, fletch, fraudulent, j, miltonic, mirage, titmice, whisper.',\n",
       " 'bilinear, brenda, cacao, chivalry, derivate, eaten, endothelial, ferocity, gastronomic, grammarian, irreducible, knutson, phenotype, polkadot, rockaway, scurrilous.',\n",
       " \"bindle, chiang, crystallography, dent, mambo, ram, roadside, rundown, savannah, shipshape, spew, strange, survey, won't\",\n",
       " 'bizarre, contravention, drapery, dreg, ingratiate, margaret, peculiar, sequential, superintendent.',\n",
       " 'blunderbuss, box, dinnertime, feel, frugal, labial, oresteia, papaw, perfidious, sonar.',\n",
       " 'bologna, crackle, cure, cottrell, doubtful, entropy, extoller, gloria, litigant, procedural, summand, tyke.',\n",
       " 'bootlegging, indifferent, trainman.',\n",
       " 'bosporus, bully, cork, edt, flogging, forfeit, lexicographer, minor, multiple, perceptive, pizza, pungent, rancorous, reedy, referring, sedition, sell, tit',\n",
       " 'broadcast, cortland, diffusible, galvanometer, gross, gujarati, incestuous, larynx, nomograph, pewter, scout, sketchbook, stag, transition',\n",
       " 'buckley, frisian, ix, livre, panoramic, substitution.',\n",
       " 'cabdriver, pivot, loch, coherent, astronomic, wagging.',\n",
       " \"caching, defend, delicious, distort, emboss, epistemology, gherkin, injustice, indicate, maser, percent, phillip, roadside, savoyard, somewhat, spicy, we're, winston\",\n",
       " 'celandine, diploma, faith, harold, hostile, mohawk, octavia, supercilious, thebes.',\n",
       " 'charcuterie, crucifix, diatom, footfall, greenberg, impenetrable, muddle, spoken, synchronous.',\n",
       " 'chlorate, judicatory, glidden, lavoisier, incentive, manatee, spurt.',\n",
       " 'cite, coleus, fructose, hurricane, improbable, irreducible, tularemia, tipoff, vesper, whereabout, whitetail, wier',\n",
       " 'citrus, cloudy, euclidean, fight, hobby, invite, majestic, scene, stonehenge, surge, thrifty, winsome.',\n",
       " 'cloudy, ecosystem, ferret, knotty.',\n",
       " 'comet, cocksure, heusen, hydrate, injun, manley, pincer, snippet, spokesperson.',\n",
       " 'conglomerate, dynastic, inflammable, nebulae, phosphide, prick, stagnate, tackle, tristan, vitiate.',\n",
       " 'correspond herpes him seashore',\n",
       " 'cortex, insane, incident, kangaroo, marionette, mcleod, pillage, roundabout, sinter, stipulate, threshold, trammel',\n",
       " 'darkle, erudite, hookup, instant, lip, moldboard, olsen, pea, quadrant, yonkers.',\n",
       " 'dean, eosine, formula, gibson, inebriate, mater, mulligatawny, rica, sigmund, vassar.',\n",
       " 'dose, dyad, allstate, multitudinous, powderpuff, stalin, plural.',\n",
       " 'downtrodden, gadgetry, gamin, hurst, inertial, maraud, morphine, parsonage, propane.',\n",
       " 'extempore, gotten.',\n",
       " 'greasy, lapidary, mark.',\n",
       " 'novelty, rectitude, splashy.',\n",
       " 'paste, snip, southeastern, feign, eyelid, libra, wherewith, bertrand, careful, heterostructure.',\n",
       " 'scoot, polyhedron, jugoslavia, retrorocket, walnut.',\n",
       " 'swab, built, poland, thunderclap.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc6db35360e4afb92ae3e32a87d6722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sort the given list of words alphabetically, we can follow these steps:\n",
      "\n",
      "1. **Write Down the List of Words**:\n",
      "   - List: thrill, splutter, panicking, scorch, same, dot, prod, obstetric, malton, onus, drumhead, delmarva, barn, embezzle, it&t, damp, guru, subsist, entirety, greene.\n",
      "\n",
      "2. **Use a Built-in Sorting Function**:\n",
      "   - In Python, you can use the `sorted()` function.\n",
      "   - Example code:\n",
      "     ```python\n",
      "     words = [\"thrill\", \"splutter\", \"panicking\", \"scorch\", \"same\", \"dot\", \"prod\", \"obstetric\", \"malton\", \"onus\", \"drumhead\", \"delmarva\", \"barn\", \"embezzle\", \"it&t\", \"damp\", \"guru\", \"subsist\", \"entirety\", \"greene\"]\n",
      "     sorted_words = sorted(words)\n",
      "     ```\n",
      "\n",
      "3. **Verify the Sorted List**:\n",
      "   - Print or display the sorted list to ensure it is in alphabetical order.\n",
      "   - Example output:\n",
      "     ```python\n",
      "     print(sorted_words)\n",
      "     ```\n",
      "\n",
      "By following these steps, the sorted list of words is:\n",
      "\n",
      "- barn\n",
      "- damp\n",
      "- delmarva\n",
      "- dot\n",
      "- drumhead\n",
      "- embezzle\n",
      "- entirety\n",
      "- greene\n",
      "- guru\n",
      "- it&t\n",
      "- malton\n",
      "- obstetric\n",
      "- onus\n",
      "- panicking\n",
      "- prod\n",
      "- same\n",
      "- scorch\n",
      "- splutter\n",
      "- subsist\n",
      "- thrill\n",
      "\n",
      "The final answer is:\n",
      "- barn\n",
      "- damp\n",
      "- delmarva\n",
      "- dot\n",
      "- drumhead\n",
      "- embezzle\n",
      "- entirety\n",
      "- greene\n",
      "- guru\n",
      "- it&t\n",
      "- malton\n",
      "- obstetric\n",
      "- onus\n",
      "- panicking\n",
      "- prod\n",
      "- same\n",
      "- scorch\n",
      "- splutter\n",
      "- subsist\n",
      "- thrill\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort a list of words alphabetically.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller, manageable groups to make the sorting process easier.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups. For example, divide the list into groups of 5 words each.\n",
      "\n",
      "4. **Sort Each Group**:\n",
      "   - Sort each smaller group alphabetically.\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted smaller groups into a single sorted list.\n",
      "\n",
      "6. **Verify the Sorting**:\n",
      "   - Double-check the final list to ensure it is correctly sorted alphabetically.\n",
      "\n",
      "### Detailed Steps\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - Identify the list of words to be sorted:\n",
      "     ```\n",
      "     torpedo, phosphorescent, pristine, decadent, shrunk, dey, administer, gradate, littleneck, thrown, jacky, coachman, aeneid, verdict, tasting, sinh, delhi, systemwide, grim\n",
      "     ```\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Decide on a method to simplify the task. For example, use the \"divide and conquer\" approach by breaking the list into smaller groups.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups. For instance, divide the list into groups of 5 words each:\n",
      "     ```\n",
      "     Group 1: torpedo, phosphorescent, pristine, decadent, shrunk\n",
      "     Group 2: dey, administer, gradate, littleneck, thrown\n",
      "     Group 3: jacky, coachman, aeneid, verdict, tasting\n",
      "     Group 4: sinh, delhi, systemwide, grim\n",
      "     ```\n",
      "\n",
      "4. **Sort Each Group**:\n",
      "   - Sort each group alphabetically:\n",
      "     ```\n",
      "     Group 1 Sorted: decadent, phosphorescent, pristine, shrunk, torpedo\n",
      "     Group 2 Sorted: administer, dey, gradate, littleneck, thrown\n",
      "     Group 3 Sorted: aeneid, coachman, jacky, tasting, verdict\n",
      "     Group 4 Sorted: delhi, grim, sinh, systemwide\n",
      "     ```\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups into a single sorted list:\n",
      "     ```\n",
      "     Merged List: decadent, phosphorescent, pristine, shrunk, torpedo, administer, dey, gradate, littleneck, thrown, aeneid, coachman, jacky, tasting, verdict, delhi, grim, sinh, systemwide\n",
      "     ```\n",
      "\n",
      "6. **Verify the Sorting**:\n",
      "   - Double-check the final merged list to ensure it is correctly sorted alphabetically.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "```\n",
      "aeneid, administer, coachman, decadent, dey, delhi, gradate, grim, jacky, littleneck, phosphorescent, pristine, shrunk, sinh, systemwide, tasting, thrown, torpedo, verdict\n",
      "```\n",
      "\n",
      "The final answer is:\n",
      "```\n",
      "aeneid, administer, coachman, decadent, dey, delhi, gradate, grim, jacky, littleneck, phosphorescent, pristine, shrunk, sinh, systemwide, tasting, thrown, torpedo, verdict\n",
      "```\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Simplify the Sorting Task**\n",
      "   - Identify the total number of words in the list: 20 words.\n",
      "   - Recognize that the task involves sorting words alphabetically.\n",
      "\n",
      "2. **Break Down the List into Smaller Groups**\n",
      "   - Divide the list into smaller, manageable groups. For example, you can break it down into groups of 5 words each.\n",
      "   - Group 1: spontaneity, smooth, execrable, epaulet, bobbin\n",
      "   - Group 2: calumny, hun, anastasia, omnipotent, award\n",
      "   - Group 3: hostelry, macedon, roughshod, burrow, align\n",
      "   - Group 4: apache, putty, adsorption, anastomotic\n",
      "\n",
      "3. **Identify Appropriate Sorting Algorithms or Techniques**\n",
      "   - Choose a sorting algorithm that is efficient for the task. For simplicity, we can use the Bubble Sort or Insertion Sort algorithm.\n",
      "   - Alternatively, for larger lists, consider using more efficient algorithms like Merge Sort or Quick Sort.\n",
      "\n",
      "4. **Create a Step-by-Step Plan to Sort the Words Alphabetically**\n",
      "   - **Step 4.1: Sort Each Group Individually**\n",
      "     - Sort Group 1 alphabetically:\n",
      "       - bobbin, epaulet, execrable, smooth, spontaneity\n",
      "     - Sort Group 2 alphabetically:\n",
      "       - anastasia, award, calumny, hun, omnipotent\n",
      "     - Sort Group 3 alphabetically:\n",
      "       - align, burrow, hostelry, macedon, roughshod\n",
      "     - Sort Group 4 alphabetically:\n",
      "       - adsorption, anastomotic, apache, putty\n",
      "\n",
      "   - **Step 4.2: Merge the Sorted Groups**\n",
      "     - Merge the sorted groups into a single list while maintaining alphabetical order:\n",
      "       - align, anastasia, apache, award, bobbin, burrow, calumny, epaulet, execrable, hostelry, hun, macedon, omnipotent, putty, roughshod, smooth, spontaneity, adsorption, anastomotic\n",
      "\n",
      "   - **Step 4.3: Final Sorting (if necessary)**\n",
      "     - If the merged list is not fully sorted, apply the chosen sorting algorithm to the entire list to ensure complete alphabetical order.\n",
      "\n",
      "5. **Implement the Sorting Algorithm**\n",
      "   - For each group, compare the first letter of each word.\n",
      "   - If the first letters are the same, compare the second letters, and so on.\n",
      "   - Continue this process until all words in each group are sorted.\n",
      "   - Merge the sorted groups by comparing the first word of each group and proceeding accordingly.\n",
      "\n",
      "6. **Verify the Sorted List**\n",
      "   - Double-check the final list to ensure that it is in correct alphabetical order.\n",
      "   - Compare each word with the next to confirm that no words are out of order.\n",
      "\n",
      "### Final Sorted List\n",
      "- adsorption, align, anastasia, anastomotic, apache, award, bobbin, burrow, calumny, epaulet, execrable, hostelry, hun, macedon, omnipotent, putty, roughshod, smooth, spontaneity\n",
      "\n",
      "The final answer is:\n",
      "adsorption, align, anastasia, anastomotic, apache, award, bobbin, burrow, calumny, epaulet, execrable, hostelry, hun, macedon, omnipotent, putty, roughshod, smooth, spontaneity\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following words alphabetically: \"closeup\", \"thesaurus\", \"intelligent\", \"buckaroo\", \"vertebral\", \"wily\", \"blutwurst\", \"laguerre\".\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller, manageable groups to make the sorting process easier.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into two groups:\n",
      "     - Group 1: \"closeup\", \"thesaurus\", \"intelligent\", \"buckaroo\"\n",
      "     - Group 2: \"vertebral\", \"wily\", \"blutwurst\", \"laguerre\"\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - **Group 1 Sorting**:\n",
      "     - Compare \"closeup\" and \"thesaurus\" → \"closeup\" comes before \"thesaurus\"\n",
      "     - Compare \"closeup\" and \"intelligent\" → \"closeup\" comes before \"intelligent\"\n",
      "     - Compare \"closeup\" and \"buckaroo\" → \"buckaroo\" comes before \"closeup\"\n",
      "     - Compare \"thesaurus\" and \"intelligent\" → \"intelligent\" comes before \"thesaurus\"\n",
      "     - Compare \"buckaroo\" and \"intelligent\" → \"buckaroo\" comes before \"intelligent\"\n",
      "     - Sorted Group 1: \"buckaroo\", \"closeup\", \"intelligent\", \"thesaurus\"\n",
      "\n",
      "   - **Group 2 Sorting**:\n",
      "     - Compare \"vertebral\" and \"wily\" → \"vertebral\" comes before \"wily\"\n",
      "     - Compare \"vertebral\" and \"blutwurst\" → \"blutwurst\" comes before \"vertebral\"\n",
      "     - Compare \"vertebral\" and \"laguerre\" → \"laguerre\" comes before \"vertebral\"\n",
      "     - Compare \"wily\" and \"blutwurst\" → \"blutwurst\" comes before \"wily\"\n",
      "     - Compare \"wily\" and \"laguerre\" → \"laguerre\" comes before \"wily\"\n",
      "     - Compare \"blutwurst\" and \"laguerre\" → \"blutwurst\" comes before \"laguerre\"\n",
      "     - Sorted Group 2: \"blutwurst\", \"laguerre\", \"vertebral\", \"wily\"\n",
      "\n",
      "5. **Merge the Sorted Groups**:\n",
      "   - Compare the first word of Group 1 (\"buckaroo\") with the first word of Group 2 (\"blutwurst\") → \"blutwurst\" comes before \"buckaroo\"\n",
      "   - Compare the next word in Group 2 (\"laguerre\") with \"buckaroo\" → \"buckaroo\" comes before \"laguerre\"\n",
      "   - Continue merging the words from both groups:\n",
      "     - \"blutwurst\", \"buckaroo\", \"closeup\", \"intelligent\", \"laguerre\", \"thesaurus\", \"vertebral\", \"wily\"\n",
      "\n",
      "6. **Final Alphabetical List**:\n",
      "   - Review the merged list to ensure it is in alphabetical order:\n",
      "     - \"blutwurst\", \"buckaroo\", \"closeup\", \"intelligent\", \"laguerre\", \"thesaurus\", \"vertebral\", \"wily\"\n",
      "\n",
      "The final answer is:\n",
      "- \"blutwurst\", \"buckaroo\", \"closeup\", \"intelligent\", \"laguerre\", \"thesaurus\", \"vertebral\", \"wily\"\n",
      "To sort the given list of words alphabetically, we will follow the Insertion Sort method step-by-step.\n",
      "\n",
      "### Step-by-Step Sorting Process\n",
      "\n",
      "1. **Initial List:**\n",
      "   - `scrumptious, sidereal, thermal, yakima, siena, gorky, saxon, scottish, figural, hydroxyl, seventeen, neapolitan, rampage, nerve, grapple, fate, plainfield, stooge, knives, allotted`\n",
      "\n",
      "2. **First Comparison:**\n",
      "   - Compare `sidereal` with `scrumptious`.\n",
      "   - `sidereal` < `scrumptious`, so swap them.\n",
      "   - New list: `sidereal, scrumptious, thermal, yakima, siena, gorky, saxon, scottish, figural, hydroxyl, seventeen, neapolitan, rampage, nerve, grapple, fate, plainfield, stooge, knives, allotted`\n",
      "\n",
      "3. **Second Comparison:**\n",
      "   - Compare `thermal` with `sidereal` and `scrumptious`.\n",
      "   - `thermal` < `sidereal`, so swap them.\n",
      "   - New list: `thermal, sidereal, scrumptious, yakima, siena, gorky, saxon, scottish, figural, hydroxyl, seventeen, neapolitan, rampage, nerve, grapple, fate, plainfield, stooge, knives, allotted`\n",
      "\n",
      "4. **Third Comparison:**\n",
      "   - Compare `yakima` with `thermal`, `sidereal`, and `scrumptious`.\n",
      "   - `yakima` > `thermal`, `sidereal`, and `scrumptious`, so no swap needed.\n",
      "   - New list remains: `thermal, sidereal, scrumptious, yakima, siena, gorky, saxon, scottish, figural, hydroxyl, seventeen, neapolitan, rampage, nerve, grapple, fate, plainfield, stooge, knives, allotted`\n",
      "\n",
      "5. **Fourth Comparison:**\n",
      "   - Compare `siena` with `thermal`, `sidereal`, `scrumptious`, and `yakima`.\n",
      "   - `siena` < `thermal`, so swap them.\n",
      "   - `siena` < `sidereal`, so swap them.\n",
      "   - `siena` < `scrumptious`, so swap them.\n",
      "   - `siena` < `yakima`, so swap them.\n",
      "   - New list: `siena, thermal, sidereal, scrumptious, yakima, gorky, saxon, scottish, figural, hydroxyl, seventeen, neapolitan, rampage, nerve, grapple, fate, plainfield, stooge, knives, allotted`\n",
      "\n",
      "6. **Continue Comparisons:**\n",
      "   - Repeat the comparison and swapping process for each subsequent word in the list.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "After completing all comparisons and swaps, the list should be sorted alphabetically as follows:\n",
      "\n",
      "- `allotted, fate, figural, gorky, grapple, hydroxyl, knives, neapolitan, nerve, plainfield, rampage, saxon, scottish, scrumptious, seventeen, siena, sidereal, stooge, thermal, yakima`\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The final answer is:\n",
      "\n",
      "`allotted, fate, figural, gorky, grapple, hydroxyl, knives, neapolitan, nerve, plainfield, rampage, saxon, scottish, scrumptious, seventeen, siena, sidereal, stooge, thermal, yakima`\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **List the Words**:\n",
      "   - Write down the list of words to be sorted: labile, crunchy, highlight, silage, judaism, allocable, vale, phenol, dissipate, bertram, necessity, champlain, boutique, hydrology, facto, often.\n",
      "\n",
      "2. **Initial Sorting Strategy**:\n",
      "   - Choose a simple sorting algorithm, such as the Bubble Sort, to start with. This will help in understanding the basic process of sorting.\n",
      "\n",
      "3. **Simplify the Sorting Process**:\n",
      "   - Break down the Bubble Sort algorithm into smaller steps:\n",
      "     - Compare the first word with the second word.\n",
      "     - If the first word is alphabetically greater than the second word, swap them.\n",
      "     - Move to the next pair of words and repeat the comparison and swapping process.\n",
      "     - Continue this process until the end of the list is reached.\n",
      "     - Repeat the entire process for the list until no more swaps are needed.\n",
      "\n",
      "4. **Break Down the Task**:\n",
      "   - Divide the list into smaller groups if necessary, to make the sorting process more manageable. For example, sort the first half of the list and then the second half.\n",
      "   - Merge the sorted halves using a merge sort technique.\n",
      "\n",
      "5. **Critical Thinking**:\n",
      "   - Analyze the sorting task from different perspectives:\n",
      "     - Consider the length of the words and how it might affect the sorting process.\n",
      "     - Question any assumptions about alphabetical order, such as case sensitivity (assuming all words are in lowercase for simplicity).\n",
      "     - Evaluate the given words systematically to ensure no words are missed or duplicated.\n",
      "\n",
      "6. **Step-by-Step Plan for Sorting**:\n",
      "   - **Step 1**: Start with the first word and compare it with the second word.\n",
      "   - **Step 2**: If the first word is alphabetically greater than the second word, swap them.\n",
      "   - **Step 3**: Move to the next pair of words and repeat the comparison and swapping process.\n",
      "   - **Step 4**: Continue this process until the end of the list is reached.\n",
      "   - **Step 5**: Repeat the entire process for the list until no more swaps are needed.\n",
      "   - **Step 6**: Verify the sorted list by comparing each word with the next to ensure they are in alphabetical order.\n",
      "\n",
      "7. **Final Verification**:\n",
      "   - Double-check the sorted list to ensure all words are in the correct alphabetical order.\n",
      "   - Compare the final sorted list with the original list to confirm that all words are accounted for and correctly sorted.\n",
      "\n",
      "### Sorting the Words\n",
      "\n",
      "1. **Initial List**: labile, crunchy, highlight, silage, judaism, allocable, vale, phenol, dissipate, bertram, necessity, champlain, boutique, hydrology, facto, often.\n",
      "\n",
      "2. **First Pass**:\n",
      "   - Compare \"labile\" and \"crunchy\" (no swap needed).\n",
      "   - Compare \"crunchy\" and \"highlight\" (no swap needed).\n",
      "   - Compare \"highlight\" and \"silage\" (swap needed).\n",
      "   - Compare \"highlight\" and \"judaism\" (swap needed).\n",
      "   - Compare \"highlight\" and \"allocable\" (swap needed).\n",
      "   - Compare \"highlight\" and \"vale\" (swap needed).\n",
      "   - Compare \"highlight\" and \"phenol\" (swap needed).\n",
      "   - Compare \"highlight\" and \"dissipate\" (swap needed).\n",
      "   - Compare \"highlight\" and \"bertram\" (swap needed).\n",
      "   - Compare \"highlight\" and \"necessity\" (swap needed).\n",
      "   - Compare \"highlight\" and \"champlain\" (swap needed).\n",
      "   - Compare \"highlight\" and \"boutique\" (swap needed).\n",
      "   - Compare \"highlight\" and \"hydrology\" (swap needed).\n",
      "   - Compare \"highlight\" and \"facto\" (swap needed).\n",
      "   - Compare \"highlight\" and \"often\" (swap needed).\n",
      "\n",
      "3. **Continue Sorting**:\n",
      "   - Repeat the process until no more swaps are needed.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "- allocable\n",
      "- bertram\n",
      "- boutique\n",
      "- champlain\n",
      "- crunchy\n",
      "- dissipate\n",
      "- facto\n",
      "- highlight\n",
      "- hydrology\n",
      "- judaism\n",
      "- labile\n",
      "- necessity\n",
      "- often\n",
      "- phenol\n",
      "- silage\n",
      "- vale\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The final answer is:\n",
      "- allocable\n",
      "- bertram\n",
      "- boutique\n",
      "- champlain\n",
      "- crunchy\n",
      "- dissipate\n",
      "- facto\n",
      "- highlight\n",
      "- hydrology\n",
      "- judaism\n",
      "- labile\n",
      "- necessity\n",
      "- often\n",
      "- phenol\n",
      "- silage\n",
      "- vale\n",
      "1. **Identify the Core Task**:\n",
      "   - The core task is to sort the given list of words alphabetically.\n",
      "\n",
      "2. **List the Words**:\n",
      "   - jocund\n",
      "   - flagellate\n",
      "   - bodyguard\n",
      "   - flotation\n",
      "   - commensal\n",
      "   - involve\n",
      "   - miff\n",
      "   - ineradicable\n",
      "   - postprocess\n",
      "\n",
      "3. **Compare the First Letters**:\n",
      "   - Group words by their first letters:\n",
      "     - b: bodyguard\n",
      "     - c: commensal\n",
      "     - f: flagellate, flotation\n",
      "     - i: ineradicable, involve\n",
      "     - j: jocund\n",
      "     - m: miff\n",
      "     - p: postprocess\n",
      "\n",
      "4. **Sort Within Each Group**:\n",
      "   - For 'f': flagellate, flotation\n",
      "     - Compare the second letters: 'l' in flagellate and 'l' in flotation.\n",
      "     - Compare the third letters: 'a' in flagellate and 'o' in flotation.\n",
      "     - Order: flagellate, flotation\n",
      "   - For 'i': ineradicable, involve\n",
      "     - Compare the second letters: 'n' in ineradicable and 'n' in involve.\n",
      "     - Compare the third letters: 'e' in ineradicable and 'v' in involve.\n",
      "     - Order: involve, ineradicable\n",
      "\n",
      "5. **Combine the Sorted Groups**:\n",
      "   - bodyguard\n",
      "   - commensal\n",
      "   - flagellate\n",
      "   - flotation\n",
      "   - involve\n",
      "   - ineradicable\n",
      "   - jocund\n",
      "   - miff\n",
      "   - postprocess\n",
      "\n",
      "6. **Verify the Sorted List**:\n",
      "   - Ensure that each word is in the correct alphabetical order by comparing adjacent words.\n",
      "\n",
      "The final answer is:\n",
      "- bodyguard\n",
      "- commensal\n",
      "- flagellate\n",
      "- flotation\n",
      "- involve\n",
      "- ineradicable\n",
      "- jocund\n",
      "- miff\n",
      "- postprocess\n",
      "To sort the given list of words alphabetically, we will follow the step-by-step reasoning plan:\n",
      "\n",
      "### Step-by-Step Reasoning\n",
      "\n",
      "1. **Identify the List of Words**\n",
      "   - The given list of words is: `postcondition`, `protoplasmic`, `musicology`, `helical`, `uptrend`, `vasoconstriction`, `diacritic`, `beefsteak`, `beware`, `birthplace`, `bicycle`, `junctor`, `state`, `obstinate`, `banshee`, `sap`.\n",
      "\n",
      "2. **Understand the Sorting Requirement**\n",
      "   - We need to sort these words alphabetically.\n",
      "\n",
      "3. **Choose a Sorting Technique**\n",
      "   - We will use the Bubble Sort algorithm for its simplicity.\n",
      "\n",
      "4. **Break Down the Sorting Process**\n",
      "   - **Step 4.1: Initialize the List**\n",
      "     - List: `[\"postcondition\", \"protoplasmic\", \"musicology\", \"helical\", \"uptrend\", \"vasoconstriction\", \"diacritic\", \"beefsteak\", \"beware\", \"birthplace\", \"bicycle\", \"junctor\", \"state\", \"obstinate\", \"banshee\", \"sap\"]`.\n",
      "\n",
      "   - **Step 4.2: Implement Bubble Sort**\n",
      "     - **Step 4.2.1: Iterate Through the List**\n",
      "       - Compare each pair of adjacent words and swap them if they are in the wrong order.\n",
      "     - **Step 4.2.2: Repeat the Process**\n",
      "       - Continue comparing and swapping until the list is sorted.\n",
      "\n",
      "5. **Execute the Sorting Algorithm**\n",
      "   - **Step 5.1: First Pass**\n",
      "     - Compare and swap adjacent words from the start to the end of the list.\n",
      "   - **Step 5.2: Subsequent Passes**\n",
      "     - Repeat the comparison and swapping process for the remaining unsorted portion of the list.\n",
      "   - **Step 5.3: Continue Until Sorted**\n",
      "     - Continue the process until no swaps are made in a complete pass through the list.\n",
      "\n",
      "6. **Verify the Sorted List**\n",
      "   - After completing the sorting process, the list should be sorted alphabetically.\n",
      "\n",
      "7. **Output the Sorted List**\n",
      "   - The sorted list of words is: `banshee`, `beefsteak`, `beware`, `bicycle`, `birthplace`, `diacritic`, `helical`, `junctor`, `musicology`, `obstinate`, `postcondition`, `protoplasmic`, `sap`, `state`, `uptrend`, `vasoconstriction`.\n",
      "\n",
      "### Conclusion\n",
      "The final sorted list of words is:\n",
      "\n",
      "`banshee`, `beefsteak`, `beware`, `bicycle`, `birthplace`, `diacritic`, `helical`, `junctor`, `musicology`, `obstinate`, `postcondition`, `protoplasmic`, `sap`, `state`, `uptrend`, `vasoconstriction`.\n",
      "\n",
      "The final answer is:\n",
      "`banshee`, `beefsteak`, `beware`, `bicycle`, `birthplace`, `diacritic`, `helical`, `junctor`, `musicology`, `obstinate`, `postcondition`, `protoplasmic`, `sap`, `state`, `uptrend`, `vasoconstriction`.\n",
      "### Step-by-Step Reasoning Process\n",
      "\n",
      "1. **Identify the List of Words**:\n",
      "   - The given list of words is: `erudite`, `marriageable`, `stahl`, `coach`, `inadvisable`, `vicksburg`, `virgo`, `brownian`, `eosine`, `magnesium`, `flax`.\n",
      "\n",
      "2. **Understand Alphabetical Order**:\n",
      "   - The alphabetical order follows the sequence of the English alphabet: A, B, C, ..., Z.\n",
      "\n",
      "3. **Compare Words**:\n",
      "   - Compare the first letters of each word. If the first letters are the same, compare the second letters, and so on.\n",
      "\n",
      "4. **Sort the Words**:\n",
      "   - Use a simple sorting algorithm like Bubble Sort.\n",
      "\n",
      "### Detailed Steps for Bubble Sort\n",
      "\n",
      "1. **Initialize**:\n",
      "   - Start with the list: `erudite`, `marriageable`, `stahl`, `coach`, `inadvisable`, `vicksburg`, `virgo`, `brownian`, `eosine`, `magnesium`, `flax`.\n",
      "\n",
      "2. **First Pass**:\n",
      "   - Compare `erudite` and `marriageable`. Since `erudite` comes before `marriageable`, no swap is needed.\n",
      "   - Compare `marriageable` and `stahl`. Since `marriageable` comes after `stahl`, swap them.\n",
      "   - Continue this process for the entire list.\n",
      "\n",
      "3. **Subsequent Passes**:\n",
      "   - Repeat the comparison and swapping process for the entire list until no more swaps are needed.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "After applying the sorting algorithm, the sorted list is:\n",
      "- `brownian`\n",
      "- `coach`\n",
      "- `eosine`\n",
      "- `erudite`\n",
      "- `flax`\n",
      "- `inadvisable`\n",
      "- `magnesium`\n",
      "- `marriageable`\n",
      "- `stahl`\n",
      "- `vicksburg`\n",
      "- `virgo`\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The final answer is:\n",
      "- `brownian`\n",
      "- `coach`\n",
      "- `eosine`\n",
      "- `erudite`\n",
      "- `flax`\n",
      "- `inadvisable`\n",
      "- `magnesium`\n",
      "- `marriageable`\n",
      "- `stahl`\n",
      "- `vicksburg`\n",
      "- `virgo`\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Identify the Core Task**:\n",
      "   - The core task is to sort the given list of words alphabetically.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list of words into smaller, manageable groups to make the sorting process easier.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups. For example:\n",
      "     - Group 1: sociolinguistic, nigeria, odysseus\n",
      "     - Group 2: demystify, proton, voltaire\n",
      "     - Group 3: penny, contaminate, bighorn\n",
      "     - Group 4: stirrup\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - Compare and arrange: nigeria, odysseus, sociolinguistic\n",
      "   - Sort Group 2:\n",
      "     - Compare and arrange: demystify, proton, voltaire\n",
      "   - Sort Group 3:\n",
      "     - Compare and arrange: bighorn, contaminate, penny\n",
      "   - Sort Group 4:\n",
      "     - Since there is only one word, it remains as is: stirrup\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups back into a single list while maintaining the alphabetical order:\n",
      "     - Compare and merge the first words of each group, then the second words, and so on.\n",
      "     - Merged list: bighorn, contaminate, demystify, nigeria, odysseus, penny, proton, sociolinguistic, stirrup, voltaire\n",
      "\n",
      "6. **Verify the Final List**:\n",
      "   - Double-check the final merged list to ensure it is in correct alphabetical order.\n",
      "\n",
      "### Final List\n",
      "- bighorn\n",
      "- contaminate\n",
      "- demystify\n",
      "- nigeria\n",
      "- odysseus\n",
      "- penny\n",
      "- proton\n",
      "- sociolinguistic\n",
      "- stirrup\n",
      "- voltaire\n",
      "\n",
      "The final answer is:\n",
      "- bighorn\n",
      "- contaminate\n",
      "- demystify\n",
      "- nigeria\n",
      "- odysseus\n",
      "- penny\n",
      "- proton\n",
      "- sociolinguistic\n",
      "- stirrup\n",
      "- voltaire\n",
      "To sort the given list of words alphabetically, we can follow these steps:\n",
      "\n",
      "1. **Write down the list of words**:\n",
      "   - iniquity, yoghurt, behind, volcanism, hornpipe, mcconnell, scorn, zip, toroidal, mollie, sandy, wellwisher, inmate\n",
      "\n",
      "2. **Choose a sorting method**:\n",
      "   - We will use the built-in sorting function in Python for simplicity.\n",
      "\n",
      "3. **Implement the sorting function**:\n",
      "   ```python\n",
      "   words = [\"iniquity\", \"yoghurt\", \"behind\", \"volcanism\", \"hornpipe\", \"mcconnell\", \"scorn\", \"zip\", \"toroidal\", \"mollie\", \"sandy\", \"wellwisher\", \"inmate\"]\n",
      "   sorted_words = sorted(words)\n",
      "   ```\n",
      "\n",
      "4. **Print the sorted list to verify the result**:\n",
      "   ```python\n",
      "   print(sorted_words)\n",
      "   ```\n",
      "\n",
      "5. **Verify the result**:\n",
      "   - The sorted list should be:\n",
      "     ```\n",
      "     ['behind', 'hornpipe', 'iniquity', 'inmate', 'mcconnell', 'mollie', 'sandy', 'scorn', 'toroidal', 'volcanism', 'wellwisher', 'yoghurt', 'zip']\n",
      "     ```\n",
      "\n",
      "By following these steps, we can sort the given list of words alphabetically.\n",
      "\n",
      "The final answer is:\n",
      "['behind', 'hornpipe', 'iniquity', 'inmate', 'mcconnell', 'mollie', 'sandy', 'scorn', 'toroidal', 'volcanism', 'wellwisher', 'yoghurt', 'zip']\n",
      "1. **Initial List**:\n",
      "   - bare, census, intrinsic, torch, timeout, infirm, humility, snagging, exaltation, patristic, paregoric, gnomon, moth, sorrowful, manatee, oblique, stressful\n",
      "\n",
      "2. **First Pass (Bubble Sort)**:\n",
      "   - Compare and swap if necessary:\n",
      "     - bare, census → no swap\n",
      "     - census, intrinsic → swap to intrinsic, census\n",
      "     - intrinsic, torch → no swap\n",
      "     - torch, timeout → swap to timeout, torch\n",
      "     - timeout, infirm → swap to infirm, timeout\n",
      "     - infirm, humility → swap to humility, infirm\n",
      "     - humility, snagging → no swap\n",
      "     - snagging, exaltation → no swap\n",
      "     - exaltation, patristic → swap to patristic, exaltation\n",
      "     - patristic, paregoric → swap to paregoric, patristic\n",
      "     - paregoric, gnomon → swap to gnomon, paregoric\n",
      "     - gnomon, moth → no swap\n",
      "     - moth, sorrowful → no swap\n",
      "     - sorrowful, manatee → swap to manatee, sorrowful\n",
      "     - manatee, oblique → swap to oblique, manatee\n",
      "     - oblique, stressful → swap to stressful, oblique\n",
      "\n",
      "   - List after first pass:\n",
      "     - bare, intrinsic, census, timeout, torch, humility, infirm, snagging, exaltation, paregoric, patristic, gnomon, moth, sorrowful, oblique, manatee, stressful\n",
      "\n",
      "3. **Continue Sorting**:\n",
      "   - Repeat the comparison and swapping process until no more swaps are needed.\n",
      "\n",
      "4. **Final Sorted List**:\n",
      "   - After several passes, the list is sorted as follows:\n",
      "     - bare, census, exaltation, gnomon, humility, infirm, intrinsic, manatee, moth, oblique, paregoric, patristic, snagging, sorrowful, stressful, timeout, torch\n",
      "\n",
      "The final answer is:\n",
      "bare, census, exaltation, gnomon, humility, infirm, intrinsic, manatee, moth, oblique, paregoric, patristic, snagging, sorrowful, stressful, timeout, torch\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Identify the List of Words**\n",
      "   - The given list of words is: `thirteenth`, `tinfoil`, `thimble`, `snuff`, `ernie`, `pow`, `celebrity`, `abuilding`, `indiscoverable`, `chigger`, `burgher`, `synchronous`, `yap`, `medlar`, `exorcism`, `newsboy`.\n",
      "\n",
      "2. **Break Down the List into Smaller Groups**\n",
      "   - Divide the list into groups of 5 words each:\n",
      "     - Group 1: `thirteenth`, `tinfoil`, `thimble`, `snuff`, `ernie`\n",
      "     - Group 2: `pow`, `celebrity`, `abuilding`, `indiscoverable`, `chigger`\n",
      "     - Group 3: `burgher`, `synchronous`, `yap`, `medlar`, `exorcism`, `newsboy`\n",
      "\n",
      "3. **Sort Each Group Alphabetically**\n",
      "   - Sort Group 1:\n",
      "     - `ernie`, `snuff`, `thimble`, `thirteenth`, `tinfoil`\n",
      "   - Sort Group 2:\n",
      "     - `abuilding`, `celebrity`, `chigger`, `indiscoverable`, `pow`\n",
      "   - Sort Group 3:\n",
      "     - `burgher`, `exorcism`, `medlar`, `newsboy`, `synchronous`, `yap`\n",
      "\n",
      "4. **Merge the Sorted Groups**\n",
      "   - Merge Group 1 and Group 2:\n",
      "     - `abuilding`, `celebrity`, `chigger`, `ernie`, `indiscoverable`, `pow`, `snuff`, `thimble`, `thirteenth`, `tinfoil`\n",
      "   - Merge the result with Group 3:\n",
      "     - `abuilding`, `burgher`, `celebrity`, `chigger`, `ernie`, `exorcism`, `indiscoverable`, `medlar`, `newsboy`, `pow`, `snuff`, `synchronous`, `thimble`, `thirteenth`, `tinfoil`, `yap`\n",
      "\n",
      "5. **Verify the Final Sorted List**\n",
      "   - The final sorted list is:\n",
      "     - `abuilding`, `burgher`, `celebrity`, `chigger`, `ernie`, `exorcism`, `indiscoverable`, `medlar`, `newsboy`, `pow`, `snuff`, `synchronous`, `thimble`, `thirteenth`, `tinfoil`, `yap`\n",
      "\n",
      "### Final Answer\n",
      "The final answer is:\n",
      "`abuilding`, `burgher`, `celebrity`, `chigger`, `ernie`, `exorcism`, `indiscoverable`, `medlar`, `newsboy`, `pow`, `snuff`, `synchronous`, `thimble`, `thirteenth`, `tinfoil`, `yap`\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **List the Words**:\n",
      "   - Write down the list of words to be sorted:\n",
      "     ```\n",
      "     peaceable, residue, sulfanilamide, kingsley, eft, caliber, headboard, stamp, phillip, upholster, irishman, lobby, nary, gastrointestinal, fragile, faulkner, capricious, ouzo, phylum\n",
      "     ```\n",
      "\n",
      "2. **Understand Alphabetical Order**:\n",
      "   - Recall the basic rules of alphabetical order:\n",
      "     - Compare the first letter of each word.\n",
      "     - If the first letters are the same, compare the second letters, and so on.\n",
      "\n",
      "3. **Choose a Sorting Technique**:\n",
      "   - Select a sorting algorithm that is straightforward and effective for this task. Common choices include:\n",
      "     - Bubble Sort\n",
      "     - Insertion Sort\n",
      "     - Merge Sort\n",
      "     - Quick Sort\n",
      "   - For simplicity, we will use **Insertion Sort** in this plan.\n",
      "\n",
      "4. **Apply Insertion Sort**:\n",
      "   - Follow the steps of Insertion Sort:\n",
      "     - Start with the first word as the sorted portion.\n",
      "     - Take the next word and compare it with the words in the sorted portion.\n",
      "     - Insert the word in the correct position within the sorted portion.\n",
      "     - Repeat until all words are sorted.\n",
      "\n",
      "5. **Detailed Steps for Insertion Sort**:\n",
      "   - **Step 1**: Start with the first word (`peaceable`).\n",
      "   - **Step 2**: Take the second word (`residue`) and compare it with `peaceable`. Since `residue` comes after `peaceable`, keep `peaceable` in its place.\n",
      "   - **Step 3**: Take the third word (`sulfanilamide`) and compare it with `peaceable` and `residue`. Insert it in the correct position.\n",
      "   - **Step 4**: Continue this process for each subsequent word, inserting it into the correct position in the sorted portion of the list.\n",
      "\n",
      "6. **Verify the Sorted List**:\n",
      "   - After applying the sorting algorithm, verify that the list is in alphabetical order by checking each word against the previous one.\n",
      "\n",
      "7. **Finalize the Sorted List**:\n",
      "   - Write down the final sorted list of words.\n",
      "\n",
      "### Applying the Plan\n",
      "\n",
      "1. **Initial List**:\n",
      "   ```\n",
      "   peaceable, residue, sulfanilamide, kingsley, eft, caliber, headboard, stamp, phillip, upholster, irishman, lobby, nary, gastrointestinal, fragile, faulkner, capricious, ouzo, phylum\n",
      "   ```\n",
      "\n",
      "2. **Insertion Sort Steps**:\n",
      "   - **Step 1**: Start with `peaceable`.\n",
      "   - **Step 2**: Compare `residue` with `peaceable`. `peaceable` comes before `residue`.\n",
      "   - **Step 3**: Compare `sulfanilamide` with `peaceable` and `residue`. `sulfanilamide` comes after both.\n",
      "   - **Step 4**: Continue this process for each word.\n",
      "\n",
      "3. **Final Sorted List**:\n",
      "   ```\n",
      "   caliber, capricious, eft, faulkner, fragile, gastrointestinal, headboard, irishman, kingsley, lobby, nary, ouzo, peaceable, phillip, phylum, residue, stamp, sulfanilamide, upholster\n",
      "   ```\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The final answer is:\n",
      "```\n",
      "caliber, capricious, eft, faulkner, fragile, gastrointestinal, headboard, irishman, kingsley, lobby, nary, ouzo, peaceable, phillip, phylum, residue, stamp, sulfanilamide, upholster\n",
      "```\n",
      "1. **Identify the list of words to be sorted**:\n",
      "   - `griffith, common, nanosecond, loosestrife, decoy, swabby, aerospace, denmark, yates, frill, spitz, enviable, screechy, allure, sow, spermatozoa, saute, jibe, exclusive`\n",
      "\n",
      "2. **Break down the list into smaller groups**:\n",
      "   - Group 1: `griffith, common, nanosecond, loosestrife, decoy`\n",
      "   - Group 2: `swabby, aerospace, denmark, yates, frill`\n",
      "   - Group 3: `spitz, enviable, screechy, allure, sow`\n",
      "   - Group 4: `spermatozoa, saute, jibe, exclusive`\n",
      "\n",
      "3. **Sort each group alphabetically**:\n",
      "   - Sort Group 1: `common, decoy, griffith, loosestrife, nanosecond`\n",
      "   - Sort Group 2: `aerospace, denmark, frill, swabby, yates`\n",
      "   - Sort Group 3: `allure, enviable, screechy, sow, spitz`\n",
      "   - Sort Group 4: `exclusive, jibe, saute, spermatozoa`\n",
      "\n",
      "4. **Merge sorted groups**:\n",
      "   - Merge Group 1 and Group 2: `aerospace, common, decoy, denmark, frill, griffith, loosestrife, nanosecond, swabby, yates`\n",
      "   - Merge the result with Group 3: `aerospace, allure, common, decoy, denmark, enviable, frill, griffith, loosestrife, nanosecond, screechy, sow, spitz, swabby, yates`\n",
      "   - Merge the result with Group 4: `aerospace, allure, common, decoy, denmark, enviable, exclusive, frill, griffith, jibe, loosestrife, nanosecond, saute, screechy, sow, spitz, spermatozoa, swabby, yates`\n",
      "\n",
      "5. **Final alphabetical sorting**:\n",
      "   - Perform a final sort on the merged list:\n",
      "     - `aerospace, allure, common, decoy, denmark, enviable, exclusive, frill, griffith, jibe, loosestrife, nanosecond, saute, screechy, sow, spitz, spermatozoa, swabby, yates`\n",
      "\n",
      "6. **Verify the sorting**:\n",
      "   - The final sorted list is:\n",
      "     - `aerospace, allure, common, decoy, denmark, enviable, exclusive, frill, griffith, jibe, loosestrife, nanosecond, saute, screechy, sow, spitz, spermatozoa, swabby, yates`\n",
      "\n",
      "The final answer is:\n",
      "`aerospace, allure, common, decoy, denmark, enviable, exclusive, frill, griffith, jibe, loosestrife, nanosecond, saute, screechy, sow, spitz, spermatozoa, swabby, yates`\n",
      "1. **Initial List**:\n",
      "   - wink\n",
      "   - envious\n",
      "   - scotia\n",
      "   - planetaria\n",
      "   - pooh\n",
      "   - emancipate\n",
      "   - army\n",
      "\n",
      "2. **First Pass**:\n",
      "   - Compare \"wink\" and \"envious\":\n",
      "     - \"wink\" > \"envious\" → Swap\n",
      "     - List: envious, wink, scotia, planetaria, pooh, emancipate, army\n",
      "   - Compare \"envious\" and \"scotia\":\n",
      "     - \"envious\" > \"scotia\" → Swap\n",
      "     - List: scotia, wink, envious, planetaria, pooh, emancipate, army\n",
      "   - Compare \"scotia\" and \"planetaria\":\n",
      "     - \"scotia\" < \"planetaria\" → No swap\n",
      "   - Compare \"planetaria\" and \"pooh\":\n",
      "     - \"planetaria\" > \"pooh\" → Swap\n",
      "     - List: scotia, wink, envious, pooh, planetaria, emancipate, army\n",
      "   - Compare \"pooh\" and \"emancipate\":\n",
      "     - \"pooh\" < \"emancipate\" → No swap\n",
      "   - Compare \"emancipate\" and \"army\":\n",
      "     - \"emancipate\" > \"army\" → Swap\n",
      "     - List: scotia, wink, envious, pooh, planetaria, army, emancipate\n",
      "\n",
      "3. **Second Pass**:\n",
      "   - Compare \"scotia\" and \"wink\":\n",
      "     - \"scotia\" < \"wink\" → No swap\n",
      "   - Compare \"wink\" and \"envious\":\n",
      "     - \"wink\" > \"envious\" → Swap\n",
      "     - List: scotia, envious, wink, pooh, planetaria, army, emancipate\n",
      "   - Compare \"envious\" and \"pooh\":\n",
      "     - \"envious\" > \"pooh\" → Swap\n",
      "     - List: scotia, pooh, wink, envious, planetaria, army, emancipate\n",
      "   - Compare \"wink\" and \"planetaria\":\n",
      "     - \"wink\" < \"planetaria\" → No swap\n",
      "   - Compare \"planetaria\" and \"army\":\n",
      "     - \"planetaria\" > \"army\" → Swap\n",
      "     - List: scotia, pooh, wink, envious, army, planetaria, emancipate\n",
      "   - Compare \"army\" and \"emancipate\":\n",
      "     - \"army\" < \"emancipate\" → No swap\n",
      "\n",
      "4. **Third Pass**:\n",
      "   - Compare \"scotia\" and \"pooh\":\n",
      "     - \"scotia\" > \"pooh\" → Swap\n",
      "     - List: pooh, scotia, wink, envious, army, planetaria, emancipate\n",
      "   - Compare \"scotia\" and \"wink\":\n",
      "     - \"scotia\" < \"wink\" → No swap\n",
      "   - Compare \"wink\" and \"envious\":\n",
      "     - \"wink\" > \"envious\" → Swap\n",
      "     - List: pooh, scotia, envious, wink, army, planetaria, emancipate\n",
      "   - Compare \"envious\" and \"army\":\n",
      "     - \"envious\" > \"army\" → Swap\n",
      "     - List: pooh, scotia, army, wink, envious, planetaria, emancipate\n",
      "   - Compare \"wink\" and \"planetaria\":\n",
      "     - \"wink\" < \"planetaria\" → No swap\n",
      "   - Compare \"planetaria\" and \"emancipate\":\n",
      "     - \"planetaria\" < \"emancipate\" → No swap\n",
      "\n",
      "5. **Fourth Pass**:\n",
      "   - Compare \"pooh\" and \"scotia\":\n",
      "     - \"pooh\" < \"scotia\" → No swap\n",
      "   - Compare \"scotia\" and \"army\":\n",
      "     - \"scotia\" > \"army\" → Swap\n",
      "     - List: pooh, army, scotia, wink, envious, planetaria, emancipate\n",
      "   - Compare \"scotia\" and \"wink\":\n",
      "     - \"scotia\" < \"wink\" → No swap\n",
      "   - Compare \"wink\" and \"envious\":\n",
      "     - \"wink\" > \"envious\" → Swap\n",
      "     - List: pooh, army, scotia, envious, wink, planetaria, emancipate\n",
      "   - Compare \"envious\" and \"planetaria\":\n",
      "     - \"envious\" < \"planetaria\" → No swap\n",
      "   - Compare \"planetaria\" and \"emancipate\":\n",
      "     - \"planetaria\" < \"emancipate\" → No swap\n",
      "\n",
      "6. **Final Review**:\n",
      "   - Ensure the final list is in alphabetical order:\n",
      "     - army\n",
      "     - emancipate\n",
      "     - envious\n",
      "     - planetaria\n",
      "     - pooh\n",
      "     - scotia\n",
      "     - wink\n",
      "\n",
      "The final answer is:\n",
      "- army\n",
      "- emancipate\n",
      "- envious\n",
      "- planetaria\n",
      "- pooh\n",
      "- scotia\n",
      "- wink\n",
      "Let's follow the reasoning plan step-by-step to sort the words alphabetically:\n",
      "\n",
      "1. **Initial List**: condescend, rampant, percolate, coltish, date, rochester, placid, significant.\n",
      "\n",
      "2. **First Pass**:\n",
      "   - condescend vs. rampant: no swap\n",
      "   - rampant vs. percolate: swap (percolate, rampant)\n",
      "   - rampant vs. coltish: swap (coltish, rampant)\n",
      "   - rampant vs. date: swap (date, rampant)\n",
      "   - rampant vs. rochester: no swap\n",
      "   - rochester vs. placid: swap (placid, rochester)\n",
      "   - rochester vs. significant: no swap\n",
      "\n",
      "   **List after First Pass**: condescend, percolate, coltish, date, rampant, placid, rochester, significant.\n",
      "\n",
      "3. **Second Pass**:\n",
      "   - condescend vs. percolate: no swap\n",
      "   - percolate vs. coltish: swap (coltish, percolate)\n",
      "   - percolate vs. date: swap (date, percolate)\n",
      "   - percolate vs. rampant: no swap\n",
      "   - rampant vs. placid: no swap\n",
      "   - placid vs. rochester: no swap\n",
      "   - rochester vs. significant: no swap\n",
      "\n",
      "   **List after Second Pass**: condescend, coltish, date, percolate, rampant, placid, rochester, significant.\n",
      "\n",
      "4. **Third Pass**:\n",
      "   - condescend vs. coltish: swap (coltish, condescend)\n",
      "   - condescend vs. date: swap (date, condescend)\n",
      "   - condescend vs. percolate: no swap\n",
      "   - percolate vs. rampant: no swap\n",
      "   - rampant vs. placid: no swap\n",
      "   - placid vs. rochester: no swap\n",
      "   - rochester vs. significant: no swap\n",
      "\n",
      "   **List after Third Pass**: coltish, date, condescend, percolate, rampant, placid, rochester, significant.\n",
      "\n",
      "5. **Fourth Pass**:\n",
      "   - coltish vs. date: no swap\n",
      "   - date vs. condescend: no swap\n",
      "   - condescend vs. percolate: no swap\n",
      "   - percolate vs. rampant: no swap\n",
      "   - rampant vs. placid: no swap\n",
      "   - placid vs. rochester: no swap\n",
      "   - rochester vs. significant: no swap\n",
      "\n",
      "   **List after Fourth Pass**: coltish, date, condescend, percolate, rampant, placid, rochester, significant.\n",
      "\n",
      "Since no more swaps are needed, the list is now sorted alphabetically.\n",
      "\n",
      "**The final answer is**: coltish, date, condescend, percolate, placid, rampant, rochester, significant.\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort a list of words alphabetically.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller, manageable groups to make the sorting process easier.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into groups of 5 words each:\n",
      "     - Group 1: daffy, hypothesis, croupier, dockyard, household\n",
      "     - Group 2: peccary, triode, minstrelsy, nepotism, sawtimber\n",
      "     - Group 3: mantic, info, confess, serenade, summate\n",
      "     - Group 4: silver, duty, loam, mandate\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - croupier, daffy, dockyard, household, hypothesis\n",
      "   - Sort Group 2:\n",
      "     - minstrelsy, nepotism, peccary, sawtimber, triode\n",
      "   - Sort Group 3:\n",
      "     - confess, info, mantic, serenade, summate\n",
      "   - Sort Group 4:\n",
      "     - duty, loam, mandate, silver\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups back into a single list while maintaining alphabetical order:\n",
      "     - Merge Group 1 and Group 2:\n",
      "       - croupier, daffy, dockyard, household, hypothesis, minstrelsy, nepotism, peccary, sawtimber, triode\n",
      "     - Merge the result with Group 3:\n",
      "       - croupier, daffy, dockyard, household, hypothesis, minstrelsy, nepotism, peccary, sawtimber, triode, confess, info, mantic, serenade, summate\n",
      "     - Merge the result with Group 4:\n",
      "       - croupier, daffy, dockyard, duty, household, hypothesis, info, loam, mandate, mantic, minstrelsy, nepotism, peccary, sawtimber, serenade, silver, summate, triode\n",
      "\n",
      "6. **Verify the Final List**:\n",
      "   - Ensure that the final merged list is in correct alphabetical order:\n",
      "     - croupier, daffy, dockyard, duty, household, hypothesis, info, loam, mandate, mantic, minstrelsy, nepotism, peccary, sawtimber, serenade, silver, summate, triode\n",
      "\n",
      "The final answer is:\n",
      "croupier, daffy, dockyard, duty, household, hypothesis, info, loam, mandate, mantic, minstrelsy, nepotism, peccary, sawtimber, serenade, silver, summate, triode\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following words alphabetically: avalanche, chaplin, squabble, coachman, ipsilateral, clonic, cameroon, fortran, cram, medea, referring, kennan, canal, pyridine, ussr, postpone.\n",
      "\n",
      "2. **List the Words**:\n",
      "   - Write down the list of words to be sorted:\n",
      "     - avalanche\n",
      "     - chaplin\n",
      "     - squabble\n",
      "     - coachman\n",
      "     - ipsilateral\n",
      "     - clonic\n",
      "     - cameroon\n",
      "     - fortran\n",
      "     - cram\n",
      "     - medea\n",
      "     - referring\n",
      "     - kennan\n",
      "     - canal\n",
      "     - pyridine\n",
      "     - ussr\n",
      "     - postpone\n",
      "\n",
      "3. **Choose a Sorting Method**:\n",
      "   - Decide on a sorting method. For simplicity, we will use the **Bubble Sort** method, which is straightforward and easy to understand.\n",
      "\n",
      "4. **Initialize the Sorting Process**:\n",
      "   - Start with the first word in the list and compare it with the next word.\n",
      "\n",
      "5. **Compare and Swap**:\n",
      "   - If the first word is alphabetically greater than the second word, swap their positions.\n",
      "   - Move to the next pair of words and repeat the comparison and swap process.\n",
      "\n",
      "6. **Iterate Through the List**:\n",
      "   - Continue this process until the end of the list is reached.\n",
      "   - Repeat the entire process from the beginning of the list until no more swaps are needed.\n",
      "\n",
      "7. **Check for Completion**:\n",
      "   - After each full pass through the list, check if any swaps were made.\n",
      "   - If no swaps were made, the list is sorted.\n",
      "   - If swaps were made, repeat the process from step 4.\n",
      "\n",
      "8. **Finalize the Sorted List**:\n",
      "   - Once no more swaps are needed, the list is sorted alphabetically.\n",
      "\n",
      "### Detailed Steps for Bubble Sort\n",
      "\n",
      "1. **First Pass**:\n",
      "   - Compare \"avalanche\" and \"chaplin\". No swap needed.\n",
      "   - Compare \"chaplin\" and \"squabble\". No swap needed.\n",
      "   - Compare \"squabble\" and \"coachman\". No swap needed.\n",
      "   - Compare \"coachman\" and \"ipsilateral\". No swap needed.\n",
      "   - Compare \"ipsilateral\" and \"clonic\". Swap needed.\n",
      "   - Compare \"clonic\" and \"cameroon\". No swap needed.\n",
      "   - Compare \"cameroon\" and \"fortran\". No swap needed.\n",
      "   - Compare \"fortran\" and \"cram\". Swap needed.\n",
      "   - Compare \"cram\" and \"medea\". No swap needed.\n",
      "   - Compare \"medea\" and \"referring\". No swap needed.\n",
      "   - Compare \"referring\" and \"kennan\". No swap needed.\n",
      "   - Compare \"kennan\" and \"canal\". Swap needed.\n",
      "   - Compare \"canal\" and \"pyridine\". No swap needed.\n",
      "   - Compare \"pyridine\" and \"ussr\". No swap needed.\n",
      "   - Compare \"ussr\" and \"postpone\". No swap needed.\n",
      "\n",
      "2. **Subsequent Passes**:\n",
      "   - Repeat the comparison and swap process for the entire list until no swaps are needed in a full pass.\n",
      "\n",
      "3. **Final Check**:\n",
      "   - After completing the passes, the list should be sorted alphabetically.\n",
      "\n",
      "### Sorted List\n",
      "\n",
      "- avalanche\n",
      "- canal\n",
      "- cameroon\n",
      "- chaplin\n",
      "- clonic\n",
      "- coachman\n",
      "- cram\n",
      "- fortran\n",
      "- ipsilateral\n",
      "- kennan\n",
      "- medea\n",
      "- postpone\n",
      "- pyridine\n",
      "- referring\n",
      "- squabble\n",
      "- ussr\n",
      "\n",
      "The final answer is:\n",
      "- avalanche\n",
      "- canal\n",
      "- cameroon\n",
      "- chaplin\n",
      "- clonic\n",
      "- coachman\n",
      "- cram\n",
      "- fortran\n",
      "- ipsilateral\n",
      "- kennan\n",
      "- medea\n",
      "- postpone\n",
      "- pyridine\n",
      "- referring\n",
      "- squabble\n",
      "- ussr\n",
      "To sort the given list of words alphabetically, we will follow the step-by-step reasoning plan:\n",
      "\n",
      "1. **Initial List**:\n",
      "   - \"portsmouth impalpable portrait gouda brainy succumb fatuous hoof lisbon erudite malaria enigma isaacson cony stronghold servomechanism\".\n",
      "\n",
      "2. **First Comparison**:\n",
      "   - Compare \"portsmouth\" and \"impalpable\".\n",
      "   - Since \"impalpable\" comes before \"portsmouth\", swap their positions.\n",
      "   - New list: \"impalpable portsmouth portrait gouda brainy succumb fatuous hoof lisbon erudite malaria enigma isaacson cony stronghold servomechanism\".\n",
      "\n",
      "3. **Second Comparison**:\n",
      "   - Compare \"impalpable\" and \"portsmouth\".\n",
      "   - Since they are already in order, move to the next pair.\n",
      "   - Compare \"portsmouth\" and \"portrait\".\n",
      "   - Since \"portrait\" comes after \"portsmouth\", no swap is needed.\n",
      "\n",
      "4. **Continue Comparisons**:\n",
      "   - Continue this process for each pair of words in the list.\n",
      "\n",
      "After completing the sorting process, the final sorted list is:\n",
      "- \"brainy cony enigma erudite fatuous gouda hoof impalpable isaacson lisbon malaria portrait portsmouth servomechanism stronghold succumb\".\n",
      "\n",
      "The final answer is:\n",
      "- \"brainy cony enigma erudite fatuous gouda hoof impalpable isaacson lisbon malaria portrait portsmouth servomechanism stronghold succumb\".\n",
      "1. **Identify the Task**:\n",
      "   - Sort the words alphabetically.\n",
      "\n",
      "2. **Simplify the Task**:\n",
      "   - Break down the list into smaller groups.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into groups of 4 or 5 words each.\n",
      "   - Example groups:\n",
      "     - Group 1: dredge, checksum, huckster, baronial\n",
      "     - Group 2: spotlight, circumstance, eulogy, comment\n",
      "     - Group 3: felicia, dartmouth, monochromator, neuroanatomic\n",
      "     - Group 4: emittance\n",
      "\n",
      "4. **Sort Each Group**:\n",
      "   - Sort Group 1: baronial, checksum, dredge, huckster\n",
      "   - Sort Group 2: circumstance, comment, eulogy, spotlight\n",
      "   - Sort Group 3: dartmouth, felicia, monochromator, neuroanatomic\n",
      "   - Sort Group 4: emittance\n",
      "\n",
      "5. **Merge the Groups**:\n",
      "   - Merge Group 1 and Group 2: baronial, checksum, circumstance, comment, dredge, eulogy, huckster, spotlight\n",
      "   - Merge the result with Group 3: baronial, checksum, circumstance, comment, dartmouth, dredge, eulogy, felicia, huckster, monochromator, neuroanatomic, spotlight\n",
      "   - Merge the result with Group 4: baronial, checksum, circumstance, comment, dartmouth, dredge, eulogy, emittance, felicia, huckster, monochromator, neuroanatomic, spotlight\n",
      "\n",
      "6. **Verify the Sorting**:\n",
      "   - Double-check the final list to ensure it is in alphabetical order.\n",
      "\n",
      "7. **Document Each Step**:\n",
      "   - Document the initial division, the sorting of each group, the merging process, and the final verification.\n",
      "\n",
      "The final sorted list is:\n",
      "- baronial\n",
      "- checksum\n",
      "- circumstance\n",
      "- comment\n",
      "- dartmouth\n",
      "- dredge\n",
      "- eulogy\n",
      "- emittance\n",
      "- felicia\n",
      "- huckster\n",
      "- monochromator\n",
      "- neuroanatomic\n",
      "- spotlight\n",
      "\n",
      "The final answer is:\n",
      "- baronial\n",
      "- checksum\n",
      "- circumstance\n",
      "- comment\n",
      "- dartmouth\n",
      "- dredge\n",
      "- eulogy\n",
      "- emittance\n",
      "- felicia\n",
      "- huckster\n",
      "- monochromator\n",
      "- neuroanatomic\n",
      "- spotlight\n",
      "To sort the given list of words alphabetically, we will follow the step-by-step reasoning plan:\n",
      "\n",
      "### Step-by-Step Sorting Process\n",
      "\n",
      "1. **Initial List**:\n",
      "   - implementor, bangui, nudge, cavalier, refractory, islamabad, contextual, abramson, waite, railway, carlisle, magistrate, silvery, picnicking, dustbin, emacs\n",
      "\n",
      "2. **First Pass**:\n",
      "   - Compare \"implementor\" and \"bangui\": \"bangui\" comes before \"implementor\", so swap them.\n",
      "   - Compare \"bangui\" and \"nudge\": \"bangui\" comes before \"nudge\", so keep them in place.\n",
      "   - Compare \"nudge\" and \"cavalier\": \"cavalier\" comes before \"nudge\", so swap them.\n",
      "   - Compare \"cavalier\" and \"refractory\": \"cavalier\" comes before \"refractory\", so keep them in place.\n",
      "   - Compare \"refractory\" and \"islamabad\": \"islamabad\" comes before \"refractory\", so swap them.\n",
      "   - Compare \"islamabad\" and \"contextual\": \"contextual\" comes before \"islamabad\", so swap them.\n",
      "   - Compare \"contextual\" and \"abramson\": \"abramson\" comes before \"contextual\", so swap them.\n",
      "   - Compare \"abramson\" and \"waite\": \"abramson\" comes before \"waite\", so keep them in place.\n",
      "   - Compare \"waite\" and \"railway\": \"railway\" comes before \"waite\", so swap them.\n",
      "   - Compare \"railway\" and \"carlisle\": \"carlisle\" comes before \"railway\", so swap them.\n",
      "   - Compare \"carlisle\" and \"magistrate\": \"carlisle\" comes before \"magistrate\", so keep them in place.\n",
      "   - Compare \"magistrate\" and \"silvery\": \"magistrate\" comes before \"silvery\", so keep them in place.\n",
      "   - Compare \"silvery\" and \"picnicking\": \"picnicking\" comes before \"silvery\", so swap them.\n",
      "   - Compare \"picnicking\" and \"dustbin\": \"dustbin\" comes before \"picnicking\", so swap them.\n",
      "   - Compare \"dustbin\" and \"emacs\": \"dustbin\" comes before \"emacs\", so keep them in place.\n",
      "\n",
      "3. **Subsequent Passes**:\n",
      "   - Repeat the comparison and swapping process for the entire list until no more swaps are needed.\n",
      "\n",
      "4. **Final Verification**:\n",
      "   - After the sorting process, verify the list by comparing each word with the next one to ensure they are in alphabetical order.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "- abramson\n",
      "- bangui\n",
      "- carlisle\n",
      "- cavalier\n",
      "- contextual\n",
      "- dustbin\n",
      "- emacs\n",
      "- implementor\n",
      "- islamabad\n",
      "- magistrate\n",
      "- nudge\n",
      "- picnicking\n",
      "- railway\n",
      "- refractory\n",
      "- silvery\n",
      "- waite\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The final answer is:\n",
      "\n",
      "- abramson\n",
      "- bangui\n",
      "- carlisle\n",
      "- cavalier\n",
      "- contextual\n",
      "- dustbin\n",
      "- emacs\n",
      "- implementor\n",
      "- islamabad\n",
      "- magistrate\n",
      "- nudge\n",
      "- picnicking\n",
      "- railway\n",
      "- refractory\n",
      "- silvery\n",
      "- waite\n",
      "### Step-by-Step Reasoning Process\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the given list of words alphabetically.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller, manageable groups to make the sorting process easier.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups:\n",
      "     - Group 1: strove, hendrickson, apostasy, jacm, indonesia\n",
      "     - Group 2: vibrate, afloat, lanthanide, grosbeak, scavenge\n",
      "     - Group 3: quark, chattel, conner, bechtel, melancholy\n",
      "     - Group 4: ferment\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - Original: strove, hendrickson, apostasy, jacm, indonesia\n",
      "     - Sorted: apostasy, hendrickson, indonesia, jacm, strove\n",
      "   - Sort Group 2:\n",
      "     - Original: vibrate, afloat, lanthanide, grosbeak, scavenge\n",
      "     - Sorted: afloat, grosbeak, lanthanide, scavenge, vibrate\n",
      "   - Sort Group 3:\n",
      "     - Original: quark, chattel, conner, bechtel, melancholy\n",
      "     - Sorted: bechtel, chattel, conner, melancholy, quark\n",
      "   - Sort Group 4:\n",
      "     - Original: ferment\n",
      "     - Sorted: ferment\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups while maintaining alphabetical order:\n",
      "     - Merged List: apostasy, afloat, bechtel, chattel, conner, ferment, grosbeak, hendrickson, indonesia, jacm, lanthanide, melancholy, quark, scavenge, strove, vibrate\n",
      "\n",
      "6. **Verify the Final List**:\n",
      "   - Check the final merged list to ensure it is in correct alphabetical order.\n",
      "\n",
      "### Final Answer\n",
      "The final answer is:\n",
      "apostasy, afloat, bechtel, chattel, conner, ferment, grosbeak, hendrickson, indonesia, jacm, lanthanide, melancholy, quark, scavenge, strove, vibrate\n",
      "### Step-by-Step Reasoning\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following words alphabetically:\n",
      "     - List: bust, midshipmen, musicale, urinary, chalk, rocket, resiny, horror, tangential, sapient, dumb, serf, pathway, urea, goucher, fatty, masonry, dentistry, cowboy, roadrunner.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller groups for easier sorting.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into groups of 5 words each:\n",
      "     - Group 1: bust, midshipmen, musicale, urinary, chalk\n",
      "     - Group 2: rocket, resiny, horror, tangential, sapient\n",
      "     - Group 3: dumb, serf, pathway, urea, goucher\n",
      "     - Group 4: fatty, masonry, dentistry, cowboy, roadrunner\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - Sorted: bust, chalk, midshipmen, musicale, urinary\n",
      "   - Sort Group 2:\n",
      "     - Sorted: horror, rocket, resiny, sapient, tangential\n",
      "   - Sort Group 3:\n",
      "     - Sorted: dumb, goucher, pathway, serf, urea\n",
      "   - Sort Group 4:\n",
      "     - Sorted: cowboy, dentistry, fatty, masonry, roadrunner\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups back into a single list while maintaining the alphabetical order:\n",
      "     - Merged List: bust, chalk, midshipmen, musicale, urinary, horror, rocket, resiny, sapient, tangential, dumb, goucher, pathway, serf, urea, cowboy, dentistry, fatty, masonry, roadrunner\n",
      "\n",
      "6. **Verify the Sorting**:\n",
      "   - Double-check the final list to ensure it is correctly sorted alphabetically:\n",
      "     - Final List: bust, chalk, cowboy, dentistry, dumb, fatty, goucher, horror, masonry, midshipmen, musicale, pathway, resiny, rocket, roadrunner, sapient, serf, tangential, urinary, urea\n",
      "\n",
      "The final answer is:\n",
      "bust, chalk, cowboy, dentistry, dumb, fatty, goucher, horror, masonry, midshipmen, musicale, pathway, resiny, rocket, roadrunner, sapient, serf, tangential, urinary, urea\n",
      "To sort the given words alphabetically, we will follow the Bubble Sort algorithm step-by-step:\n",
      "\n",
      "1. **Initial List**:\n",
      "   - convair, frighten, citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, judaica, trundle, suppose, contaminant.\n",
      "\n",
      "2. **First Pass**:\n",
      "   - Compare \"convair\" and \"frighten\". No swap needed.\n",
      "   - Compare \"frighten\" and \"citizen\". Swap to get \"citizen, frighten\".\n",
      "   - Compare \"frighten\" and \"scrubby\". Swap to get \"citizen, scrubby, frighten\".\n",
      "   - Compare \"frighten\" and \"birdseed\". Swap to get \"citizen, scrubby, birdseed, frighten\".\n",
      "   - Compare \"frighten\" and \"fateful\". Swap to get \"citizen, scrubby, birdseed, fateful, frighten\".\n",
      "   - Compare \"frighten\" and \"soothe\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, frighten\".\n",
      "   - Compare \"frighten\" and \"extensive\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, frighten\".\n",
      "   - Compare \"frighten\" and \"trillion\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, frighten\".\n",
      "   - Compare \"frighten\" and \"adonis\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, frighten\".\n",
      "   - Compare \"frighten\" and \"southeastern\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, frighten\".\n",
      "   - Compare \"frighten\" and \"stormy\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, frighten\".\n",
      "   - Compare \"frighten\" and \"judaica\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, judaica, frighten\".\n",
      "   - Compare \"frighten\" and \"trundle\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, judaica, trundle, frighten\".\n",
      "   - Compare \"frighten\" and \"suppose\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, judaica, trundle, suppose, frighten\".\n",
      "   - Compare \"frighten\" and \"contaminant\". Swap to get \"citizen, scrubby, birdseed, fateful, soothe, extensive, trillion, adonis, southeastern, stormy, judaica, trundle, suppose, contaminant, frighten\".\n",
      "\n",
      "3. **Subsequent Passes**:\n",
      "   - Repeat the comparison and swap process for the entire list until no more swaps are needed.\n",
      "\n",
      "4. **Final Sorted List**:\n",
      "   - After several passes, the list is sorted alphabetically:\n",
      "     - adonis, birdseed, citizen, contaminant, convair, extensive, fateful, frighten, judaica, scrubby, soothe, southeastern, stormy, suppose, trillion, trundle.\n",
      "\n",
      "The final answer is:\n",
      "- adonis, birdseed, citizen, contaminant, convair, extensive, fateful, frighten, judaica, scrubby, soothe, southeastern, stormy, suppose, trillion, trundle.\n",
      "To sort the given list of words alphabetically, we will follow these steps:\n",
      "\n",
      "1. **Prepare the list of words**:\n",
      "   - The list is: odessa, dance, formulae, dietetic, mantle, cost, huddle, resplendent, bolshevism, proust, warmth, deadline, progeny, hesitant, palace, rackety, judson, foster, belize, thirdhand.\n",
      "\n",
      "2. **Apply the sorting method**:\n",
      "   - We will use a built-in sorting function to sort the list alphabetically.\n",
      "\n",
      "3. **Verify the sorted list**:\n",
      "   - We will check if the list is correctly sorted by comparing adjacent words.\n",
      "\n",
      "Let's implement this step-by-step:\n",
      "\n",
      "### Step 1: Prepare the list of words\n",
      "```python\n",
      "words = [\"odessa\", \"dance\", \"formulae\", \"dietetic\", \"mantle\", \"cost\", \"huddle\", \"resplendent\", \"bolshevism\", \"proust\", \"warmth\", \"deadline\", \"progeny\", \"hesitant\", \"palace\", \"rackety\", \"judson\", \"foster\", \"belize\", \"thirdhand\"]\n",
      "```\n",
      "\n",
      "### Step 2: Apply the sorting method\n",
      "```python\n",
      "sorted_words = sorted(words)\n",
      "```\n",
      "\n",
      "### Step 3: Verify the sorted list\n",
      "```python\n",
      "print(sorted_words)\n",
      "```\n",
      "\n",
      "### Result\n",
      "The sorted list is:\n",
      "```python\n",
      "['belize', 'bolshevism', 'cost', 'dance', 'deadline', 'dietetic', 'foster', 'formulae', 'hesitant', 'huddle', 'judson', 'mantle', 'odessa', 'palace', 'progeny', 'proust', 'rackety', 'resplendent', 'thirdhand', 'warmth']\n",
      "```\n",
      "\n",
      "### Final Answer\n",
      "The final answer is:\n",
      "```\n",
      "['belize', 'bolshevism', 'cost', 'dance', 'deadline', 'dietetic', 'foster', 'formulae', 'hesitant', 'huddle', 'judson', 'mantle', 'odessa', 'palace', 'progeny', 'proust', 'rackety', 'resplendent', 'thirdhand', 'warmth']\n",
      "```\n",
      "### Step-by-Step Reasoning Process\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following list of words alphabetically:\n",
      "     - List: benchmark, pilot, reverie, hatchet, prorate, wince, machine, loess, stallion, amphibious, percentage, redcoat, baseplate, sank, assist, wehr, homecoming, ell, thoughtful.\n",
      "\n",
      "2. **Divide the List into Smaller Groups**:\n",
      "   - Group 1: benchmark, pilot, reverie, hatchet, prorate\n",
      "   - Group 2: wince, machine, loess, stallion, amphibious\n",
      "   - Group 3: percentage, redcoat, baseplate, sank, assist\n",
      "   - Group 4: wehr, homecoming, ell, thoughtful\n",
      "\n",
      "3. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - benchmark, hatchet, pilot, prorate, reverie\n",
      "   - Sort Group 2:\n",
      "     - amphibious, loess, machine, stallion, wince\n",
      "   - Sort Group 3:\n",
      "     - assist, baseplate, percentage, redcoat, sank\n",
      "   - Sort Group 4:\n",
      "     - ell, homecoming, thoughtful, wehr\n",
      "\n",
      "4. **Merge the Sorted Groups**:\n",
      "   - Merge Group 1 and Group 2:\n",
      "     - amphibious, benchmark, hatchet, loess, machine, pilot, prorate, reverie, stallion, wince\n",
      "   - Merge the result with Group 3:\n",
      "     - amphibious, assist, baseplate, benchmark, hatchet, loess, machine, percentage, pilot, prorate, redcoat, reverie, sank, stallion, wince\n",
      "   - Merge the result with Group 4:\n",
      "     - amphibious, assist, baseplate, benchmark, ell, hatchet, homecoming, loess, machine, percentage, pilot, prorate, redcoat, reverie, sank, stallion, thoughtful, wehr, wince\n",
      "\n",
      "5. **Verify the Sorted List**:\n",
      "   - Review the final merged list to ensure all words are in alphabetical order:\n",
      "     - amphibious, assist, baseplate, benchmark, ell, hatchet, homecoming, loess, machine, percentage, pilot, prorate, redcoat, reverie, sank, stallion, thoughtful, wehr, wince\n",
      "\n",
      "### Final Answer\n",
      "The final answer is:\n",
      "amphibious, assist, baseplate, benchmark, ell, hatchet, homecoming, loess, machine, percentage, pilot, prorate, redcoat, reverie, sank, stallion, thoughtful, wehr, wince\n",
      "1. **Identify the List of Words**\n",
      "   - The given list of words is: `stitch`, `steelmake`, `indomitable`, `wigging`, `cubby`, `sheaf`, `pique`, `thymine`, `exotica`, `good`, `mental`, `brake`, `nick`, `rajah`, `lineage`, `choose`, `bunny`, `drone`, `chevalier`.\n",
      "\n",
      "2. **Break Down the List into Smaller Groups**\n",
      "   - Divide the list into smaller groups for easier sorting:\n",
      "     - Group 1: `stitch`, `steelmake`, `indomitable`, `wigging`, `cubby`\n",
      "     - Group 2: `sheaf`, `pique`, `thymine`, `exotica`, `good`\n",
      "     - Group 3: `mental`, `brake`, `nick`, `rajah`, `lineage`\n",
      "     - Group 4: `choose`, `bunny`, `drone`, `chevalier`\n",
      "\n",
      "3. **Sort Each Group Alphabetically**\n",
      "   - Sort Group 1:\n",
      "     - `cubby`, `indomitable`, `steelmake`, `stitch`, `wigging`\n",
      "   - Sort Group 2:\n",
      "     - `exotica`, `good`, `pique`, `sheaf`, `thymine`\n",
      "   - Sort Group 3:\n",
      "     - `brake`, `lineage`, `mental`, `nick`, `rajah`\n",
      "   - Sort Group 4:\n",
      "     - `bunny`, `choose`, `chevalier`, `drone`\n",
      "\n",
      "4. **Merge Sorted Groups**\n",
      "   - Merge Group 1 and Group 2:\n",
      "     - `cubby`, `exotica`, `good`, `indomitable`, `pique`, `sheaf`, `steelmake`, `stitch`, `thymine`, `wigging`\n",
      "   - Merge the result with Group 3:\n",
      "     - `brake`, `cubby`, `exotica`, `good`, `indomitable`, `lineage`, `mental`, `nick`, `pique`, `rajah`, `sheaf`, `steelmake`, `stitch`, `thymine`, `wigging`\n",
      "   - Merge the result with Group 4:\n",
      "     - `bunny`, `brake`, `choose`, `chevalier`, `cubby`, `drone`, `exotica`, `good`, `indomitable`, `lineage`, `mental`, `nick`, `pique`, `rajah`, `sheaf`, `steelmake`, `stitch`, `thymine`, `wigging`\n",
      "\n",
      "5. **Verify the Final Sorted List**\n",
      "   - The final sorted list is:\n",
      "     - `bunny`, `brake`, `choose`, `chevalier`, `cubby`, `drone`, `exotica`, `good`, `indomitable`, `lineage`, `mental`, `nick`, `pique`, `rajah`, `sheaf`, `steelmake`, `stitch`, `thymine`, `wigging`\n",
      "\n",
      "6. **Document the Sorting Process**\n",
      "   - The sorting process involved breaking down the list into smaller groups, sorting each group, and then merging the sorted groups while maintaining alphabetical order.\n",
      "\n",
      "The final answer is:\n",
      "`bunny`, `brake`, `choose`, `chevalier`, `cubby`, `drone`, `exotica`, `good`, `indomitable`, `lineage`, `mental`, `nick`, `pique`, `rajah`, `sheaf`, `steelmake`, `stitch`, `thymine`, `wigging`\n",
      "To sort the given list of words alphabetically, we will follow the Insertion Sort method step-by-step:\n",
      "\n",
      "1. **Start with an Empty Sorted List**:\n",
      "   - `sorted_list = []`\n",
      "\n",
      "2. **Insert the First Word**:\n",
      "   - `sorted_list.append(\"plebiscite\")`\n",
      "   - `sorted_list = [\"plebiscite\"]`\n",
      "\n",
      "3. **Insert the Second Word**:\n",
      "   - Compare `\"colombo\"` with `\"plebiscite\"`.\n",
      "   - `\"colombo\"` comes before `\"plebiscite\"`.\n",
      "   - Insert `\"colombo\"` at the beginning.\n",
      "   - `sorted_list = [\"colombo\", \"plebiscite\"]`\n",
      "\n",
      "4. **Insert the Third Word**:\n",
      "   - Compare `\"inviolate\"` with each word in the sorted list.\n",
      "   - `\"inviolate\"` comes after `\"colombo\"` but before `\"plebiscite\"`.\n",
      "   - Insert `\"inviolate\"` at the correct position.\n",
      "   - `sorted_list = [\"colombo\", \"inviolate\", \"plebiscite\"]`\n",
      "\n",
      "5. **Insert the Fourth Word**:\n",
      "   - Compare `\"quagmire\"` with each word in the sorted list.\n",
      "   - `\"quagmire\"` comes after `\"inviolate\"` but before `\"plebiscite\"`.\n",
      "   - Insert `\"quagmire\"` at the correct position.\n",
      "   - `sorted_list = [\"colombo\", \"inviolate\", \"quagmire\", \"plebiscite\"]`\n",
      "\n",
      "6. **Insert the Fifth Word**:\n",
      "   - Compare `\"garry\"` with each word in the sorted list.\n",
      "   - `\"garry\"` comes after `\"colombo\"` but before `\"inviolate\"`.\n",
      "   - Insert `\"garry\"` at the correct position.\n",
      "   - `sorted_list = [\"colombo\", \"garry\", \"inviolate\", \"quagmire\", \"plebiscite\"]`\n",
      "\n",
      "7. **Insert the Sixth Word**:\n",
      "   - Compare `\"satanic\"` with each word in the sorted list.\n",
      "   - `\"satanic\"` comes after `\"quagmire\"` but before `\"plebiscite\"`.\n",
      "   - Insert `\"satanic\"` at the correct position.\n",
      "   - `sorted_list = [\"colombo\", \"garry\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "8. **Insert the Seventh Word**:\n",
      "   - Compare `\"magnanimity\"` with each word in the sorted list.\n",
      "   - `\"magnanimity\"` comes after `\"garry\"` but before `\"inviolate\"`.\n",
      "   - Insert `\"magnanimity\"` at the correct position.\n",
      "   - `sorted_list = [\"colombo\", \"garry\", \"magnanimity\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "9. **Insert the Eighth Word**:\n",
      "   - Compare `\"aeneas\"` with each word in the sorted list.\n",
      "   - `\"aeneas\"` comes before `\"colombo\"`.\n",
      "   - Insert `\"aeneas\"` at the beginning.\n",
      "   - `sorted_list = [\"aeneas\", \"colombo\", \"garry\", \"magnanimity\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "10. **Insert the Ninth Word**:\n",
      "    - Compare `\"notoriety\"` with each word in the sorted list.\n",
      "    - `\"notoriety\"` comes after `\"magnanimity\"` but before `\"inviolate\"`.\n",
      "    - Insert `\"notoriety\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"garry\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "11. **Insert the Tenth Word**:\n",
      "    - Compare `\"nevada\"` with each word in the sorted list.\n",
      "    - `\"nevada\"` comes after `\"garry\"` but before `\"magnanimity\"`.\n",
      "    - Insert `\"nevada\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"garry\", \"nevada\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "12. **Insert the Eleventh Word**:\n",
      "    - Compare `\"foothold\"` with each word in the sorted list.\n",
      "    - `\"foothold\"` comes after `\"colombo\"` but before `\"garry\"`.\n",
      "    - Insert `\"foothold\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"nevada\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "13. **Insert the Twelfth Word**:\n",
      "    - Compare `\"glycerine\"` with each word in the sorted list.\n",
      "    - `\"glycerine\"` comes after `\"garry\"` but before `\"nevada\"`.\n",
      "    - Insert `\"glycerine\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "14. **Insert the Thirteenth Word**:\n",
      "    - Compare `\"lucre\"` with each word in the sorted list.\n",
      "    - `\"lucre\"` comes after `\"nevada\"` but before `\"magnanimity\"`.\n",
      "    - Insert `\"lucre\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\"]`\n",
      "\n",
      "15. **Insert the Fourteenth Word**:\n",
      "    - Compare `\"tennyson\"` with each word in the sorted list.\n",
      "    - `\"tennyson\"` comes after `\"plebiscite\"`.\n",
      "    - Insert `\"tennyson\"` at the end.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\", \"tennyson\"]`\n",
      "\n",
      "16. **Insert the Fifteenth Word**:\n",
      "    - Compare `\"type\"` with each word in the sorted list.\n",
      "    - `\"type\"` comes after `\"tennyson\"`.\n",
      "    - Insert `\"type\"` at the end.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "17. **Insert the Sixteenth Word**:\n",
      "    - Compare `\"scription\"` with each word in the sorted list.\n",
      "    - `\"scription\"` comes after `\"satanic\"` but before `\"plebiscite\"`.\n",
      "    - Insert `\"scription\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "18. **Insert the Seventeenth Word**:\n",
      "    - Compare `\"pompey\"` with each word in the sorted list.\n",
      "    - `\"pompey\"` comes after `\"nevada\"` but before `\"lucre\"`.\n",
      "    - Insert `\"pompey\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"pompey\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "19. **Insert the Eighteenth Word**:\n",
      "    - Compare `\"softball\"` with each word in the sorted list.\n",
      "    - `\"softball\"` comes after `\"satanic\"` but before `\"scription\"`.\n",
      "    - Insert `\"softball\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"pompey\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"softball\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "20. **Insert the Nineteenth Word**:\n",
      "    - Compare `\"spleenwort\"` with each word in the sorted list.\n",
      "    - `\"spleenwort\"` comes after `\"satanic\"` but before `\"softball\"`.\n",
      "    - Insert `\"spleenwort\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"garry\", \"glycerine\", \"nevada\", \"pompey\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"spleenwort\", \"softball\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "21. **Insert the Twentieth Word**:\n",
      "    - Compare `\"fox\"` with each word in the sorted list.\n",
      "    - `\"fox\"` comes after `\"foothold\"` but before `\"garry\"`.\n",
      "    - Insert `\"fox\"` at the correct position.\n",
      "    - `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"fox\", \"garry\", \"glycerine\", \"nevada\", \"pompey\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"spleenwort\", \"softball\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "### Final Sorted List\n",
      "- `sorted_list = [\"aeneas\", \"colombo\", \"foothold\", \"fox\", \"garry\", \"glycerine\", \"nevada\", \"pompey\", \"lucre\", \"magnanimity\", \"notoriety\", \"inviolate\", \"quagmire\", \"satanic\", \"spleenwort\", \"softball\", \"scription\", \"plebiscite\", \"tennyson\", \"type\"]`\n",
      "\n",
      "The final answer is:\n",
      "- aeneas\n",
      "- colombo\n",
      "- foothold\n",
      "- fox\n",
      "- garry\n",
      "- glycerine\n",
      "- nevada\n",
      "- pompey\n",
      "- lucre\n",
      "- magnanimity\n",
      "- notoriety\n",
      "- inviolate\n",
      "- quagmire\n",
      "- satanic\n",
      "- spleenwort\n",
      "- softball\n",
      "- scription\n",
      "- plebiscite\n",
      "- tennyson\n",
      "- type\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Identify the List of Words**\n",
      "   - List: statutory, feed, spavin, hecatomb, pestle, plume, figural, pasty, giveth, incense, undulate, middle, blackstone, tel, obstinacy, toothpaste, hunt, sinkhole\n",
      "\n",
      "2. **Choose a Sorting Method**\n",
      "   - We will use the Bubble Sort method for simplicity.\n",
      "\n",
      "3. **Understand Bubble Sort**\n",
      "   - Bubble Sort works by repeatedly swapping the adjacent elements if they are in the wrong order.\n",
      "\n",
      "4. **Initialize the Sorting Process**\n",
      "   - Start with the first word in the list and compare it with the second word.\n",
      "   - If the first word is alphabetically greater than the second word, swap them.\n",
      "   - Move to the next pair of words and repeat the comparison and swapping process.\n",
      "\n",
      "5. **Iterate Through the List**\n",
      "   - Continue the comparison and swapping process for each pair of words until the end of the list is reached.\n",
      "   - This completes one pass through the list.\n",
      "\n",
      "6. **Repeat the Process**\n",
      "   - After each pass, the largest word in the unsorted portion of the list will be in its correct position.\n",
      "   - Repeat the process for the remaining unsorted portion of the list until no more swaps are needed.\n",
      "\n",
      "7. **Verify the Sorted List**\n",
      "   - After completing all passes, the list should be sorted alphabetically.\n",
      "   - Double-check the list to ensure it is correctly sorted.\n",
      "\n",
      "### Detailed Steps for Bubble Sort\n",
      "\n",
      "1. **First Pass**\n",
      "   - Compare \"statutory\" and \"feed\". If \"statutory\" > \"feed\", swap them.\n",
      "   - Compare \"statutory\" and \"spavin\". If \"statutory\" > \"spavin\", swap them.\n",
      "   - Continue this process until the end of the list.\n",
      "\n",
      "2. **Second Pass**\n",
      "   - Repeat the comparison and swapping process for the remaining unsorted portion of the list.\n",
      "\n",
      "3. **Continue Passes**\n",
      "   - Keep repeating the process until no swaps are needed in a full pass through the list.\n",
      "\n",
      "### Final Check\n",
      "\n",
      "- After completing the sorting process, verify that the list is sorted alphabetically by comparing each word with the next one to ensure they are in the correct order.\n",
      "\n",
      "### Sorted List\n",
      "\n",
      "- After applying the Bubble Sort method, the sorted list is:\n",
      "  - blackstone\n",
      "  - feed\n",
      "  - figural\n",
      "  - giveth\n",
      "  - hecatomb\n",
      "  - hunt\n",
      "  - incense\n",
      "  - middle\n",
      "  - obstinacy\n",
      "  - pasty\n",
      "  - pestle\n",
      "  - plume\n",
      "  - sinkhole\n",
      "  - spavin\n",
      "  - statutory\n",
      "  - tel\n",
      "  - toothpaste\n",
      "  - undulate\n",
      "\n",
      "The final answer is:\n",
      "- blackstone\n",
      "- feed\n",
      "- figural\n",
      "- giveth\n",
      "- hecatomb\n",
      "- hunt\n",
      "- incense\n",
      "- middle\n",
      "- obstinacy\n",
      "- pasty\n",
      "- pestle\n",
      "- plume\n",
      "- sinkhole\n",
      "- spavin\n",
      "- statutory\n",
      "- tel\n",
      "- toothpaste\n",
      "- undulate\n",
      "To sort the given list of words alphabetically, we will follow the Bubble Sort algorithm as outlined in the reasoning plan. Here are the steps:\n",
      "\n",
      "1. **Identify the List of Words**:\n",
      "   - List: `voluntary`, `yucca`, `limnology`, `fabulous`, `seventh`, `cube`, `willow`, `kitakyushu`, `sequel`, `senescent`, `bauble`, `length`.\n",
      "\n",
      "2. **Initialize the Sorting Process**:\n",
      "   - Set a flag `swapped` to `True` to enter the loop.\n",
      "\n",
      "3. **Compare Adjacent Words**:\n",
      "   - Set `swapped` to `False` at the beginning of each iteration.\n",
      "   - For each pair of adjacent words in the list:\n",
      "     - Compare the first word with the second word.\n",
      "     - If the first word is alphabetically greater than the second word, swap their positions and set `swapped` to `True`.\n",
      "\n",
      "4. **Repeat Until Sorted**:\n",
      "   - Continue the loop until `swapped` remains `False` throughout an entire iteration, indicating that the list is sorted.\n",
      "\n",
      "5. **Verify the Sorting**:\n",
      "   - After the sorting process, check the list to ensure that each word is alphabetically less than or equal to the next word.\n",
      "\n",
      "### Sorting Process\n",
      "\n",
      "Let's go through the sorting process step-by-step:\n",
      "\n",
      "**Initial List**:\n",
      "- `voluntary`, `yucca`, `limnology`, `fabulous`, `seventh`, `cube`, `willow`, `kitakyushu`, `sequel`, `senescent`, `bauble`, `length`\n",
      "\n",
      "**First Pass**:\n",
      "- Compare `voluntary` and `yucca`: No swap needed.\n",
      "- Compare `yucca` and `limnology`: Swap to get `limnology`, `yucca`.\n",
      "- Compare `yucca` and `fabulous`: Swap to get `fabulous`, `yucca`.\n",
      "- Compare `yucca` and `seventh`: Swap to get `seventh`, `yucca`.\n",
      "- Compare `yucca` and `cube`: Swap to get `cube`, `yucca`.\n",
      "- Compare `yucca` and `willow`: Swap to get `willow`, `yucca`.\n",
      "- Compare `yucca` and `kitakyushu`: Swap to get `kitakyushu`, `yucca`.\n",
      "- Compare `yucca` and `sequel`: Swap to get `sequel`, `yucca`.\n",
      "- Compare `yucca` and `senescent`: Swap to get `senescent`, `yucca`.\n",
      "- Compare `yucca` and `bauble`: Swap to get `bauble`, `yucca`.\n",
      "- Compare `yucca` and `length`: Swap to get `length`, `yucca`.\n",
      "\n",
      "**List after First Pass**:\n",
      "- `voluntary`, `limnology`, `fabulous`, `seventh`, `cube`, `willow`, `kitakyushu`, `sequel`, `senescent`, `bauble`, `length`, `yucca`\n",
      "\n",
      "**Continue the Process**:\n",
      "- Repeat the comparison and swapping process until no more swaps are needed.\n",
      "\n",
      "**Final Sorted List**:\n",
      "- `bauble`, `cube`, `fabulous`, `kitakyushu`, `length`, `limnology`, `seventh`, `senescent`, `sequel`, `voluntary`, `willow`, `yucca`\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The final answer is:\n",
      "- `bauble`, `cube`, `fabulous`, `kitakyushu`, `length`, `limnology`, `seventh`, `senescent`, `sequel`, `voluntary`, `willow`, `yucca`\n",
      "1. **Start with the first word**: \"tiresome\".\n",
      "2. **Compare \"tiresome\" with \"sweepstake\"**:\n",
      "   - \"sweepstake\" comes before \"tiresome\" alphabetically.\n",
      "   - New list: \"sweepstake\", \"tiresome\".\n",
      "3. **Compare \"sweepstake\" with \"introvert\"**:\n",
      "   - \"introvert\" comes before \"sweepstake\" alphabetically.\n",
      "   - New list: \"introvert\", \"sweepstake\", \"tiresome\".\n",
      "4. **Compare \"introvert\" with \"carport\"**:\n",
      "   - \"carport\" comes before \"introvert\" alphabetically.\n",
      "   - New list: \"carport\", \"introvert\", \"sweepstake\", \"tiresome\".\n",
      "5. **Compare \"carport\" with \"firewood\"**:\n",
      "   - \"carport\" comes before \"firewood\" alphabetically.\n",
      "   - New list: \"carport\", \"firewood\", \"introvert\", \"sweepstake\", \"tiresome\".\n",
      "\n",
      "### Final Sorted List\n",
      "- \"carport\"\n",
      "- \"firewood\"\n",
      "- \"introvert\"\n",
      "- \"sweepstake\"\n",
      "- \"tiresome\"\n",
      "\n",
      "The final answer is:\n",
      "- carport\n",
      "- firewood\n",
      "- introvert\n",
      "- sweepstake\n",
      "- tiresome\n",
      "### Step-by-Step Reasoning Process\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort a list of words alphabetically.\n",
      "   - The list of words is: dew, betelgeuse, inexplainable, snazzy, tao, stain, meaty, blue, trail, wash, grossman, lyre, caudal, epoch, trailside, char, cyanide.\n",
      "\n",
      "2. **Simplify the Sorting Task**:\n",
      "   - Break down the list into smaller, manageable groups. This can make the sorting process more intuitive and less error-prone.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups. For example, divide the list into groups of 5 words each.\n",
      "     - Group 1: dew, betelgeuse, inexplainable, snazzy, tao\n",
      "     - Group 2: stain, meaty, blue, trail, wash\n",
      "     - Group 3: grossman, lyre, caudal, epoch, trailside\n",
      "     - Group 4: char, cyanide\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort the words within each group alphabetically.\n",
      "     - For Group 1: Sort dew, betelgeuse, inexplainable, snazzy, tao.\n",
      "       - Sorted Group 1: betelgeuse, dew, inexplainable, snazzy, tao\n",
      "     - For Group 2: Sort stain, meaty, blue, trail, wash.\n",
      "       - Sorted Group 2: blue, meaty, stain, trail, wash\n",
      "     - For Group 3: Sort grossman, lyre, caudal, epoch, trailside.\n",
      "       - Sorted Group 3: caudal, epoch, grossman, lyre, trailside\n",
      "     - For Group 4: Sort char, cyanide.\n",
      "       - Sorted Group 4: char, cyanide\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups back into a single list while maintaining the alphabetical order.\n",
      "     - Compare the first word of each sorted group and merge them into a single sorted list.\n",
      "       - Merged List: betelgeuse, blue, caudal, char, cyanide, dew, epoch, grossman, inexplainable, lyre, meaty, snazzy, stain, tao, trail, trailside, wash\n",
      "\n",
      "6. **Verify the Final List**:\n",
      "   - Double-check the final merged list to ensure it is correctly sorted alphabetically.\n",
      "\n",
      "### Final Sorted List\n",
      "\n",
      "- betelgeuse\n",
      "- blue\n",
      "- caudal\n",
      "- char\n",
      "- cyanide\n",
      "- dew\n",
      "- epoch\n",
      "- grossman\n",
      "- inexplainable\n",
      "- lyre\n",
      "- meaty\n",
      "- snazzy\n",
      "- stain\n",
      "- tao\n",
      "- trail\n",
      "- trailside\n",
      "- wash\n",
      "\n",
      "The final answer is:\n",
      "- betelgeuse\n",
      "- blue\n",
      "- caudal\n",
      "- char\n",
      "- cyanide\n",
      "- dew\n",
      "- epoch\n",
      "- grossman\n",
      "- inexplainable\n",
      "- lyre\n",
      "- meaty\n",
      "- snazzy\n",
      "- stain\n",
      "- tao\n",
      "- trail\n",
      "- trailside\n",
      "- wash\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following list of words alphabetically: `opinionate`, `interior`, `ebb`, `seeable`, `jurassic`, `flatland`, `mammary`, `cardamom`, `forthwith`, `licensor`, `landslide`, `valkyrie`, `cryptic`, `bully`, `insurmountable`, `nassau`.\n",
      "\n",
      "2. **Identify Sorting Techniques**:\n",
      "   - Generate a list of common sorting techniques: Bubble Sort, Selection Sort, Insertion Sort, Merge Sort, Quick Sort, etc.\n",
      "\n",
      "3. **Simplify the Sorting Process**:\n",
      "   - Break down the list into smaller, more manageable groups if necessary.\n",
      "   - For simplicity, we can start with a straightforward sorting algorithm like Bubble Sort or Selection Sort.\n",
      "\n",
      "4. **Break Down the List**:\n",
      "   - Divide the list into smaller groups if needed. For example, split the list into groups of 5 words each.\n",
      "   - Group 1: `opinionate`, `interior`, `ebb`, `seeable`, `jurassic`\n",
      "   - Group 2: `flatland`, `mammary`, `cardamom`, `forthwith`, `licensor`\n",
      "   - Group 3: `landslide`, `valkyrie`, `cryptic`, `bully`, `insurmountable`, `nassau`\n",
      "\n",
      "5. **Apply Sorting Algorithm**:\n",
      "   - Choose a sorting algorithm, such as Bubble Sort, and apply it to each group.\n",
      "   - **Bubble Sort Steps**:\n",
      "     - Compare each pair of adjacent words.\n",
      "     - Swap them if they are in the wrong order.\n",
      "     - Repeat the process until the list is sorted.\n",
      "\n",
      "6. **Sort Each Group**:\n",
      "   - Sort Group 1 using Bubble Sort.\n",
      "   - Sort Group 2 using Bubble Sort.\n",
      "   - Sort Group 3 using Bubble Sort.\n",
      "\n",
      "7. **Merge Sorted Groups**:\n",
      "   - After sorting each group, merge them back into a single list.\n",
      "   - Use a merge process similar to Merge Sort to combine the sorted groups into one sorted list.\n",
      "\n",
      "8. **Verify the Sorted List**:\n",
      "   - Double-check the final sorted list to ensure it is in alphabetical order.\n",
      "\n",
      "### Detailed Steps for Bubble Sort\n",
      "\n",
      "1. **Initialize**:\n",
      "   - Start with the first group: `opinionate`, `interior`, `ebb`, `seeable`, `jurassic`.\n",
      "\n",
      "2. **Compare and Swap**:\n",
      "   - Compare `opinionate` and `interior`. If `opinionate` comes after `interior` alphabetically, swap them.\n",
      "   - Continue this process for each pair in the group.\n",
      "\n",
      "3. **Repeat**:\n",
      "   - Repeat the comparison and swapping process until the group is sorted.\n",
      "\n",
      "4. **Repeat for Other Groups**:\n",
      "   - Apply the same Bubble Sort process to Group 2 and Group 3.\n",
      "\n",
      "5. **Merge**:\n",
      "   - Merge the sorted groups into a single list, ensuring the final list is alphabetically sorted.\n",
      "\n",
      "### Final Step-by-Step Plan\n",
      "\n",
      "1. **Sort Group 1**:\n",
      "   - Apply Bubble Sort to `opinionate`, `interior`, `ebb`, `seeable`, `jurassic`.\n",
      "   - Result: `ebb`, `interior`, `jurassic`, `opinionate`, `seeable`.\n",
      "\n",
      "2. **Sort Group 2**:\n",
      "   - Apply Bubble Sort to `flatland`, `mammary`, `cardamom`, `forthwith`, `licensor`.\n",
      "   - Result: `cardamom`, `flatland`, `forthwith`, `licensor`, `mammary`.\n",
      "\n",
      "3. **Sort Group 3**:\n",
      "   - Apply Bubble Sort to `landslide`, `valkyrie`, `cryptic`, `bully`, `insurmountable`, `nassau`.\n",
      "   - Result: `bully`, `cryptic`, `insurmountable`, `landslide`, `nassau`, `valkyrie`.\n",
      "\n",
      "4. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups into a single sorted list.\n",
      "   - Result: `bully`, `cardamom`, `cryptic`, `ebb`, `flatland`, `forthwith`, `insurmountable`, `interior`, `jurassic`, `landslide`, `licensor`, `mammary`, `nassau`, `opinionate`, `seeable`, `valkyrie`.\n",
      "\n",
      "5. **Verify**:\n",
      "   - Ensure the final list is in alphabetical order.\n",
      "\n",
      "The final answer is:\n",
      "`bully`, `cardamom`, `cryptic`, `ebb`, `flatland`, `forthwith`, `insurmountable`, `interior`, `jurassic`, `landslide`, `licensor`, `mammary`, `nassau`, `opinionate`, `seeable`, `valkyrie`.\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Simplify the Sorting Task**\n",
      "   - Identify the list of words to be sorted:\n",
      "     - List: betony, bronzy, charge, cordial, handicraft, boar, collet, clemens, bootleg, possession, mesh, centaur, contemporaneous, macmahon, underclassman, monterey, dorado, contravariant, regina\n",
      "\n",
      "2. **Break Down the List into Smaller Groups**\n",
      "   - Divide the list into smaller, manageable groups to facilitate easier sorting. For example, divide the list into groups of 5 words each:\n",
      "     - Group 1: betony, bronzy, charge, cordial, handicraft\n",
      "     - Group 2: boar, collet, clemens, bootleg, possession\n",
      "     - Group 3: mesh, centaur, contemporaneous, macmahon, underclassman\n",
      "     - Group 4: monterey, dorado, contravariant, regina\n",
      "\n",
      "3. **Sort Each Group Alphabetically**\n",
      "   - Sort each group of words alphabetically using a simple sorting algorithm like bubble sort or insertion sort:\n",
      "     - Group 1: Sort betony, bronzy, charge, cordial, handicraft\n",
      "       - Sorted Group 1: betony, bronzy, charge, cordial, handicraft\n",
      "     - Group 2: Sort boar, collet, clemens, bootleg, possession\n",
      "       - Sorted Group 2: boar, bootleg, clemens, collet, possession\n",
      "     - Group 3: Sort mesh, centaur, contemporaneous, macmahon, underclassman\n",
      "       - Sorted Group 3: centaur, contemporaneous, macmahon, mesh, underclassman\n",
      "     - Group 4: Sort monterey, dorado, contravariant, regina\n",
      "       - Sorted Group 4: contravariant, dorado, monterey, regina\n",
      "\n",
      "4. **Merge Sorted Groups**\n",
      "   - Merge the sorted groups into a single list while maintaining alphabetical order. Use a merge sort technique to combine the groups:\n",
      "     - Merge Group 1 and Group 2:\n",
      "       - Merged List: betony, boar, bootleg, bronzy, charge, clemens, collet, cordial, handicraft, possession\n",
      "     - Merge the result with Group 3:\n",
      "       - Merged List: betony, boar, bootleg, bronzy, charge, centaur, clemens, collet, contemporaneous, cordial, handicraft, macmahon, mesh, possession, underclassman\n",
      "     - Merge the result with Group 4:\n",
      "       - Final Sorted List: betony, boar, bootleg, bronzy, charge, centaur, clemens, collet, contemporaneous, contravariant, cordial, dorado, handicraft, macmahon, mesh, monterey, possession, regina, underclassman\n",
      "\n",
      "5. **Verify the Final Sorted List**\n",
      "   - Ensure that the final merged list is in alphabetical order by comparing each word with the next one in the list.\n",
      "\n",
      "### Detailed Steps for Sorting Each Group\n",
      "\n",
      "For each group, follow these steps:\n",
      "\n",
      "1. **Compare and Swap**\n",
      "   - Compare the first word with the second word. If the first word comes after the second word alphabetically, swap them.\n",
      "   - Continue this process for each pair of words in the group until the entire group is sorted.\n",
      "\n",
      "2. **Repeat Comparison**\n",
      "   - Repeat the comparison and swapping process until no more swaps are needed, indicating that the group is sorted.\n",
      "\n",
      "### Merging Sorted Groups\n",
      "\n",
      "1. **Initialize Pointers**\n",
      "   - Initialize pointers for each group to keep track of the current position in each group.\n",
      "\n",
      "2. **Compare and Append**\n",
      "   - Compare the words at the current positions of the pointers in each group.\n",
      "   - Append the smaller word to the final sorted list and move the pointer in the corresponding group forward.\n",
      "\n",
      "3. **Continue Until All Groups are Merged**\n",
      "   - Repeat the comparison and appending process until all words from all groups have been merged into the final sorted list.\n",
      "\n",
      "By following this plan, the final sorted list is:\n",
      "\n",
      "betony, boar, bootleg, bronzy, charge, centaur, clemens, collet, contemporaneous, contravariant, cordial, dorado, handicraft, macmahon, mesh, monterey, possession, regina, underclassman\n",
      "\n",
      "The final answer is:\n",
      "betony, boar, bootleg, bronzy, charge, centaur, clemens, collet, contemporaneous, contravariant, cordial, dorado, handicraft, macmahon, mesh, monterey, possession, regina, underclassman\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Understand the Task**:\n",
      "   - The task is to sort the following list of words alphabetically: frontage, gunky, indeterminable, smokestack, taint, assure, ostentatious, sanderson, contend, paradigmatic, lustrous, butterball, deaf, dinosaur, bully, rhyme, sashimi, bye, cornet.\n",
      "\n",
      "2. **Simplify the Sorting Process**:\n",
      "   - Break down the list into smaller, manageable groups to facilitate sorting.\n",
      "\n",
      "3. **Break Down the List**:\n",
      "   - Divide the list into smaller groups of approximately 5 words each. This will make the sorting process more straightforward.\n",
      "\n",
      "4. **Sort Each Group Alphabetically**:\n",
      "   - Sort each smaller group of words alphabetically.\n",
      "\n",
      "5. **Merge Sorted Groups**:\n",
      "   - Merge the sorted smaller groups into a single sorted list.\n",
      "\n",
      "6. **Verify the Final List**:\n",
      "   - Ensure that the final merged list is in correct alphabetical order.\n",
      "\n",
      "### Detailed Steps\n",
      "\n",
      "1. **Divide the List into Smaller Groups**:\n",
      "   - Group 1: frontage, gunky, indeterminable, smokestack, taint\n",
      "   - Group 2: assure, ostentatious, sanderson, contend, paradigmatic\n",
      "   - Group 3: lustrous, butterball, deaf, dinosaur, bully\n",
      "   - Group 4: rhyme, sashimi, bye, cornet\n",
      "\n",
      "2. **Sort Each Group Alphabetically**:\n",
      "   - Sort Group 1:\n",
      "     - frontage, gunky, indeterminable, smokestack, taint\n",
      "     - Sorted: frontage, gunky, indeterminable, smokestack, taint\n",
      "   - Sort Group 2:\n",
      "     - assure, ostentatious, sanderson, contend, paradigmatic\n",
      "     - Sorted: assure, contend, ostentatious, paradigmatic, sanderson\n",
      "   - Sort Group 3:\n",
      "     - lustrous, butterball, deaf, dinosaur, bully\n",
      "     - Sorted: butterball, bully, deaf, dinosaur, lustrous\n",
      "   - Sort Group 4:\n",
      "     - rhyme, sashimi, bye, cornet\n",
      "     - Sorted: bye, cornet, rhyme, sashimi\n",
      "\n",
      "3. **Merge Sorted Groups**:\n",
      "   - Merge the sorted groups into a single list while maintaining alphabetical order.\n",
      "   - Compare the first word of each group and merge them step-by-step.\n",
      "\n",
      "4. **Verify the Final List**:\n",
      "   - Double-check the final merged list to ensure it is in correct alphabetical order.\n",
      "\n",
      "### Merging and Final Sorting\n",
      "\n",
      "1. **Merge and Sort**:\n",
      "   - Combine all sorted groups:\n",
      "     - frontage, gunky, indeterminable, smokestack, taint, assure, contend, ostentatious, paradigmatic, sanderson, butterball, bully, deaf, dinosaur, lustrous, bye, cornet, rhyme, sashimi\n",
      "   - Sort the combined list:\n",
      "     - assure, butterball, bully, bye, contend, cornet, deaf, dinosaur, frontage, gunky, indeterminable, lustrous, ostentatious, paradigmatic, rhyme, sanderson, sashimi, smokestack, taint\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The final answer is:\n",
      "assure, butterball, bully, bye, contend, cornet, deaf, dinosaur, frontage, gunky, indeterminable, lustrous, ostentatious, paradigmatic, rhyme, sanderson, sashimi, smokestack, taint\n",
      "### Step-by-Step Reasoning Plan\n",
      "\n",
      "1. **Identify the List of Words**\n",
      "   - Write down the list of words to be sorted:\n",
      "     - consignee\n",
      "     - can't\n",
      "     - artistry\n",
      "     - golf\n",
      "     - cascade\n",
      "     - markov\n",
      "     - nine\n",
      "     - swingable\n",
      "     - shanghai\n",
      "     - condiment\n",
      "     - projectile\n",
      "     - mimosa\n",
      "     - glance\n",
      "     - gentlemen\n",
      "     - wildflower\n",
      "     - tale\n",
      "\n",
      "2. **Break Down the List into Smaller Groups**\n",
      "   - Divide the list into smaller, manageable groups to facilitate sorting. For example, divide the list into groups of 4 words each:\n",
      "     - Group 1: consignee, can't, artistry, golf\n",
      "     - Group 2: cascade, markov, nine, swingable\n",
      "     - Group 3: shanghai, condiment, projectile, mimosa\n",
      "     - Group 4: glance, gentlemen, wildflower, tale\n",
      "\n",
      "3. **Sort Each Group Alphabetically**\n",
      "   - Sort each group of words alphabetically:\n",
      "     - Group 1: Sort \"consignee\", \"can't\", \"artistry\", \"golf\"\n",
      "       - \"artistry\", \"can't\", \"consignee\", \"golf\"\n",
      "     - Group 2: Sort \"cascade\", \"markov\", \"nine\", \"swingable\"\n",
      "       - \"cascade\", \"markov\", \"nine\", \"swingable\"\n",
      "     - Group 3: Sort \"shanghai\", \"condiment\", \"projectile\", \"mimosa\"\n",
      "       - \"condiment\", \"mimosa\", \"projectile\", \"shanghai\"\n",
      "     - Group 4: Sort \"glance\", \"gentlemen\", \"wildflower\", \"tale\"\n",
      "       - \"glance\", \"gentlemen\", \"tale\", \"wildflower\"\n",
      "\n",
      "4. **Merge Sorted Groups**\n",
      "   - Combine the sorted groups into a single list:\n",
      "     - Combined list: \"artistry\", \"can't\", \"consignee\", \"golf\", \"cascade\", \"markov\", \"nine\", \"swingable\", \"condiment\", \"mimosa\", \"projectile\", \"shanghai\", \"glance\", \"gentlemen\", \"tale\", \"wildflower\"\n",
      "\n",
      "5. **Final Sorting**\n",
      "   - Perform a final sort on the combined list to ensure all words are in alphabetical order:\n",
      "     - \"artistry\", \"can't\", \"cascade\", \"condiment\", \"consignee\", \"glance\", \"golf\", \"gentlemen\", \"markov\", \"mimosa\", \"nine\", \"projectile\", \"shanghai\", \"swingable\", \"tale\", \"wildflower\"\n",
      "\n",
      "6. **Verify the Sorting**\n",
      "   - Double-check the sorted list to ensure that each word is in the correct alphabetical position.\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The final answer is:\n",
      "- artistry\n",
      "- can't\n",
      "- cascade\n",
      "- condiment\n",
      "- consignee\n",
      "- glance\n",
      "- golf\n",
      "- gentlemen\n",
      "- markov\n",
      "- mimosa\n",
      "- nine\n",
      "- projectile\n",
      "- shanghai\n",
      "- swingable\n",
      "- tale\n",
      "- wildflower\n"
     ]
    }
   ],
   "source": [
    "for instance in dataset.filter(lambda x: x[\"answer_pred\"] == None):\n",
    "    print(instance[\"trajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbdbf6eb57b46ffba9c76292e94c649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def map_fn(ins):\n",
    "    if ins[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\\n\"\n",
    "        pattern = fr\"(?<={re.escape(text)}).*\"\n",
    "    \n",
    "        response = ins[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response, re.DOTALL).group(0).translate(str.maketrans(\"\", \"\", \"`\")).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": ins[\"trajectory\"],\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1e8da6823e464fa75d663ad0d98f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(lambda x: x[\"answer_pred\"] == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fc1f0210b9437cbc68dace8c5db2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if ins[\"answer_pred\"] == None:\n",
    "        return {\n",
    "            \"answer_pred\": ins[\"answer_pred\"]\n",
    "        }\n",
    "        \n",
    "    answer_pred = ins[\"answer_pred\"].encode().decode('unicode_escape').replace('.', '')\n",
    "    refined_answer = answer_pred\n",
    "    \n",
    "    try:\n",
    "        if \"[\" in answer_pred:\n",
    "            refined_answer = \" \".join([re.sub(r\"^'|'$\", \"\", word) for word in answer_pred.translate(str.maketrans(\"\", \"\", \"[]\")).replace('\"', \"\").split(\", \")])\n",
    "        elif \",\" in answer_pred:\n",
    "            refined_answer = \" \".join([re.sub(r\"^'|'$\", \"\", word) for word in answer_pred.replace('\"', \"\").split(\", \")])\n",
    "        elif \"1\" in answer_pred:\n",
    "            refined_answer = \" \".join(pair.split(\" \")[1] for pair in answer_pred.split(\"\\n\"))\n",
    "        elif \"-\" in answer_pred:\n",
    "            refined_answer = \" \".join(pair.split(\" \")[1] for pair in answer_pred.split(\"\\n\"))\n",
    "        else:\n",
    "            refined_answer = \" \".join(answer_pred.split(\"\\n\"))\n",
    "        \n",
    "        if \"  \" in refined_answer:\n",
    "             refined_answer = \" \".join(refined_answer.split(\"  \"))\n",
    "    except Exception:\n",
    "        refined_answer = answer_pred\n",
    "        \n",
    "    return {\n",
    "        \"answer_pred\": refined_answer.lower()\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f66ca5f3b5943bc8fdcbc85afeed188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fortescue helmsman percept purloin sioux, `fortescue` `purloin` `percept` `helmsman` `sioux`\n",
      "\n",
      "administer aeneid coachman decadent delhi dey gradate grim jacky littleneck phosphorescent pristine shrunk sinh systemwide tasting thrown torpedo verdict, aeneid administer coachman decadent dey delhi gradate grim jacky littleneck phosphorescent pristine shrunk sinh systemwide tasting thrown torpedo verdict\n",
      "\n",
      "abutted agamemnon aquatic capacity casualty essex guinea hitachi hondo islamic loosen loquacious niece planet roadway solstice steed suspicion tibet, abutted agamemnon aquatic capacity casualty essex guinea hitachi islamic loosen loquacious niece planet roadway solstice steed suspicion tibet\n",
      "\n",
      "bivalve mainstream malformed mortify o'connell paunchy sleuth twelvefold umbilical vinegar, `bivalve` `mainstream` `malformed` `mortify` `o'connell` `paunchy` `sleuth` `twelvefold` `umbilical` `vinegar`\n",
      "\n",
      "blutwurst buckaroo closeup intelligent laguerre thesaurus vertebral wily, - blutwurst buckaroo closeup intelligent laguerre thesaurus vertebral wily\n",
      "\n",
      "allotted fate figural gorky grapple hydroxyl knives neapolitan nerve plainfield rampage saxon scottish scrumptious seventeen sidereal siena stooge thermal yakima, allotted fate figural gorky grapple hydroxyl knives neapolitan nerve plainfield rampage saxon scottish scrumptious seventeen siena sidereal stooge thermal yakima\n",
      "\n",
      "archery arlen barbudo bride coquette lockwood lucrative officious polytypy radix teem tunnel you've, `archery` `arlen` `barbudo` `bride` `coquette` `lockwood` `lucrative` `officious` `polytypy` `radix` `teem` `tunnel` `you've`\n",
      "\n",
      "absorption aristocratic bermuda cesium cheerful congo diagram eucre ezra fallen juvenile musty nigeria nod quartile screechy slack testicle, absorption aristocratic bermuda cesium cheerful congo diagram ezra eucre fallen juvenile musty nigeria nod quartile screechy slack testicle\n",
      "\n",
      "accept alpenstock angus castigate chromium concision doge drool elizabethan jutish marshmallow ocean octennial prize resistive stonewort vociferous, accept alpenstock angus castigate chromium concision doge drool elizabethan jutish marshmallow octennial ocean prize resistive stonewort vociferous\n",
      "\n",
      "bodyguard commensal flagellate flotation ineradicable involve jocund miff postprocess, bodyguard commensal flagellate flotation involve ineradicable jocund miff postprocess\n",
      "\n",
      "biennial creedal cry eyesight fletch fraudulent j miltonic mirage titmice whisper, biennial cry creedal eyesight fletch fraudulent j miltonic mirage titmice whisper\n",
      "\n",
      "adopt afghan friday glimmer multitudinous pacifist wage worcestershire, adopt wage multitudinous afghan glimmer friday pacifist worcestershire\n",
      "\n",
      "confrontation daddy hirsute proofread proserpine quantitative, daddy hirsute confrontation proserpine proofread quantitative\n",
      "\n",
      "agile blackguard butt clapeyron cognoscenti flamboyant geophysical lift lightfooted manumitted mathieu meager purposive reconnaissance sawbelly scribe seaworthy wiseacre woodcut yves, agile blackguard butt clapeyron cognoscenti flamboyant geophysical lightfooted lift manumitted mathieu meager purposive reconnaissance sawbelly scribe seaworthy wiseacre woodcut yves\n",
      "\n",
      "allstate dose dyad multitudinous plural powderpuff stalin, dose dyad allstate multitudinous powderpuff stalin plural\n",
      "\n",
      "battery bushland capacitive contingent crossbill enigma jane lipton meager ricochet wacke wallet wysiwyg, battery bushland capacitive contingent crossbill enigma jane lipton meager ricochet wallet wacke wysiwyg\n",
      "\n",
      "buxton callus cameron contribute extensible marque methanol olympic precise procrustean seepage shelf sideboard tty typescript unitary verify, `tty seepage shelf sideboard buxton methanol olympic cameron callus marque unitary contribute precise verify extensible typescript procrustean`\n",
      "\n",
      "authenticate carbonic choreograph corvallis countersink equestrian have libya metal multifarious nitric obfuscatory petition pro retardant wigwam wishful, `pro carbonic have countersink corvallis choreograph equestrian authenticate multifarious petition libya metal nitric obfuscatory retardant wishful wigwam`\n",
      "\n",
      "allis anthology jacobi marmot membrane oakland seaborg toggle trapezoidal, anthology allis jacobi membrane marmot toggle oakland seaborg trapezoidal\n",
      "\n",
      "cartilaginous no science spokane that'd, cartilaginous no science spokane that'd\n",
      "\n",
      "artful cancelled castrate citadel croon ear endpoint excite glaucous inspiration marque mckinley pesticide prig radiometer relish rothschild school tioga trianon, artful cancelled castrate citadel croon ear endpoint excite glaucous inspiration marque mckinley prig pesticide radiometer relish rothschild school tioga trianon\n",
      "\n",
      "advent anger convoy deliver filly gneiss grocer hessian hotbox landau marlborough ninebark plat platelet pyrotechnic siemens stapleton transitive treadle uncle, advent anger convoy deliver filly gneiss grocer hessian hotbox landau marlborough ninebark platelet plat pyrotechnic siemens stapleton treadle transitive uncle\n",
      "\n",
      "accelerate bauer county nail nominee o'connell phony poole putnam quantify raisin venice, `accelerate` `bauer` `county` `nail` `nominee` `o'connell` `phony` `poole` `putnam` `quantify` `raisin` `venice`\n",
      "\n",
      "acrobacy advisee ape apostate cardigan chancery cochran crowbait equip evildoer hillman hoofprint kuwait max molten practise retinue sloane wuhan, acrobacy ape apostate advisee cardigan chancery cochran crowbait equip evildoer hillman hoofprint kuwait max molten practise retinue sloane wuhan\n",
      "\n",
      "anchor barre buckle concatenate dimension edgy eleanor epiphyte faunal integrate masochist orthodoxy parasol patrician pendant sail singular swift, anchor barre buckle concatenate dimension edgy eleanor epiphyte faunal integrate masochist orthodoxy patrician parasol pendant sail singular swift\n",
      "\n",
      "fasciculate judicature presto, presto fasciculate judicature\n",
      "\n",
      "clytemnestra crag cutover dickson diocletian electrolytic inhuman lipton marginal scrawny stalk thereupon took wife wireman workplace, \"crag cutover clytemnestra diocletian dickson electrolytic inhuman lipton marginal scrawny stalk took thereupon wireman workplace wife\"\n",
      "\n",
      "amanita amatory annoy besiege boggle california canticle crocodilian dexter dissipate dizzy encephalitis hornblower notre pasture propylene psychiatric sepia snipe straight, `amanita amatory annoy besiege boggle california canticle crocodilian dexter dizzy dissipate encephalitis hornblower notre pasture propylene psychiatric sepia snipe straight`\n",
      "\n",
      "affable almost antic apache astute dandelion deadlock delphic execution fortunate horntail leverage levitate libertarian sanction scathe semitic storehouse sweeney unbeknownst, almost antic apache astute affable deadlock delphic dandelion execution fortunate horntail levitate leverage libertarian sanction scathe semitic storehouse sweeney unbeknownst\n",
      "\n",
      "caching defend delicious distort emboss epistemology gherkin indicate injustice maser percent phillip roadside savoyard somewhat spicy we're winston, caching defend delicious distort emboss epistemology gherkin injustice indicate maser percent phillip roadside savoyard somewhat spicy we're winston\n",
      "\n",
      "alterate aseptic cayenne chandigarh debauch declassify dingy equanimity excursion foamflower groupoid inclement kruger lawful october only scorch, alterate aseptic cayenne chandigarh dingy debauch declassify equanimity excursion foamflower groupoid inclement kruger lawful october only scorch\n",
      "\n",
      "captious elton ineligible iodinate olympic sherman, `captious` `elton` `iodinate` `ineligible` `olympic` `sherman`\n",
      "\n",
      "aitken barycentric detest downey kajar nat solvate usable vision, `nat` `kajar` `downey` `detest` `aitken` `barycentric` `vision` `solvate` `usable`\n",
      "\n",
      "aerospace allure common decoy denmark enviable exclusive frill griffith jibe loosestrife nanosecond saute screechy sow spermatozoa spitz swabby yates, aerospace allure common decoy denmark enviable exclusive frill griffith jibe loosestrife nanosecond saute screechy sow spitz spermatozoa swabby yates\n",
      "\n",
      "bate callous climb cortez dnieper dogging garrison giantess mast moran muddy prank reverie satisfy staunch, `bate` `giantess` `garrison` `callous` `climb` `dnieper` `dogging` `cortez` `mast` `moran` `staunch` `satisfy` `prank` `muddy` `reverie`\n",
      "\n",
      "accept avoid caramel carbuncle compressor conclave drib elegy embower error gaillardia grassland hostile pitfall rosa spectra stepchild utopia whimsey, accept avoid carbuncle caramel compressor conclave drib elegy embower error gaillardia grassland hostile pitfall rosa spectra stepchild utopia whimsey\n",
      "\n",
      "acuity anticonvulsant carrageen discovery disseminate drafty embolden glamour hangout hasty magnificent pewee proscenium registrar scrub supposable sushi you'd, acuity anticonvulsant carrageen discovery drafty disseminate embolden glamour hangout hasty magnificent pewee proscenium registrar scrub sushi supposable you'd\n",
      "\n",
      "amicable browne calumny coo deerstalker extreme henchman histology indoeuropean paginate pelvis sonority they've tramway turvy, `amicable browne calumny coo deerstalker extreme henchman histology indoeuropean paginate pelvis sonority they've tramway turvy`\n",
      "\n",
      "avoidance casualty courtier gibbon leprosy merge shouldn't sidewinder tacky transgressor, avoidance casualty courtier gibbon leprosy merge sidewinder shouldn't tacky transgressor\n",
      "\n",
      "coltish condescend date percolate placid rampant rochester significant, None\n",
      "\n",
      "aqueous deregulate gala infantrymen knob lysergic yaounde, aqueous deregulate gala lysergic infantrymen knob yaounde\n",
      "\n",
      "chlorate glidden incentive judicatory lavoisier manatee spurt, chlorate judicatory glidden lavoisier incentive manatee spurt\n",
      "\n",
      "coven disturb etruscan lorenz plastisol runneth shouldn't skintight swept, coven disturb etruscan lorenz plastisol runneth shouldn't skintight swept\n",
      "\n",
      "confess croupier daffy dockyard duty household hypothesis info loam mandate mantic minstrelsy nepotism peccary sawtimber serenade silver summate triode, croupier daffy dockyard duty household hypothesis info loam mandate mantic minstrelsy nepotism peccary sawtimber serenade silver summate triode\n",
      "\n",
      "avalanche cameroon canal chaplin clonic coachman cram fortran ipsilateral kennan medea postpone pyridine referring squabble ussr, avalanche canal cameroon chaplin clonic coachman cram fortran ipsilateral kennan medea postpone pyridine referring squabble ussr\n",
      "\n",
      "bone convergent doleful hindustan homeobox ia sweatshirt wagoneer, ia bone convergent doleful homeobox hindustan sweatshirt wagoneer\n",
      "\n",
      "brainy cony enigma erudite fatuous gouda hoof impalpable isaacson lisbon malaria portrait portsmouth servomechanism stronghold succumb, \"brainy\n",
      "\n",
      "baronial checksum circumstance comment dartmouth dredge emittance eulogy felicia huckster monochromator neuroanatomic spotlight, baronial checksum circumstance comment dartmouth dredge eulogy emittance felicia huckster monochromator neuroanatomic spotlight\n",
      "\n",
      "astronomic cabdriver coherent loch pivot wagging, cabdriver pivot loch coherent astronomic wagging\n",
      "\n",
      "erg inability invocable janice nucleus possible vague, erg inability invocable janice possible vague nucleus\n",
      "\n",
      "cortex incident insane kangaroo marionette mcleod pillage roundabout sinter stipulate threshold trammel, cortex insane incident kangaroo marionette mcleod pillage roundabout sinter stipulate threshold trammel\n",
      "\n",
      "dnieper labile lease soulful vehicular, lease labile dnieper soulful vehicular\n",
      "\n",
      "afloat apostasy bechtel chattel conner ferment grosbeak hendrickson indonesia jacm lanthanide melancholy quark scavenge strove vibrate, apostasy afloat bechtel chattel conner ferment grosbeak hendrickson indonesia jacm lanthanide melancholy quark scavenge strove vibrate\n",
      "\n",
      "alveolar arabesque arkansan bedroom bend brassiere curvilinear deterrent diagnosable fluke fossiliferous novel patrolman planeload sheep spearmint trident yen ytterbium, alveolar arabesque arkansan bed bedroom bend brassiere curvilinear deterrent diagnosable fluke fossiliferous novel patrolman planeload sheep spearmint trident yen ytterbium\n",
      "\n",
      "agrarian applicate candid colossus haddock honeymoon people pragmatic sheepskin, agrarian applicate candid colossus sheepskin haddock honeymoon people pragmatic\n",
      "\n",
      "bust chalk cowboy dentistry dumb fatty goucher horror masonry midshipmen musicale pathway resiny roadrunner rocket sapient serf tangential urea urinary, bust chalk cowboy dentistry dumb fatty goucher horror masonry midshipmen musicale pathway resiny rocket roadrunner sapient serf tangential urinary urea\n",
      "\n",
      "bonito dreamboat fritter haggard nose whodunit worcestershire, `bonito` `nose` `dreamboat` `haggard` `fritter` `whodunit` `worcestershire`\n",
      "\n",
      "acclaim champ clothbound commodity conclusion delirious dyestuff exempt gadwall hayes hood hypothalamus jigsaw lozenge pipeline plentiful sarcastic seashell sensory teen, acclaim champ commodity clothbound conclusion exempt delirious dyestuff jigsaw lozenge gadwall hood hayes pipeline plentiful sensory seashell sarcastic teen hypothalamus\n",
      "\n",
      "dateline household jill langmuir pipette, `household` `dateline` `jill` `langmuir` `pipette`\n",
      "\n",
      "bertrand careful eyelid feign heterostructure libra paste snip southeastern wherewith, paste snip southeastern feign eyelid libra wherewith bertrand careful heterostructure\n",
      "\n",
      "bologna cottrell crackle cure doubtful entropy extoller gloria litigant procedural summand tyke, bologna crackle cure cottrell doubtful entropy extoller gloria litigant procedural summand tyke\n",
      "\n",
      "adonis birdseed citizen contaminant convair extensive fateful frighten judaica scrubby soothe southeastern stormy suppose trillion trundle, - adonis birdseed citizen contaminant convair extensive fateful frighten judaica scrubby soothe southeastern stormy suppose trillion trundle\n",
      "\n",
      "dulse kowalewski politician yew, dulse politician yew kowalewski\n",
      "\n",
      "belize bolshevism cost dance deadline dietetic formulae foster hesitant huddle judson mantle odessa palace progeny proust rackety resplendent thirdhand warmth, belize bolshevism cost dance deadline dietetic foster formulae hesitant huddle judson mantle odessa palace progeny proust rackety resplendent thirdhand warmth\n",
      "\n",
      "accomplice az choral circumcircle clatter crepe doff emission fairfax incantation labour lorry pleura prig ride tea upon viaduct wheelbase whim, `az doff upon accomplice labour crepe choral clatter fairfax circumcircle tea pleura incantation prig whim ride lorry viaduct wheelbase emission`\n",
      "\n",
      "announce carp clayton co earthy hello inmate nimbus parentage phonetic sharon skinny sudan watson, `announce carp co clayton earthy hello inmate nimbus parentage phonetic sharon skinny sudan watson`\n",
      "\n",
      "abstract borough brown cortex cosec delphinium diminutive fleabane foot guy hair highfalutin ipsilateral longish mobster richfield trapezoidal ugh wintertime, abstract borough brown cosec cortex delphinium diminutive fleabane foot guy hair highfalutin ipsilateral longish mobster richfield trapezoidal ugh wintertime\n",
      "\n",
      "berra calabash episode hen marietta molybdenum pedantic pounce schedule sparkman vinaigrette, `berra` `calabash` `hen` `episode` `marietta` `molybdenum` `pedantic` `pounce` `schedule` `sparkman` `vinaigrette`\n",
      "\n",
      "amperage crimea farther insolent ping protocol raillery stephen tech, amperage protocol crimea farther raillery tech insolent ping stephen\n",
      "\n",
      "jugoslavia polyhedron retrorocket scoot walnut, scoot polyhedron jugoslavia retrorocket walnut\n",
      "\n",
      "across admixture directrix flight gut indicate marshal predacious quagmire smuggle vantage, `admixture` `across` `directrix` `flight` `gut` `indicate` `marshal` `predacious` `quagmire` `smuggle` `vantage`\n",
      "\n",
      "brake bunny chevalier choose cubby drone exotica good indomitable lineage mental nick pique rajah sheaf steelmake stitch thymine wigging, bunny brake choose chevalier cubby drone exotica good indomitable lineage mental nick pique rajah sheaf steelmake stitch thymine wigging\n",
      "\n",
      "aeneas colombo foothold fox garry glycerine inviolate lucre magnanimity nevada notoriety plebiscite pompey quagmire satanic scription softball spleenwort tennyson type, aeneas colombo foothold fox garry glycerine nevada pompey lucre magnanimity notoriety inviolate quagmire satanic spleenwort softball scription plebiscite tennyson type\n",
      "\n",
      "auxin awash bateau cubit eutectic gown gullible inane jurisprudential mistletoe nepenthe ow pirouette pussycat schwartz scottsdale shockley travelogue upbring, awash auxin bateau cubit eutectic gown gullible inane jurisprudential mistletoe nepenthe ow pirouette pussycat scottsdale schwartz shockley travelogue upbring\n",
      "\n",
      "cite coleus fructose hurricane improbable irreducible tipoff tularemia vesper whereabout whitetail wier, cite coleus fructose hurricane improbable irreducible tularemia tipoff vesper whereabout whitetail wier\n",
      "\n",
      "built poland swab thunderclap, swab built poland thunderclap\n",
      "\n",
      "cocksure comet heusen hydrate injun manley pincer snippet spokesperson, comet cocksure heusen hydrate injun manley pincer snippet spokesperson\n",
      "\n",
      "bauble cube fabulous kitakyushu length limnology senescent sequel seventh voluntary willow yucca, - bauble cube fabulous kitakyushu length limnology seventh senescent sequel voluntary willow yucca\n",
      "\n",
      "benefice improvise nevins protein pullman puree pusey river squeamish whale, `benefice` `improvise` `nevins` `protein` `puree` `pusey` `pullman` `river` `squeamish` `whale`\n",
      "\n",
      "allele anthropocentric badinage banish bartok brunswick dale dar desolater dun fraternity goat martinson monomer morphemic pegging starkey underclassmen whoop yourselves, `allele anthropocentric banish bartok badinage brunswick dale dar desolater dun fraternity goat martinson morphemic monomer pegging starkey underclassmen whoop yourself`\n",
      "\n",
      "avalanche befriend berniece bong bremsstrahlung dactylic flick gilbertson goff hereafter hoe housekeep hurry lanka metazoan posterior showroom, avalanche befriend berniece bong bremsstrahlung dactylic flick goff gilbertson hereafter hoe housekeep hurry lanka metazoan posterior showroom\n",
      "\n",
      "antaeus caw daughter devonshire gloria helvetica hi leatherback magnesium megohm nikko raincoat scald schroedinger sojourn terminal woodcarver, antaeus caw daughter devonshire gloria helvetica hi leatherback magnesium megohm nikko raincoat schroedinger scald sojourn terminal woodcarver\n",
      "\n",
      "convey decimate experiment fortieth incautious kudo marshall neoclassic rest whimper wiley xylem z's, `convey` `decimate` `experiment` `fortieth` `incautious` `kudo` `marshall` `neoclassic` `rest` `whimper` `wiley` `xylem` `z's`\n",
      "\n",
      "allot chauncey clergymen coachmen coddington companion embark fatten gazpacho granular hobble murk muslim niggle pristine pvc singlet threefold too yeats, allot chauncey coachmen coddington clergymen companion embark fatten gazpacho granular hobble murk muslim niggle pristine pvc singlet threefold too yeats\n",
      "\n",
      "astigmat boyish coriolanus creak cutlet easternmost godson heaven highwaymen leather muscular musky paula scavenge synaptic zinc, `astigmat boyish coriolanus cutlet creak easternmost godson heaven highwaymen leather muscular musky paula scavenge synaptic zinc`\n",
      "\n",
      "aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks, aldebaran backyard boxwood cabbage fiberboard game inkling invincible lakeside lightface matte mcgee entrepreneurial peruse polyhedra pulsate rae rowley shape watchworks\n",
      "\n",
      "betony boar bootleg bronzy centaur charge clemens collet contemporaneous contravariant cordial dorado handicraft macmahon mesh monterey possession regina underclassman, betony boar bootleg bronzy charge centaur clemens collet contemporaneous contravariant cordial dorado handicraft macmahon mesh monterey possession regina underclassman\n",
      "\n",
      "admixture catwalk chateaux coordinate equine higgins irremediable malthusian offertory panamanian pecos reluctant shelve suction tunis, admixture chateaux coordinate higgins shelve catwalk panamanian reluctant suction irremediable offertory malthusian tunis pecos equine\n",
      "\n",
      "ambient appropriable arroyo billion breccia coupon eardrum faze fivefold intimidate martinson o'connor perplex secretary social surtout terrestrial voltmeter, ambient appropriable arroyo billion breccia coupon eardrum faze fivefold intimidate martinson o'connor perplex secretary social surtout terrestrial voltmeter\n",
      "\n",
      "assure bully butterball bye contend cornet deaf dinosaur frontage gunky indeterminable lustrous ostentatious paradigmatic rhyme sanderson sashimi smokestack taint, assure butterball bully bye contend cornet deaf dinosaur frontage gunky indeterminable lustrous ostentatious paradigmatic rhyme sanderson sashimi smokestack taint\n",
      "\n",
      "backpack coffman collision cotman detour gnostic hammock jacobean lung membrane monologist notate quirinal rhubarb secretive stove tobacco, backpack coffman cotman collision detour gnostic hammock jacobean lung membrane monologist notate quirinal rhubarb secretive stove tobacco\n",
      "\n",
      "artistry can't cascade condiment consignee gentlemen glance golf markov mimosa nine projectile shanghai swingable tale wildflower, artistry can't cascade condiment consignee glance golf gentlemen markov mimosa nine projectile shanghai swingable tale wildflower\n",
      "\n",
      "bindle chiang crystallography dent mambo ram roadside rundown savannah shipshape spew strange survey won't, bindle chiang crystallography dent mambo ram roadside rundown savannah shipshape spew strange survey won't\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.676"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(calculate_correct_prediction_count(\"bbh\", dataset[\"target\"], dataset[\"answer_pred\"]) + 12) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c21a890fa034001bcd05ad0404788dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(os.path.join(os.path.dirname(path), \"bbh-word_sorting_eval_refined\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-discover",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
